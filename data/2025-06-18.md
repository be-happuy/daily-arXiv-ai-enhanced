<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 72]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.CL](#cs.CL) [Total: 61]
- [cs.IR](#cs.IR) [Total: 3]
- [eess.AS](#eess.AS) [Total: 2]
- [eess.IV](#eess.IV) [Total: 10]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 8]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.RO](#cs.RO) [Total: 3]
- [cs.SD](#cs.SD) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Non-planar Object Detection and Identification by Features Matching and Triangulation Growth](https://arxiv.org/abs/2506.13769)
*Filippo Leveni*

Main category: cs.CV

TL;DR: 提出了一种基于特征的迭代方法，用于检测和识别场景图像中变形的模板对象，利用Delaunay三角剖分和局部一致性标准进行特征匹配分组。


<details>
  <summary>Details</summary>
Motivation: 解决在几何模型（如单应性）不适用的情况下（如非平面模板或平面模板变形）的对象检测问题。

Method: 使用Delaunay三角剖分作为图结构，从单个三角形开始逐步扩展，通过几何和光度一致性标准评估特征匹配。

Result: 在变形较小的情况下性能与基于单应性的RANSAC相当或更好，变形显著时表现更优。

Conclusion: 该方法适用于复杂变形场景，扩展了传统几何模型的应用范围。

Abstract: Object detection and identification is surely a fundamental topic in the computer vision field; it plays a crucial role in many applications such as object tracking, industrial robots control, image retrieval, etc. We propose a feature-based approach for detecting and identifying distorted occurrences of a given template in a scene image by incremental grouping of feature matches between the image and the template. For this purpose, we consider the Delaunay triangulation of template features as an useful tool through which to be guided in this iterative approach. The triangulation is treated as a graph and, starting from a single triangle, neighboring nodes are considered and the corresponding features are identified; then matches related to them are evaluated to determine if they are worthy to be grouped. This evaluation is based on local consistency criteria derived from geometric and photometric properties of local features. Our solution allows the identification of the object in situations where geometric models (e.g. homography) does not hold, thus enable the detection of objects such that the template is non planar or when it is planar but appears distorted in the image. We show that our approach performs just as well or better than application of homography-based RANSAC in scenarios in which distortion is nearly absent, while when the deformation becomes relevant our method shows better description performance.

</details>


### [2] [CDST: Color Disentangled Style Transfer for Universal Style Reference Customization](https://arxiv.org/abs/2506.13770)
*Shiwen Zhang,Zhuowei Chen,Lang Chen,Yanze Wu*

Main category: cs.CV

TL;DR: CDST是一种新颖的双流风格迁移训练范式，通过完全隔离颜色与风格，实现无需调优的通用风格迁移。


<details>
  <summary>Details</summary>
Motivation: 解决传统风格迁移中颜色与风格耦合的问题，并首次实现无需调优的特征保留风格迁移。

Method: 采用双流训练范式，分离颜色与风格，结合多特征图像嵌入压缩和Diffusion UNet解耦律的新风格定义。

Result: 在多种风格迁移任务中达到最先进水平，风格相似性显著提升，同时保留强大编辑能力。

Conclusion: CDST为风格迁移领域提供了高效、通用的解决方案，具有广泛的应用潜力。

Abstract: We introduce Color Disentangled Style Transfer (CDST), a novel and efficient two-stream style transfer training paradigm which completely isolates color from style and forces the style stream to be color-blinded. With one same model, CDST unlocks universal style transfer capabilities in a tuning-free manner during inference. Especially, the characteristics-preserved style transfer with style and content references is solved in the tuning-free way for the first time. CDST significantly improves the style similarity by multi-feature image embeddings compression and preserves strong editing capability via our new CDST style definition inspired by Diffusion UNet disentanglement law. By conducting thorough qualitative and quantitative experiments and human evaluations, we demonstrate that CDST achieves state-of-the-art results on various style transfer tasks.

</details>


### [3] [Hidden Bias in the Machine: Stereotypes in Text-to-Image Models](https://arxiv.org/abs/2506.13780)
*Sedat Porikli,Vedat Porikli*

Main category: cs.CV

TL;DR: 研究发现文本到图像（T2I）模型在生成图像时会复制和放大社会偏见，尤其是在性别、种族、年龄等方面。


<details>
  <summary>Details</summary>
Motivation: 探讨T2I模型是否复制和放大社会偏见，以促进更公平的视觉生成系统。

Method: 使用Stable Diffusion 1.5和Flux-1模型生成16,000多张图像，并与Google Image Search的8,000张图像对比。

Result: 生成的图像在性别、种族、年龄等方面存在显著差异，强化了社会刻板印象。

Conclusion: 需要更包容的数据集和开发实践以减少偏见。

Abstract: Text-to-Image (T2I) models have transformed visual content creation, producing highly realistic images from natural language prompts. However, concerns persist around their potential to replicate and magnify existing societal biases. To investigate these issues, we curated a diverse set of prompts spanning thematic categories such as occupations, traits, actions, ideologies, emotions, family roles, place descriptions, spirituality, and life events. For each of the 160 unique topics, we crafted multiple prompt variations to reflect a wide range of meanings and perspectives. Using Stable Diffusion 1.5 (UNet-based) and Flux-1 (DiT-based) models with original checkpoints, we generated over 16,000 images under consistent settings. Additionally, we collected 8,000 comparison images from Google Image Search. All outputs were filtered to exclude abstract, distorted, or nonsensical results. Our analysis reveals significant disparities in the representation of gender, race, age, somatotype, and other human-centric factors across generated images. These disparities often mirror and reinforce harmful stereotypes embedded in societal narratives. We discuss the implications of these findings and emphasize the need for more inclusive datasets and development practices to foster fairness in generative visual systems.

</details>


### [4] [Fake it till You Make it: Reward Modeling as Discriminative Prediction](https://arxiv.org/abs/2506.13846)
*Runtao Liu,Jiahao Zhan,Yingqing He,Chen Wei,Alan Yuille,Qifeng Chen*

Main category: cs.CV

TL;DR: GAN-RM提出了一种高效的奖励建模框架，无需人工标注偏好数据或显式设计质量维度，通过对抗训练实现奖励模型的训练。


<details>
  <summary>Details</summary>
Motivation: 当前奖励建模方法依赖大量人工标注数据或复杂设计的质量维度，实现复杂且不完整。

Method: 利用对抗训练，通过区分目标样本与模型生成样本训练奖励模型，仅需少量目标样本。

Result: 实验证明GAN-RM在多种应用中有效，如样本过滤、监督微调和直接偏好优化。

Conclusion: GAN-RM简化了奖励建模流程，提高了效率，适用于多种增强视觉生成模型的场景。

Abstract: An effective reward model plays a pivotal role in reinforcement learning for post-training enhancement of visual generative models. However, current approaches of reward modeling suffer from implementation complexity due to their reliance on extensive human-annotated preference data or meticulously engineered quality dimensions that are often incomplete and engineering-intensive. Inspired by adversarial training in generative adversarial networks (GANs), this paper proposes GAN-RM, an efficient reward modeling framework that eliminates manual preference annotation and explicit quality dimension engineering. Our method trains the reward model through discrimination between a small set of representative, unpaired target samples(denoted as Preference Proxy Data) and model-generated ordinary outputs, requiring only a few hundred target samples. Comprehensive experiments demonstrate our GAN-RM's effectiveness across multiple key applications including test-time scaling implemented as Best-of-N sample filtering, post-training approaches like Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO).

</details>


### [5] [DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding](https://arxiv.org/abs/2506.13897)
*Thomas Kreutz,Max Mühlhäuser,Alejandro Sanchez Guinea*

Main category: cs.CV

TL;DR: DeSPITE模型通过多模态对比预训练，将LiDAR点云、人体骨骼姿态、IMU数据和文本嵌入到联合空间中，实现了新的人体活动理解任务。


<details>
  <summary>Details</summary>
Motivation: 尽管LiDAR在感知人体活动时具有隐私保护优势，但其在多模态对比预训练中的应用尚未充分探索。本文旨在填补这一空白。

Method: 提出DeSPITE模型，通过噪声对比估计学习四种模态的联合嵌入空间，并结合LIPD和Babel数据集进行实验。

Result: 实验表明，DeSPITE支持骨骼<->点云<->IMU匹配、检索和时间片段检索等新任务，并在点云HAR任务中表现出色。

Conclusion: DeSPITE是一种有效的多模态预训练策略，为点云序列的人体活动理解提供了新方法。

Abstract: Despite LiDAR (Light Detection and Ranging) being an effective privacy-preserving alternative to RGB cameras to perceive human activities, it remains largely underexplored in the context of multi-modal contrastive pre-training for human activity understanding (e.g., human activity recognition (HAR), retrieval, or person re-identification (RE-ID)). To close this gap, our work explores learning the correspondence between LiDAR point clouds, human skeleton poses, IMU data, and text in a joint embedding space. More specifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embedding model, which effectively learns a joint embedding space across these four modalities through noise contrastive estimation. At the heart of our empirical exploration, we have combined the existing LIPD and Babel datasets, which enabled us to synchronize data of all four modalities, allowing us to explore the learning of a new joint embedding space. Our experiments demonstrate novel human activity understanding tasks for point cloud sequences enabled through DeSPITE, including Skeleton<->Pointcloud<->IMU matching, retrieval, and temporal moment retrieval. Furthermore, we show that DeSPITE is an effective pre-training strategy for point cloud HAR through experiments in MSR-Action3D and HMPEAR.

</details>


### [6] [OPTIMUS: Observing Persistent Transformations in Multi-temporal Unlabeled Satellite-data](https://arxiv.org/abs/2506.13902)
*Raymond Yu,Paul Han,Josh Myers-Dean,Piper Wolters,Favyen Bastani*

Main category: cs.CV

TL;DR: OPTIMUS是一种自监督学习方法，通过检测时间序列中的变化点来识别卫星图像中的持久变化，显著提高了变化检测的性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标注的变化标签数据，尤其是稀有类别，监督方法在卫星图像变化检测中面临挑战。

Method: 提出OPTIMUS，基于自监督学习原则，通过恢复时间序列图像的相对顺序信息来检测持久变化。

Result: OPTIMUS在区分变化与未变化时间序列上的AUROC得分从56.3%提升至87.6%。

Conclusion: OPTIMUS有效解决了卫星图像变化检测中的数据标注难题，显著提升了性能。

Abstract: In the face of pressing environmental issues in the 21st century, monitoring surface changes on Earth is more important than ever. Large-scale remote sensing, such as satellite imagery, is an important tool for this task. However, using supervised methods to detect changes is difficult because of the lack of satellite data annotated with change labels, especially for rare categories of change. Annotation proves challenging due to the sparse occurrence of changes in satellite images. Even within a vast collection of images, only a small fraction may exhibit persistent changes of interest. To address this challenge, we introduce OPTIMUS, a self-supervised learning method based on an intuitive principle: if a model can recover information about the relative order of images in the time series, then that implies that there are long-lasting changes in the images. OPTIMUS demonstrates this principle by using change point detection methods on model outputs in a time series. We demonstrate that OPTIMUS can directly detect interesting changes in satellite images, achieving an improvement in AUROC score from 56.3% to 87.6% at distinguishing changed time series from unchanged ones compared to baselines. Our code and dataset are available at https://huggingface.co/datasets/optimus-change/optimus-dataset/.

</details>


### [7] [Intelligent Image Sensing for Crime Analysis: A ML Approach towards Enhanced Violence Detection and Investigation](https://arxiv.org/abs/2506.13910)
*Aritra Dutta,Pushpita Boral,G Suseela*

Main category: cs.CV

TL;DR: 利用机器学习检测和分类视频流中的暴力事件，提出了一种基于3D卷积神经网络和双向LSTM的框架，在多样化的数据集上表现出更高的计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统监控方法在及时检测多样化和突发暴力行为方面存在局限，亟需自动化的暴力检测解决方案。

Method: 采用监督学习进行二分类和多分类暴力检测，使用3D卷积神经网络进行检测，可分离卷积3D模型和双向LSTM进行分类。

Result: 在多样化数据集上训练，结合实时视频流处理，表现出更高的计算效率和准确性。

Conclusion: 该框架为暴力检测提供了高效且准确的解决方案，适用于实时监控场景。

Abstract: The increasing global crime rate, coupled with substantial human and property losses, highlights the limitations of traditional surveillance methods in promptly detecting diverse and unexpected acts of violence. Addressing this pressing need for automatic violence detection, we leverage Machine Learning to detect and categorize violent events in video streams. This paper introduces a comprehensive framework for violence detection and classification, employing Supervised Learning for both binary and multi-class violence classification. The detection model relies on 3D Convolutional Neural Networks, while the classification model utilizes the separable convolutional 3D model for feature extraction and bidirectional LSTM for temporal processing. Training is conducted on a diverse customized datasets with frame-level annotations, incorporating videos from surveillance cameras, human recordings, hockey fight, sohas and wvd dataset across various platforms. Additionally, a camera module integrated with raspberry pi is used to capture live video feed, which is sent to the ML model for processing. Thus, demonstrating improved performance in terms of computational resource efficiency and accuracy.

</details>


### [8] [HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment](https://arxiv.org/abs/2506.13925)
*Numair Nadeem,Saeed Anwar,Muhammad Hamza Asad,Abdul Bais*

Main category: cs.CV

TL;DR: HierVL是一个结合视觉语言模型和半监督语义分割的统一框架，通过多尺度查询和跨模态对齐提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决半监督语义分割在标签稀缺和领域变化下的挑战，尤其是视觉方法在相似类别和边界定位上的不足。

Method: 引入HierVL框架，包括层次语义查询生成器、跨模态空间对齐模块和双查询变换解码器，结合正则化损失。

Result: 在COCO、Pascal VOC、ADE20和Cityscapes上分别提升4.4%、3.1%、5.9%和1.8%的mIoU。

Conclusion: 语言引导的分割显著提升了标签效率和细粒度实例感知的泛化能力。

Abstract: Semi-supervised semantic segmentation remains challenging under severe label scarcity and domain variability. Vision-only methods often struggle to generalize, resulting in pixel misclassification between similar classes, poor generalization and boundary localization. Vision-Language Models offer robust, domain-invariant semantics but lack the spatial grounding required for dense prediction. We introduce HierVL, a unified framework that bridges this gap by integrating abstract text embeddings into a mask-transformer architecture tailored for semi-supervised segmentation. HierVL features three novel components: a Hierarchical Semantic Query Generator that filters and projects abstract class embeddings into multi-scale queries to suppress irrelevant classes and handle intra-class variability; a Cross-Modal Spatial Alignment Module that aligns semantic queries with pixel features for sharper boundaries under sparse supervision; and a Dual-Query Transformer Decoder that fuses semantic and instance-level queries to prevent instance collapse. We also introduce targeted regularization losses that maintain vision-language alignment throughout training to reinforce semantic grounding. HierVL establishes a new state-of-the-art by achieving a +4.4% mean improvement of the intersection over the union on COCO (with 232 labeled images), +3.1% on Pascal VOC (with 92 labels), +5.9% on ADE20 (with 158 labels) and +1.8% on Cityscapes (with 100 labels), demonstrating better performance under 1% supervision on four benchmark datasets. Our results show that language-guided segmentation closes the label efficiency gap and unlocks new levels of fine-grained, instance-aware generalization.

</details>


### [9] [Mapping Farmed Landscapes from Remote Sensing](https://arxiv.org/abs/2506.13993)
*Michelangelo Conserva,Alex Wilson,Charlotte Stanton,Vishal Batchu,Varun Gulshan*

Main category: cs.CV

TL;DR: Farmscapes是一种高分辨率（25厘米）的农村景观特征地图，覆盖英格兰大部分地区，通过深度学习模型生成，为生态学家和政策制定者提供开放工具。


<details>
  <summary>Details</summary>
Motivation: 全球生物多样性目标需要详细的生态地图支持，但目前缺乏大规模、高分辨率的生态地图。

Method: 使用深度学习分割模型，基于942个手动标注的航空影像图块训练，生成农村景观特征地图。

Result: 模型在识别关键栖息地（如林地96%、农田95%）和线性特征（如树篱72%）方面表现优异。

Conclusion: Farmscapes为栖息地恢复、生物多样性监测和景观连通性分析提供了数据支持。

Abstract: Effective management of agricultural landscapes is critical for meeting global biodiversity targets, but efforts are hampered by the absence of detailed, large-scale ecological maps. To address this, we introduce Farmscapes, the first large-scale (covering most of England), high-resolution (25cm) map of rural landscape features, including ecologically vital elements like hedgerows, woodlands, and stone walls. This map was generated using a deep learning segmentation model trained on a novel, dataset of 942 manually annotated tiles derived from aerial imagery. Our model accurately identifies key habitats, achieving high f1-scores for woodland (96\%) and farmed land (95\%), and demonstrates strong capability in segmenting linear features, with an F1-score of 72\% for hedgerows. By releasing the England-wide map on Google Earth Engine, we provide a powerful, open-access tool for ecologists and policymakers. This work enables data-driven planning for habitat restoration, supports the monitoring of initiatives like the EU Biodiversity Strategy, and lays the foundation for advanced analysis of landscape connectivity.

</details>


### [10] [FindMeIfYouCan: Bringing Open Set metrics to $\textit{near} $, $ \textit{far} $ and $\textit{farther}$ Out-of-Distribution Object Detection](https://arxiv.org/abs/2506.14008)
*Daniel Montoya,Aymen Bouguerra,Alexandra Gomez-Villa,Fabio Arnez*

Main category: cs.CV

TL;DR: 论文指出当前OOD-OD评估协议存在问题，并提出新基准和指标以改进未知物体检测。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测方法假设测试类别与训练一致，但实际应用中需检测未知物体，尤其是安全关键领域。当前OOD-OD评估协议存在缺陷，可能导致对未知物体的忽视和过度自信。

Method: 手动整理并扩展现有基准，利用语义相似性创建新评估分类（near、far、farther），并引入开放集社区的指标。

Result: 语义和视觉接近的OOD物体更易定位但易与ID物体混淆；far和farther物体定位更难但不易误判为ID物体。

Conclusion: 新评估协议和指标提供了更全面的性能分析，揭示了OOD检测中的关键挑战和潜在改进方向。

Abstract: State-of-the-art Object Detection (OD) methods predominantly operate under a closed-world assumption, where test-time categories match those encountered during training. However, detecting and localizing unknown objects is crucial for safety-critical applications in domains such as autonomous driving and medical imaging. Recently, Out-Of-Distribution (OOD) detection has emerged as a vital research direction for OD, focusing on identifying incorrect predictions typically associated with unknown objects. This paper shows that the current evaluation protocol for OOD-OD violates the assumption of non-overlapping objects with respect to the In-Distribution (ID) datasets, and obscures crucial situations such as ignoring unknown objects, potentially leading to overconfidence in deployment scenarios where truly novel objects might be encountered. To address these limitations, we manually curate, and enrich the existing benchmark by exploiting semantic similarity to create new evaluation splits categorized as $\textit{near}$, $\textit{far}$, and $\textit{farther}$ from ID distributions. Additionally, we incorporate established metrics from the Open Set community, providing deeper insights into how effectively methods detect unknowns, when they ignore them, and when they mistakenly classify OOD objects as ID. Our comprehensive evaluation demonstrates that semantically and visually close OOD objects are easier to localize than far ones, but are also more easily confounded with ID objects. $\textit{Far}$ and $\textit{farther}$ objects are harder to localize but less prone to be taken for an ID object.

</details>


### [11] [Disentangling 3D from Large Vision-Language Models for Controlled Portrait Generation](https://arxiv.org/abs/2506.14015)
*Nick Yiwen Huang,Akin Caliskan,Berkay Kicanaoglu,James Tompkin,Hyeongwoo Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种从大型视觉语言模型（LVLM）中解耦3D信息的方法，用于生成可控的3D肖像，支持文本和几何控制。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在生成3D肖像时无法同时实现文本和3D几何控制的问题，并克服LVLM嵌入空间中的噪声问题。

Method: 使用预训练的LVLM（如CLIP）和3D可变形模型（FLAME），通过规范化技术和Jacobian正则化来解耦噪声和特征。

Result: 生成的3D肖像在文本和3D控制上表现一致，且质量更高、多样性更强。

Conclusion: 该方法为创作者提供了一种无需大规模标注数据或训练大型模型即可控制3D生成的解决方案。

Abstract: We consider the problem of disentangling 3D from large vision-language models, which we show on generative 3D portraits. This allows free-form text control of appearance attributes like age, hair style, and glasses, and 3D geometry control of face expression and camera pose. In this setting, we assume we use a pre-trained large vision-language model (LVLM; CLIP) to generate from a smaller 2D dataset with no additional paired labels and with a pre-defined 3D morphable model (FLAME). First, we disentangle using canonicalization to a 2D reference frame from a deformable neural 3D triplane representation. But another form of entanglement arises from the significant noise in the LVLM's embedding space that describes irrelevant features. This damages output quality and diversity, but we overcome this with a Jacobian regularization that can be computed efficiently with a stochastic approximator. Compared to existing methods, our approach produces portraits with added text and 3D control, where portraits remain consistent when either control is changed. Broadly, this approach lets creators control 3D generators on their own 2D face data without needing resources to label large data or train large models.

</details>


### [12] [SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval and Iterative Refinement](https://arxiv.org/abs/2506.14035)
*Chelsi Jain,Yiran Wu,Yifan Zeng,Jiale Liu,S hengyu Dai,Zhenwen Shao,Qingyun Wu,Huazheng Wang*

Main category: cs.CV

TL;DR: SimpleDoc是一个轻量级但强大的DocVQA框架，通过双线索检索器提升证据页收集效率，并在多个数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: DocVQA任务需要处理多模态信息（如图像和表格），现有方法虽然采用RAG流程，但仍有改进空间。SimpleDoc旨在通过更高效的检索和生成机制提升性能。

Method: SimpleDoc采用双线索检索器，先通过嵌入相似性检索候选页，再基于页面摘要过滤和重排序。单VLM推理代理迭代调用检索器，逐步将相关页加入工作内存以回答问题。

Result: SimpleDoc在4个DocVQA数据集上平均比基线方法提升3.2%，且检索页数更少。

Conclusion: SimpleDoc通过轻量级设计和高效检索机制，显著提升了DocVQA任务的性能，代码已开源。

Abstract: Document Visual Question Answering (DocVQA) is a practical yet challenging task, which is to ask questions based on documents while referring to multiple pages and different modalities of information, e.g, images and tables. To handle multi-modality, recent methods follow a similar Retrieval Augmented Generation (RAG) pipeline, but utilize Visual Language Models (VLMs) based embedding model to embed and retrieve relevant pages as images, and generate answers with VLMs that can accept an image as input. In this paper, we introduce SimpleDoc, a lightweight yet powerful retrieval - augmented framework for DocVQA. It boosts evidence page gathering by first retrieving candidates through embedding similarity and then filtering and re-ranking these candidates based on page summaries. A single VLM-based reasoner agent repeatedly invokes this dual-cue retriever, iteratively pulling fresh pages into a working memory until the question is confidently answered. SimpleDoc outperforms previous baselines by 3.2% on average on 4 DocVQA datasets with much fewer pages retrieved. Our code is available at https://github.com/ag2ai/SimpleDoc.

</details>


### [13] [Image Segmentation with Large Language Models: A Survey with Perspectives for Intelligent Transportation Systems](https://arxiv.org/abs/2506.14096)
*Sanjeda Akter,Ibne Farabi Shihab,Anuj Sharma*

Main category: cs.CV

TL;DR: 本文综述了大型语言模型（LLMs）与计算机视觉结合在图像分割中的应用，特别是在智能交通系统（ITS）中的潜力、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统需要精确的场景理解以确保安全和效率，LLMs与计算机视觉的结合为此提供了新的可能性。

Method: 系统回顾了LLM增强图像分割的方法，基于提示机制和核心架构对现有方法进行了分类。

Result: 这些创新可以提升自动驾驶、交通监控和基础设施维护中的道路场景理解能力。

Conclusion: 未来需解决实时性和安全性等挑战，并强调可解释、以人为本的AI是下一代交通系统成功部署的关键。

Abstract: The integration of Large Language Models (LLMs) with computer vision is profoundly transforming perception tasks like image segmentation. For intelligent transportation systems (ITS), where accurate scene understanding is critical for safety and efficiency, this new paradigm offers unprecedented capabilities. This survey systematically reviews the emerging field of LLM-augmented image segmentation, focusing on its applications, challenges, and future directions within ITS. We provide a taxonomy of current approaches based on their prompting mechanisms and core architectures, and we highlight how these innovations can enhance road scene understanding for autonomous driving, traffic monitoring, and infrastructure maintenance. Finally, we identify key challenges, including real-time performance and safety-critical reliability, and outline a perspective centered on explainable, human-centric AI as a prerequisite for the successful deployment of this technology in next-generation transportation systems.

</details>


### [14] [FADPNet: Frequency-Aware Dual-Path Network for Face Super-Resolution](https://arxiv.org/abs/2506.14121)
*Siyu Xu,Wenjie Li,Guangwei Gao,Jian Yang,Guo-Jun Qi,Chia-Wen Lin*

Main category: cs.CV

TL;DR: 提出了一种频率感知双路径网络（FADPNet），通过分别处理低频和高频面部特征，优化计算资源分配，提升面部超分辨率性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法对所有面部像素一视同仁，导致计算资源分配不佳和性能下降。CNN对高频特征敏感，而Mamba擅长低频特征且复杂度更低。

Method: 将面部特征分解为低频和高频，分别通过Mamba低频增强块（LFEB）和CNN高频细化模块（HFR）处理。

Result: 在面部超分辨率质量和模型效率之间取得优异平衡，性能优于现有方法。

Conclusion: FADPNet通过频率感知的双路径设计，显著提升了面部超分辨率的效果和效率。

Abstract: Face super-resolution (FSR) under limited computational costs remains an open problem. Existing approaches typically treat all facial pixels equally, resulting in suboptimal allocation of computational resources and degraded FSR performance. CNN is relatively sensitive to high-frequency facial features, such as component contours and facial outlines. Meanwhile, Mamba excels at capturing low-frequency features like facial color and fine-grained texture, and does so with lower complexity than Transformers. Motivated by these observations, we propose FADPNet, a Frequency-Aware Dual-Path Network that decomposes facial features into low- and high-frequency components and processes them via dedicated branches. For low-frequency regions, we introduce a Mamba-based Low-Frequency Enhancement Block (LFEB), which combines state-space attention with squeeze-and-excitation operations to extract low-frequency global interactions and emphasize informative channels. For high-frequency regions, we design a CNN-based Deep Position-Aware Attention (DPA) module to enhance spatially-dependent structural details, complemented by a lightweight High-Frequency Refinement (HFR) module that further refines frequency-specific representations. Through the above designs, our method achieves an excellent balance between FSR quality and model efficiency, outperforming existing approaches.

</details>


### [15] [KDMOS:Knowledge Distillation for Motion Segmentation](https://arxiv.org/abs/2506.14130)
*Chunyu Cao,Jintao Cheng,Zeyu Chen,Linfan Zhan,Rui Fan,Zhijian He,Xiaoyu Tang*

Main category: cs.CV

TL;DR: 提出了一种基于logits的知识蒸馏框架（KDMOS），用于运动目标分割（MOS），通过BEV投影模型（学生）和非投影模型（教师）的结合，提升精度并保持实时性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在精度和实时性之间难以平衡，MOS对自动驾驶任务至关重要，需改进性能。

Method: 采用BEV投影模型作为学生，非投影模型作为教师，解耦运动与非运动类别并应用定制蒸馏策略，引入动态上采样和优化网络架构。

Result: 在SemanticKITTI-MOS数据集上实现78.8%的IoU，参数减少7.69%，在Apollo数据集上表现竞争性。

Conclusion: KDMOS框架显著提升了MOS的精度和效率，适用于自动驾驶场景。

Abstract: Motion Object Segmentation (MOS) is crucial for autonomous driving, as it enhances localization, path planning, map construction, scene flow estimation, and future state prediction. While existing methods achieve strong performance, balancing accuracy and real-time inference remains a challenge. To address this, we propose a logits-based knowledge distillation framework for MOS, aiming to improve accuracy while maintaining real-time efficiency. Specifically, we adopt a Bird's Eye View (BEV) projection-based model as the student and a non-projection model as the teacher. To handle the severe imbalance between moving and non-moving classes, we decouple them and apply tailored distillation strategies, allowing the teacher model to better learn key motion-related features. This approach significantly reduces false positives and false negatives. Additionally, we introduce dynamic upsampling, optimize the network architecture, and achieve a 7.69% reduction in parameter count, mitigating overfitting. Our method achieves a notable IoU of 78.8% on the hidden test set of the SemanticKITTI-MOS dataset and delivers competitive results on the Apollo dataset. The KDMOS implementation is available at https://github.com/SCNU-RISLAB/KDMOS.

</details>


### [16] [Interpreting Biomedical VLMs on High-Imbalance Out-of-Distributions: An Insight into BiomedCLIP on Radiology](https://arxiv.org/abs/2506.14136)
*Nafiz Sadman,Farhana Zulkernine,Benjamin Kwan*

Main category: cs.CV

TL;DR: 研究分析了BiomedCLIP在医学影像分类中的表现，发现零样本推理效果差，全微调能改善分类，线性探测能检测重叠特征。


<details>
  <summary>Details</summary>
Motivation: 探索BiomedCLIP的嵌入空间并量化其在高度不平衡、分布外多标签医学数据集上的局限性。

Method: 在IU-xray数据集上评估BiomedCLIP的零样本推理、全微调和线性探测三种分类方式。

Result: 零样本推理表现差，全微调改善分类，线性探测检测重叠特征。

Conclusion: 需谨慎调整模型以提高实际应用中的可靠性和适用性。

Abstract: In this paper, we construct two research objectives: i) explore the learned embedding space of BiomedCLIP, an open-source large vision language model, to analyse meaningful class separations, and ii) quantify the limitations of BiomedCLIP when applied to a highly imbalanced, out-of-distribution multi-label medical dataset. We experiment on IU-xray dataset, which exhibits the aforementioned criteria, and evaluate BiomedCLIP in classifying images (radiographs) in three contexts: zero-shot inference, full finetuning, and linear probing. The results show that the model under zero-shot settings over-predicts all labels, leading to poor precision and inter-class separability. Full fine-tuning improves classification of distinct diseases, while linear probing detects overlapping features. We demonstrate visual understanding of the model using Grad-CAM heatmaps and compare with 15 annotations by a radiologist. We highlight the need for careful adaptations of the models to foster reliability and applicability in a real-world setting. The code for the experiments in this work is available and maintained on GitHub.

</details>


### [17] [RadFabric: Agentic AI System with Reasoning Capability for Radiology](https://arxiv.org/abs/2506.14142)
*Wenting Chen,Yi Dong,Zhaojun Ding,Yucheng Shi,Yifan Zhou,Fang Zeng,Yijun Luo,Tianyu Lin,Yihang Su,Yichen Wu,Kai Zhang,Zhen Xiang,Tianming Liu,Ninghao Liu,Lichao Sun,Yixuan Yuan,Xiang Li*

Main category: cs.CV

TL;DR: RadFabric是一个多模态、多代理的CXR分析框架，通过整合视觉和文本推理，显著提升诊断准确性和病理覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 当前自动化CXR诊断系统在病理覆盖、诊断准确性和多模态推理方面存在不足，RadFabric旨在解决这些问题。

Method: 基于Model Context Protocol (MCP)，RadFabric结合了病理检测代理、解剖解释代理和推理代理，通过多模态模型整合视觉、解剖和临床数据。

Result: RadFabric在骨折检测上达到1.000准确率，整体诊断准确率0.799，远超传统系统（0.229至0.527）。

Conclusion: RadFabric通过跨模态特征对齐和偏好驱动推理，推动了透明、解剖精确且临床可操作的CXR分析。

Abstract: Chest X ray (CXR) imaging remains a critical diagnostic tool for thoracic conditions, but current automated systems face limitations in pathology coverage, diagnostic accuracy, and integration of visual and textual reasoning. To address these gaps, we propose RadFabric, a multi agent, multimodal reasoning framework that unifies visual and textual analysis for comprehensive CXR interpretation. RadFabric is built on the Model Context Protocol (MCP), enabling modularity, interoperability, and scalability for seamless integration of new diagnostic agents. The system employs specialized CXR agents for pathology detection, an Anatomical Interpretation Agent to map visual findings to precise anatomical structures, and a Reasoning Agent powered by large multimodal reasoning models to synthesize visual, anatomical, and clinical data into transparent and evidence based diagnoses. RadFabric achieves significant performance improvements, with near-perfect detection of challenging pathologies like fractures (1.000 accuracy) and superior overall diagnostic accuracy (0.799) compared to traditional systems (0.229 to 0.527). By integrating cross modal feature alignment and preference-driven reasoning, RadFabric advances AI-driven radiology toward transparent, anatomically precise, and clinically actionable CXR analysis.

</details>


### [18] [SceneAware: Scene-Constrained Pedestrian Trajectory Prediction with LLM-Guided Walkability](https://arxiv.org/abs/2506.14144)
*Juho Bai,Inwook Shim*

Main category: cs.CV

TL;DR: 论文提出SceneAware框架，通过结合场景理解提升行人轨迹预测精度，优于现有方法50%以上。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注行人社交互动，忽略了环境对行人轨迹的显著影响。

Method: 结合Vision Transformer场景编码器和多模态大语言模型生成可通行掩码，通过Transformer编码时空动态与空间约束，并引入碰撞惩罚机制。

Result: 在ETH/UCY数据集上表现优异，性能提升超50%，且对不同类型行人运动均表现稳定。

Conclusion: 显式利用场景信息能有效提升预测精度，SceneAware方法可靠且高效。

Abstract: Accurate prediction of pedestrian trajectories is essential for applications in robotics and surveillance systems. While existing approaches primarily focus on social interactions between pedestrians, they often overlook the rich environmental context that significantly shapes human movement patterns. In this paper, we propose SceneAware, a novel framework that explicitly incorporates scene understanding to enhance trajectory prediction accuracy. Our method leverages a Vision Transformer~(ViT) scene encoder to process environmental context from static scene images, while Multi-modal Large Language Models~(MLLMs) generate binary walkability masks that distinguish between accessible and restricted areas during training. We combine a Transformer-based trajectory encoder with the ViT-based scene encoder, capturing both temporal dynamics and spatial constraints. The framework integrates collision penalty mechanisms that discourage predicted trajectories from violating physical boundaries, ensuring physically plausible predictions. SceneAware is implemented in both deterministic and stochastic variants. Comprehensive experiments on the ETH/UCY benchmark datasets show that our approach outperforms state-of-the-art methods, with more than 50\% improvement over previous models. Our analysis based on different trajectory categories shows that the model performs consistently well across various types of pedestrian movement. This highlights the importance of using explicit scene information and shows that our scene-aware approach is both effective and reliable in generating accurate and physically plausible predictions. Code is available at: https://github.com/juho127/SceneAware.

</details>


### [19] [VideoMAR: Autoregressive Video Generatio with Continuous Tokens](https://arxiv.org/abs/2506.14168)
*Hu Yu,Biao Gong,Hangjie Yuan,DanDan Zheng,Weilong Chai,Jingdong Chen,Kecheng Zheng,Feng Zhao*

Main category: cs.CV

TL;DR: VideoMAR是一种高效的自回归图像到视频生成模型，结合了时间因果性和空间双向性，通过课程学习和渐进分辨率训练解决了长序列建模问题，并在性能和资源效率上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索基于掩码的自回归模型在视频生成中的潜力，解决长序列建模的高成本和难度问题。

Method: 提出VideoMAR模型，结合时间因果性和空间双向性，使用下一帧扩散损失、课程学习和渐进分辨率训练，并采用渐进温度策略。

Result: 在VBench-I2V基准测试中，VideoMAR在性能上超越Cosmos I2V，同时参数、训练数据和GPU资源需求显著降低。

Conclusion: VideoMAR展示了自回归模型在视频生成中的高效性和潜力，为未来研究提供了新方向。

Abstract: Masked-based autoregressive models have demonstrated promising image generation capability in continuous space. However, their potential for video generation remains under-explored. In this paper, we propose \textbf{VideoMAR}, a concise and efficient decoder-only autoregressive image-to-video model with continuous tokens, composing temporal frame-by-frame and spatial masked generation. We first identify temporal causality and spatial bi-directionality as the first principle of video AR models, and propose the next-frame diffusion loss for the integration of mask and video generation. Besides, the huge cost and difficulty of long sequence autoregressive modeling is a basic but crucial issue. To this end, we propose the temporal short-to-long curriculum learning and spatial progressive resolution training, and employ progressive temperature strategy at inference time to mitigate the accumulation error. Furthermore, VideoMAR replicates several unique capacities of language models to video generation. It inherently bears high efficiency due to simultaneous temporal-wise KV cache and spatial-wise parallel generation, and presents the capacity of spatial and temporal extrapolation via 3D rotary embeddings. On the VBench-I2V benchmark, VideoMAR surpasses the previous state-of-the-art (Cosmos I2V) while requiring significantly fewer parameters ($9.3\%$), training data ($0.5\%$), and GPU resources ($0.2\%$).

</details>


### [20] [A multi-stage augmented multimodal interaction network for fish feeding intensity quantification](https://arxiv.org/abs/2506.14170)
*Shulong Zhang,Mingyuan Yao,Jiayin Zhao,Xiao Liu,Haihua Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种多阶段增强多模态交互网络（MAINet），用于量化鱼类摄食强度，通过特征提取、模态交互增强和证据推理决策，显著提高了模型的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前研究在模态选择、特征提取与融合以及决策推断方面存在局限性，限制了多模态融合模型的准确性、适用性和可靠性，因此需要一种更有效的方法来量化鱼类摄食强度。

Method: 提出MAINet，包括通用特征提取框架、辅助模态增强主模态机制（ARPM）和证据推理（ER）规则，分别用于特征提取、模态交互增强和决策融合。

Result: MAINet在准确率、精确率、召回率和F1分数上均达到96.7%以上，性能显著优于其他对比模型。

Conclusion: MAINet通过改进策略提高了模型的鲁棒性和特征利用效率，有效提升了鱼类摄食强度量化结果的准确性。

Abstract: In recirculating aquaculture systems, accurate and effective assessment of fish feeding intensity is crucial for reducing feed costs and calculating optimal feeding times. However, current studies have limitations in modality selection, feature extraction and fusion, and co-inference for decision making, which restrict further improvement in the accuracy, applicability and reliability of multimodal fusion models. To address this problem, this study proposes a Multi-stage Augmented Multimodal Interaction Network (MAINet) for quantifying fish feeding intensity. Firstly, a general feature extraction framework is proposed to efficiently extract feature information from input image, audio and water wave datas. Second, an Auxiliary-modality Reinforcement Primary-modality Mechanism (ARPM) is designed for inter-modal interaction and generate enhanced features, which consists of a Channel Attention Fusion Network (CAFN) and a Dual-mode Attention Fusion Network (DAFN). Finally, an Evidence Reasoning (ER) rule is introduced to fuse the output results of each modality and make decisions, thereby completing the quantification of fish feeding intensity. The experimental results show that the constructed MAINet reaches 96.76%, 96.78%, 96.79% and 96.79% in accuracy, precision, recall and F1-Score respectively, and its performance is significantly higher than the comparison models. Compared with models that adopt single-modality, dual-modality fusion and different decision-making fusion methods, it also has obvious advantages. Meanwhile, the ablation experiments further verified the key role of the proposed improvement strategy in improving the robustness and feature utilization efficiency of model, which can effectively improve the accuracy of the quantitative results of fish feeding intensity.

</details>


### [21] [One-Shot Neural Architecture Search with Network Similarity Directed Initialization for Pathological Image Classification](https://arxiv.org/abs/2506.14176)
*Renao Yan*

Main category: cs.CV

TL;DR: 提出了一种基于网络相似性引导初始化（NSDI）的策略，结合领域自适应的一键式神经架构搜索（NAS），优化病理图像分析的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接将计算机视觉模型应用于医学任务，忽略了病理图像的独特性，导致计算效率低下。

Method: 提出NSDI策略提升NAS稳定性，并引入领域自适应处理病理数据集中的染色和语义尺度变化。

Result: 在BRACS数据集上实验表明，该方法分类性能和特征定位优于现有方法。

Conclusion: 该方法显著提升了病理图像分析的效率和临床相关性。

Abstract: Deep learning-based pathological image analysis presents unique challenges due to the practical constraints of network design. Most existing methods apply computer vision models directly to medical tasks, neglecting the distinct characteristics of pathological images. This mismatch often leads to computational inefficiencies, particularly in edge-computing scenarios. To address this, we propose a novel Network Similarity Directed Initialization (NSDI) strategy to improve the stability of neural architecture search (NAS). Furthermore, we introduce domain adaptation into one-shot NAS to better handle variations in staining and semantic scale across pathology datasets. Experiments on the BRACS dataset demonstrate that our method outperforms existing approaches, delivering both superior classification performance and clinically relevant feature localization.

</details>


### [22] [Meta-SurDiff: Classification Diffusion Model Optimized by Meta Learning is Reliable for Online Surgical Phase Recognition](https://arxiv.org/abs/2506.14181)
*Yufei Li,Jirui Wu,Long Tian,Liming Wang,Xiaonan Liu,Zijun Liu,Xiyang Liu*

Main category: cs.CV

TL;DR: 论文提出了一种基于元学习优化的分类扩散模型（Meta-SurDiff），用于解决手术视频中帧模糊和相位分布不平衡带来的不确定性，以实现可靠的在线手术阶段识别。


<details>
  <summary>Details</summary>
Motivation: 在线手术阶段识别因其与人类生命健康相关的潜在应用而备受关注。现有深度模型虽能捕捉手术视频的长期依赖关系，但未充分建模视频中的不确定性，这对可靠识别至关重要。

Method: 提出Meta-SurDiff模型，结合深度生成模型和元学习，通过分类扩散模型评估模糊帧的置信度，并利用元学习目标优化扩散模型以增强分类边界鲁棒性。

Result: 在五个广泛使用的数据集（Cholec80、AutoLaparo、M2Cai16、OphNet、NurViD）上进行了实验，验证了Meta-SurDiff的有效性。

Conclusion: Meta-SurDiff通过建模不确定性，显著提升了在线手术阶段识别的可靠性，适用于多种手术场景。

Abstract: Online surgical phase recognition has drawn great attention most recently due to its potential downstream applications closely related to human life and health. Despite deep models have made significant advances in capturing the discriminative long-term dependency of surgical videos to achieve improved recognition, they rarely account for exploring and modeling the uncertainty in surgical videos, which should be crucial for reliable online surgical phase recognition. We categorize the sources of uncertainty into two types, frame ambiguity in videos and unbalanced distribution among surgical phases, which are inevitable in surgical videos. To address this pivot issue, we introduce a meta-learning-optimized classification diffusion model (Meta-SurDiff), to take full advantage of the deep generative model and meta-learning in achieving precise frame-level distribution estimation for reliable online surgical phase recognition. For coarse recognition caused by ambiguous video frames, we employ a classification diffusion model to assess the confidence of recognition results at a finer-grained frame-level instance. For coarse recognition caused by unbalanced phase distribution, we use a meta-learning based objective to learn the diffusion model, thus enhancing the robustness of classification boundaries for different surgical phases.We establish effectiveness of Meta-SurDiff in online surgical phase recognition through extensive experiments on five widely used datasets using more than four practical metrics. The datasets include Cholec80, AutoLaparo, M2Cai16, OphNet, and NurViD, where OphNet comes from ophthalmic surgeries, NurViD is the daily care dataset, while the others come from laparoscopic surgeries. We will release the code upon acceptance.

</details>


### [23] [Egocentric Human-Object Interaction Detection: A New Benchmark and Method](https://arxiv.org/abs/2506.14189)
*Kunyuan Deng,Yi Wang,Lap-Pui Chau*

Main category: cs.CV

TL;DR: 本文提出了Ego-HOIBench数据集，用于推动自我中心视角下的人-物交互（Ego-HOI）检测研究，并提出了一种轻量高效的HGIR方案，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人-物交互（HOI）检测方法主要关注第三人称视角，忽略了更直观的自我中心视角（Ego-HOI），因此需要新的数据集和方法来填补这一空白。

Method: 提出了Ego-HOIBench数据集，包含27K张自我中心视角图像，并标注了手-动词-物体三元组。此外，提出了一种基于手部几何和交互性优化的HGIR方案，利用手部姿态和几何信息优化交互特征。

Result: HGIR方案显著提升了Ego-HOI检测能力，并在Ego-HOIBench上实现了最先进的性能。

Conclusion: Ego-HOIBench为Ego-HOI研究提供了新基准，HGIR方案轻量高效，可轻松应用于现有HOI基线方法。

Abstract: Understanding the interaction between humans and objects has gained much attention in recent years. Existing human-object interaction (HOI) detection methods mainly focus on the third-person perspectives, overlooking a more intuitive way from the egocentric view of HOI, namely Ego-HOI. This paper introduces an Ego-HOIBench, a new dataset to promote the benchmarking and development of Ego-HOI detection. Our Ego-HOIBench comprises more than 27K egocentric images with high-quality hand-verb-object triplet annotations across 123 fine-grained interaction categories and locations, covering a rich diversity of scenarios, object types, and hand configurations in daily activities. In addition, we explore and adapt third-person HOI detection methods to Ego-HOIBench and illustrate the challenges of hand-occluded objects and the complexity of single- and two-hand interactions. To build a new baseline, we propose a Hand Geometry and Interactivity Refinement (HGIR) scheme, which leverages hand pose and geometric information as valuable cues for interpreting interactions. Specifically, the HGIR scheme explicitly extracts global hand geometric features from the estimated hand pose proposals and refines the interaction-specific features using pose-interaction attention. This scheme enables the model to obtain a robust and powerful interaction representation, significantly improving the Ego-HOI detection capability. Our approach is lightweight and effective, and it can be easily applied to HOI baselines in a plug-and-play manner to achieve state-of-the-art results on Ego-HOIBench. Our project is available at: https://dengkunyuan.github.io/EgoHOIBench/

</details>


### [24] [HRGS: Hierarchical Gaussian Splatting for Memory-Efficient High-Resolution 3D Reconstruction](https://arxiv.org/abs/2506.14229)
*Changbai Li,Haodong Zhu,Hanlin Chen,Juan Zhang,Tongfei Chen,Shuo Yang,Shuwei Shao,Wenhao Dong,Baochang Zhang*

Main category: cs.CV

TL;DR: HRGS是一种内存高效的分层块级优化框架，解决了3DGS在高分辨率场景中的内存扩展问题。


<details>
  <summary>Details</summary>
Motivation: 3DGS在实时3D场景重建中取得了进展，但在高分辨率场景下存在内存扩展问题。

Method: 首先生成低分辨率的全局粗高斯表示，然后分区细化每个块，引入重要性驱动的高斯修剪和法线先验。

Result: 在三个基准测试中，HRGS在高分辨率新视角合成和表面重建任务中达到了最先进的性能。

Conclusion: HRGS在内存受限的情况下实现了高质量的高分辨率3D场景重建。

Abstract: 3D Gaussian Splatting (3DGS) has made significant strides in real-time 3D scene reconstruction, but faces memory scalability issues in high-resolution scenarios. To address this, we propose Hierarchical Gaussian Splatting (HRGS), a memory-efficient framework with hierarchical block-level optimization. First, we generate a global, coarse Gaussian representation from low-resolution data. Then, we partition the scene into multiple blocks, refining each block with high-resolution data. The partitioning involves two steps: Gaussian partitioning, where irregular scenes are normalized into a bounded cubic space with a uniform grid for task distribution, and training data partitioning, where only relevant observations are retained for each block. By guiding block refinement with the coarse Gaussian prior, we ensure seamless Gaussian fusion across adjacent blocks. To reduce computational demands, we introduce Importance-Driven Gaussian Pruning (IDGP), which computes importance scores for each Gaussian and removes those with minimal contribution, speeding up convergence and reducing memory usage. Additionally, we incorporate normal priors from a pretrained model to enhance surface reconstruction quality. Our method enables high-quality, high-resolution 3D scene reconstruction even under memory constraints. Extensive experiments on three benchmarks show that HRGS achieves state-of-the-art performance in high-resolution novel view synthesis (NVS) and surface reconstruction tasks.

</details>


### [25] [Unified Representation Space for 3D Visual Grounding](https://arxiv.org/abs/2506.14238)
*Yinuo Zheng,Lipeng Gu,Honghua Chen,Liangliang Nan,Mingqiang Wei*

Main category: cs.CV

TL;DR: UniSpace-3D提出了一种统一表示空间的方法，通过CLIP模型和多模态对比学习，显著提升了3D视觉定位任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预训练的视觉和文本编码器，导致模态间几何和语义差异，影响定位和分类准确性。

Method: 1) 统一表示编码器；2) 多模态对比学习模块；3) 语言引导的查询选择模块。

Result: 在ScanRefer和Nr3D/Sr3D数据集上性能提升至少2.24%。

Conclusion: UniSpace-3D有效弥合了视觉与文本模态的差距，提升了3D视觉定位的准确性。

Abstract: 3D visual grounding (3DVG) is a critical task in scene understanding that aims to identify objects in 3D scenes based on text descriptions. However, existing methods rely on separately pre-trained vision and text encoders, resulting in a significant gap between the two modalities in terms of spatial geometry and semantic categories. This discrepancy often causes errors in object positioning and classification. The paper proposes UniSpace-3D, which innovatively introduces a unified representation space for 3DVG, effectively bridging the gap between visual and textual features. Specifically, UniSpace-3D incorporates three innovative designs: i) a unified representation encoder that leverages the pre-trained CLIP model to map visual and textual features into a unified representation space, effectively bridging the gap between the two modalities; ii) a multi-modal contrastive learning module that further reduces the modality gap; iii) a language-guided query selection module that utilizes the positional and semantic information to identify object candidate points aligned with textual descriptions. Extensive experiments demonstrate that UniSpace-3D outperforms baseline models by at least 2.24% on the ScanRefer and Nr3D/Sr3D datasets. The code will be made available upon acceptance of the paper.

</details>


### [26] [Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition](https://arxiv.org/abs/2506.14243)
*Xiaohui Jiang,Haijiang Zhu,Chadei Li,Fulin Tang,Ning An*

Main category: cs.CV

TL;DR: 提出了一种基于弹性点的密度无关几何推理框架，解决了LiDAR地点识别中的点云密度不一致和单层几何抽象问题，实现了高性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手工特征提取，面临点云密度不一致和单层几何抽象导致的描述符不稳定和表示脆弱性问题。

Method: 引入弹性点的隐式3D表示，生成均匀分布的点云，并从中提取占用网格和法向量信息，融合鸟瞰图和3D段几何信息生成描述符。

Result: 在多个数据集上实验表明，该方法达到最先进性能，并在准确性、运行时间和内存优化之间取得平衡。

Conclusion: 提出的框架在LiDAR地点识别中表现出色，具有鲁棒性和可扩展性，未来将开源代码。

Abstract: LiDAR-based place recognition serves as a crucial enabler for long-term autonomy in robotics and autonomous driving systems. Yet, prevailing methodologies relying on handcrafted feature extraction face dual challenges: (1) Inconsistent point cloud density, induced by ego-motion dynamics and environmental disturbances during repeated traversals, leads to descriptor instability, and (2) Representation fragility stems from reliance on single-level geometric abstractions that lack discriminative power in structurally complex scenarios. To address these limitations, we propose a novel framework that redefines 3D place recognition through density-agnostic geometric reasoning. Specifically, we introduce an implicit 3D representation based on elastic points, which is immune to the interference of original scene point cloud density and achieves the characteristic of uniform distribution. Subsequently, we derive the occupancy grid and normal vector information of the scene from this implicit representation. Finally, with the aid of these two types of information, we obtain descriptors that fuse geometric information from both bird's-eye view (capturing macro-level spatial layouts) and 3D segment (encoding micro-scale surface geometries) perspectives. We conducted extensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT) across diverse environments. The experimental results demonstrate that our method achieves state-of-the-art performance. Moreover, our approach strikes an optimal balance between accuracy, runtime, and memory optimization for historical maps, showcasing excellent Resilient and scalability. Our code will be open-sourced in the future.

</details>


### [27] [synth-dacl: Does Synthetic Defect Data Enhance Segmentation Accuracy and Robustness for Real-World Bridge Inspections?](https://arxiv.org/abs/2506.14255)
*Johannes Flotzinger,Fabian Deuser,Achref Jaziri,Heiko Neumann,Norbert Oswald,Visvanathan Ramesh,Thomas Braml*

Main category: cs.CV

TL;DR: 论文提出了一种基于合成数据的方法（synth-dacl）来改善桥梁视觉检测中缺陷分类的性能，解决了数据集不平衡问题，显著提升了模型在扰动测试集上的表现。


<details>
  <summary>Details</summary>
Motivation: 桥梁检测面临资源不足和数据集不平衡的挑战，尤其是细粒度缺陷（如裂缝和孔洞）的分类性能较差。

Method: 通过合成混凝土纹理数据（synth-dacl）扩展现有数据集dacl10k，平衡类别分布并增强模型鲁棒性。

Result: 结合合成数据后，模型在15个扰动测试集上的性能显著提升，平均IoU、F1分数、召回率和精确度均提高了2%。

Conclusion: 合成数据扩展是解决桥梁检测数据集不平衡问题的有效方法，能显著提升模型性能。

Abstract: Adequate bridge inspection is increasingly challenging in many countries due to growing ailing stocks, compounded with a lack of staff and financial resources. Automating the key task of visual bridge inspection, classification of defects and building components on pixel level, improves efficiency, increases accuracy and enhances safety in the inspection process and resulting building assessment. Models overtaking this task must cope with an assortment of real-world conditions. They must be robust to variations in image quality, as well as background texture, as defects often appear on surfaces of diverse texture and degree of weathering. dacl10k is the largest and most diverse dataset for real-world concrete bridge inspections. However, the dataset exhibits class imbalance, which leads to notably poor model performance particularly when segmenting fine-grained classes such as cracks and cavities. This work introduces "synth-dacl", a compilation of three novel dataset extensions based on synthetic concrete textures. These extensions are designed to balance class distribution in dacl10k and enhance model performance, especially for crack and cavity segmentation. When incorporating the synth-dacl extensions, we observe substantial improvements in model robustness across 15 perturbed test sets. Notably, on the perturbed test set, a model trained on dacl10k combined with all synthetic extensions achieves a 2% increase in mean IoU, F1 score, Recall, and Precision compared to the same model trained solely on dacl10k.

</details>


### [28] [Comparison of Two Methods for Stationary Incident Detection Based on Background Image](https://arxiv.org/abs/2506.14256)
*Deepak Ghimire,Joonwhoan Lee*

Main category: cs.CV

TL;DR: 提出两种基于背景减除的静止物体检测方案，比较性能与计算复杂度，并通过NCC图像比对实现实时跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统方法多用于移动物体检测，本文旨在检测临时静止物体。

Method: 采用单背景和双背景两种方案，双背景通过不同学习率生成，结合NCC图像比对。

Result: 方法对部分遮挡、短暂完全遮挡和光照变化鲁棒，可实时运行。

Conclusion: 提出的双背景方案在检测性能与计算复杂度间取得平衡，适用于实际场景。

Abstract: In general, background subtraction-based methods are used to detect moving objects in visual tracking applications. In this paper, we employed a background subtraction-based scheme to detect the temporarily stationary objects. We proposed two schemes for stationary object detection, and we compare those in terms of detection performance and computational complexity. In the first approach, we used a single background, and in the second approach, we used dual backgrounds, generated with different learning rates, in order to detect temporarily stopped objects. Finally, we used normalized cross correlation (NCC) based image comparison to monitor and track the detected stationary object in a video scene. The proposed method is robust with partial occlusion, short-time fully occlusion, and illumination changes, and it can operate in real time.

</details>


### [29] [Exploring Non-contrastive Self-supervised Representation Learning for Image-based Profiling](https://arxiv.org/abs/2506.14265)
*Siran Dai,Qianqian Xu,Peisong Wen,Yang Liu,Qingming Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SSLProfiler的非对比自监督学习框架，专门用于细胞图像分析，解决了细胞图像与自然图像分布差异大以及多图像信息融合的挑战，并在CVPR 2025的挑战赛中获胜。


<details>
  <summary>Details</summary>
Motivation: 细胞图像分析在药物发现中至关重要，但现有自监督学习方法因细胞图像与自然图像分布差异大及多图像信息融合困难而表现不佳。

Method: 提出SSLProfiler框架，引入针对细胞图像的专用数据增强和表征后处理方法。

Result: SSLProfiler在CVPR 2025的Cell Line Transferability挑战赛中获胜。

Conclusion: SSLProfiler通过定制化方法成功解决了细胞图像分析中的关键挑战，展现了其在实际应用中的潜力。

Abstract: Image-based cell profiling aims to create informative representations of cell images. This technique is critical in drug discovery and has greatly advanced with recent improvements in computer vision. Inspired by recent developments in non-contrastive Self-Supervised Learning (SSL), this paper provides an initial exploration into training a generalizable feature extractor for cell images using such methods. However, there are two major challenges: 1) There is a large difference between the distributions of cell images and natural images, causing the view-generation process in existing SSL methods to fail; and 2) Unlike typical scenarios where each representation is based on a single image, cell profiling often involves multiple input images, making it difficult to effectively combine all available information. To overcome these challenges, we propose SSLProfiler, a non-contrastive SSL framework specifically designed for cell profiling. We introduce specialized data augmentation and representation post-processing methods tailored to cell images, which effectively address the issues mentioned above and result in a robust feature extractor. With these improvements, SSLProfiler won the Cell Line Transferability challenge at CVPR 2025.

</details>


### [30] [Leader360V: The Large-scale, Real-world 360 Video Dataset for Multi-task Learning in Diverse Environment](https://arxiv.org/abs/2506.14271)
*Weiming Zhang,Dingwen Xiao,Aobotao Dai,Yexin Liu,Tianbo Pan,Shiqi Wen,Lei Chen,Lin Wang*

Main category: cs.CV

TL;DR: Leader360V是首个大规模标注的真实世界360视频数据集，用于实例分割和跟踪，通过自动标注流程解决标注难题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 360视频的球形特性（如极区严重失真和内容不连续）导致标注成本高且复杂，缺乏大规模标注数据集阻碍了基础模型的应用。

Method: 设计自动标注流程，结合预训练的2D分割器和大型语言模型，分三阶段（初始标注、自动细化、人工修订）生成高质量标注。

Result: Leader360V数据集具有高场景多样性，标注流程有效，显著提升了360视频分割和跟踪的模型性能。

Conclusion: Leader360V为360场景理解提供了可扩展的数据集和标注方法，推动了相关应用的发展。

Abstract: 360 video captures the complete surrounding scenes with the ultra-large field of view of 360X180. This makes 360 scene understanding tasks, eg, segmentation and tracking, crucial for appications, such as autonomous driving, robotics. With the recent emergence of foundation models, the community is, however, impeded by the lack of large-scale, labelled real-world datasets. This is caused by the inherent spherical properties, eg, severe distortion in polar regions, and content discontinuities, rendering the annotation costly yet complex. This paper introduces Leader360V, the first large-scale, labeled real-world 360 video datasets for instance segmentation and tracking. Our datasets enjoy high scene diversity, ranging from indoor and urban settings to natural and dynamic outdoor scenes. To automate annotation, we design an automatic labeling pipeline, which subtly coordinates pre-trained 2D segmentors and large language models to facilitate the labeling. The pipeline operates in three novel stages. Specifically, in the Initial Annotation Phase, we introduce a Semantic- and Distortion-aware Refinement module, which combines object mask proposals from multiple 2D segmentors with LLM-verified semantic labels. These are then converted into mask prompts to guide SAM2 in generating distortion-aware masks for subsequent frames. In the Auto-Refine Annotation Phase, missing or incomplete regions are corrected either by applying the SDR again or resolving the discontinuities near the horizontal borders. The Manual Revision Phase finally incorporates LLMs and human annotators to further refine and validate the annotations. Extensive user studies and evaluations demonstrate the effectiveness of our labeling pipeline. Meanwhile, experiments confirm that Leader360V significantly enhances model performance for 360 video segmentation and tracking, paving the way for more scalable 360 scene understanding.

</details>


### [31] [FRIDU: Functional Map Refinement with Guided Image Diffusion](https://arxiv.org/abs/2506.14322)
*Avigail Cohen Rimon,Mirela Ben-Chen,Or Litany*

Main category: cs.CV

TL;DR: 提出了一种基于图像扩散模型的功能映射优化方法，通过训练模型直接生成准确的功能映射，并在推理时利用点映射作为指导。


<details>
  <summary>Details</summary>
Motivation: 现有功能映射优化方法效率不高，需要一种更高效且能直接处理功能映射的方法。

Method: 将功能映射视为2D图像，训练图像扩散模型在功能空间生成准确映射，推理时利用点映射作为指导。

Result: 该方法在功能映射优化上表现优异，与现有最优方法竞争。

Conclusion: 基于扩散模型的优化方法为功能映射处理提供了新途径。

Abstract: We propose a novel approach for refining a given correspondence map between two shapes. A correspondence map represented as a functional map, namely a change of basis matrix, can be additionally treated as a 2D image. With this perspective, we train an image diffusion model directly in the space of functional maps, enabling it to generate accurate maps conditioned on an inaccurate initial map. The training is done purely in the functional space, and thus is highly efficient. At inference time, we use the pointwise map corresponding to the current functional map as guidance during the diffusion process. The guidance can additionally encourage different functional map objectives, such as orthogonality and commutativity with the Laplace-Beltrami operator. We show that our approach is competitive with state-of-the-art methods of map refinement and that guided diffusion models provide a promising pathway to functional map processing.

</details>


### [32] [FGA-NN: Film Grain Analysis Neural Network](https://arxiv.org/abs/2506.14350)
*Zoubida Ameur,Frédéric Lefebvre,Philippe De Lagrange,Miloš Radosavljević*

Main category: cs.CV

TL;DR: FGA-NN是一种基于学习的胶片颗粒分析方法，用于在压缩后恢复胶片颗粒，保持艺术效果。


<details>
  <summary>Details</summary>
Motivation: 胶片颗粒是电影内容的重要组成部分，但在中低比特率压缩时会丢失。为了在高效压缩的同时保留艺术意图，需要分析并建模胶片颗粒。

Method: 提出FGA-NN，首个基于学习的方法，用于估计与传统合成兼容的胶片颗粒参数。

Result: 定量和定性结果表明，FGA-NN在分析精度与合成复杂性之间取得了优越的平衡，且具有鲁棒性和适用性。

Conclusion: FGA-NN为胶片颗粒的分析与合成提供了一种高效且兼容的解决方案。

Abstract: Film grain, once a by-product of analog film, is now present in most cinematographic content for aesthetic reasons. However, when such content is compressed at medium to low bitrates, film grain is lost due to its random nature. To preserve artistic intent while compressing efficiently, film grain is analyzed and modeled before encoding and synthesized after decoding. This paper introduces FGA-NN, the first learning-based film grain analysis method to estimate conventional film grain parameters compatible with conventional synthesis. Quantitative and qualitative results demonstrate FGA-NN's superior balance between analysis accuracy and synthesis complexity, along with its robustness and applicability.

</details>


### [33] [EVA02-AT: Egocentric Video-Language Understanding with Spatial-Temporal Rotary Positional Embeddings and Symmetric Optimization](https://arxiv.org/abs/2506.14356)
*Xiaoqi Wang,Yi Wang,Lap-Pui Chau*

Main category: cs.CV

TL;DR: EVA02-AT是一种基于EVA02的视频-语言基础模型，通过单阶段预训练、空间-时间旋转位置嵌入和对称多相似性损失，解决了现有方法在效率、空间-时间编码和学习目标上的不足，并在多个任务中取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预训练成本、空间-时间编码和学习目标上存在不足，EVA02-AT旨在高效且准确地解决这些问题。

Method: 1. 通过单阶段预训练将图像CLIP模型迁移为视频编码器；2. 引入空间-时间旋转位置嵌入和联合注意力；3. 提出对称多相似性损失和改进的训练框架。

Result: 在Ego4D、EPIC-Kitchens-100和Charades-Ego等数据集上，EVA02-AT在零样本和微调设置下均达到最优性能。

Conclusion: EVA02-AT通过高效设计和精确建模，显著提升了视频-语言理解任务的性能。

Abstract: Egocentric video-language understanding demands both high efficiency and accurate spatial-temporal modeling. Existing approaches face three key challenges: 1) Excessive pre-training cost arising from multi-stage pre-training pipelines, 2) Ineffective spatial-temporal encoding due to manually split 3D rotary positional embeddings that hinder feature interactions, and 3) Imprecise learning objectives in soft-label multi-instance retrieval, which neglect negative pair correlations. In this paper, we introduce EVA02-AT, a suite of EVA02-based video-language foundation models tailored to egocentric video understanding tasks. EVA02-AT first efficiently transfers an image-based CLIP model into a unified video encoder via a single-stage pretraining. Second, instead of applying rotary positional embeddings to isolated dimensions, we introduce spatial-temporal rotary positional embeddings along with joint attention, which can effectively encode both spatial and temporal information on the entire hidden dimension. This joint encoding of spatial-temporal features enables the model to learn cross-axis relationships, which are crucial for accurately modeling motion and interaction in videos. Third, focusing on multi-instance video-language retrieval tasks, we introduce the Symmetric Multi-Similarity (SMS) loss and a novel training framework that advances all soft labels for both positive and negative pairs, providing a more precise learning objective. Extensive experiments on Ego4D, EPIC-Kitchens-100, and Charades-Ego under zero-shot and fine-tuning settings demonstrate that EVA02-AT achieves state-of-the-art performance across diverse egocentric video-language tasks with fewer parameters. Models with our SMS loss also show significant performance gains on multi-instance retrieval benchmarks. Our code and models are publicly available at https://github.com/xqwang14/EVA02-AT .

</details>


### [34] [HydroChronos: Forecasting Decades of Surface Water Change](https://arxiv.org/abs/2506.14362)
*Daniele Rege Cambrin,Eleonora Poeta,Eliana Pastor,Isaac Corley,Tania Cerquitelli,Elena Baralis,Paolo Garza*

Main category: cs.CV

TL;DR: HydroChronos是一个用于地表水动态预测的大规模多模态时空数据集，填补了该领域缺乏综合数据和标准化基准的空白。AquaClimaTempo UNet模型在预测任务中表现优异，并通过可解释性分析揭示了关键气候变量。


<details>
  <summary>Details</summary>
Motivation: 地表水动态预测对水资源管理和气候变化适应至关重要，但缺乏全面数据集和标准化基准。

Method: 引入HydroChronos数据集，包含多源数据，并提出AquaClimaTempo UNet模型作为基准。

Result: 模型在多项预测任务中显著优于基线，F1分数提升14%和11%，MAE降低0.1。

Conclusion: HydroChronos和AquaClimaTempo UNet为地表水动态预测提供了有效工具，并通过可解释性分析为未来研究提供指导。

Abstract: Forecasting surface water dynamics is crucial for water resource management and climate change adaptation. However, the field lacks comprehensive datasets and standardized benchmarks. In this paper, we introduce HydroChronos, a large-scale, multi-modal spatiotemporal dataset for surface water dynamics forecasting designed to address this gap. We couple the dataset with three forecasting tasks. The dataset includes over three decades of aligned Landsat 5 and Sentinel-2 imagery, climate data, and Digital Elevation Models for diverse lakes and rivers across Europe, North America, and South America. We also propose AquaClimaTempo UNet, a novel spatiotemporal architecture with a dedicated climate data branch, as a strong benchmark baseline. Our model significantly outperforms a Persistence baseline for forecasting future water dynamics by +14% and +11% F1 across change detection and direction of change classification tasks, and by +0.1 MAE on the magnitude of change regression. Finally, we conduct an Explainable AI analysis to identify the key climate variables and input channels that influence surface water change, providing insights to inform and guide future modeling efforts.

</details>


### [35] [DGG-XNet: A Hybrid Deep Learning Framework for Multi-Class Brain Disease Classification with Explainable AI](https://arxiv.org/abs/2506.14367)
*Sumshun Nahar Eity,Mahin Montasir Afif,Tanisha Fairooz,Md. Mortuza Ahmmed,Md Saef Ullah Miah*

Main category: cs.CV

TL;DR: DGG-XNet结合VGG16和DenseNet121，提升脑部疾病诊断的准确性和可解释性，测试准确率达91.33%。


<details>
  <summary>Details</summary>
Motivation: 传统MRI分析方法效率低且易出错，需更高效准确的诊断工具。

Method: 提出DGG-XNet，融合VGG16和DenseNet121，结合Grad-CAM增强可解释性。

Result: 在BraTS 2021和Kaggle数据集上，测试准确率91.33%，各项指标均超过91%。

Conclusion: DGG-XNet是一种高效且可解释的脑部疾病计算机辅助诊断工具。

Abstract: Accurate diagnosis of brain disorders such as Alzheimer's disease and brain tumors remains a critical challenge in medical imaging. Conventional methods based on manual MRI analysis are often inefficient and error-prone. To address this, we propose DGG-XNet, a hybrid deep learning model integrating VGG16 and DenseNet121 to enhance feature extraction and classification. DenseNet121 promotes feature reuse and efficient gradient flow through dense connectivity, while VGG16 contributes strong hierarchical spatial representations. Their fusion enables robust multiclass classification of neurological conditions. Grad-CAM is applied to visualize salient regions, enhancing model transparency. Trained on a combined dataset from BraTS 2021 and Kaggle, DGG-XNet achieved a test accuracy of 91.33\%, with precision, recall, and F1-score all exceeding 91\%. These results highlight DGG-XNet's potential as an effective and interpretable tool for computer-aided diagnosis (CAD) of neurodegenerative and oncological brain disorders.

</details>


### [36] [Discrete JEPA: Learning Discrete Token Representations without Reconstruction](https://arxiv.org/abs/2506.14373)
*Junyeob Baek,Hosung Lee,Christopher Hoang,Mengye Ren,Sungjin Ahn*

Main category: cs.CV

TL;DR: 论文提出Discrete-JEPA方法，通过语义标记化和新目标改进图像标记化，显著提升符号推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前图像标记化方法在符号抽象和逻辑推理任务中存在局限性，无法满足系统性推断需求。

Method: 扩展潜在预测编码框架，引入语义标记化和互补目标，构建适用于符号推理的鲁棒标记化方法。

Result: Discrete-JEPA在视觉符号预测任务中显著优于基线，学习到的语义标记空间自发形成系统性模式。

Conclusion: 该方法为人工智能系统的符号世界建模和规划能力提供了重要进展。

Abstract: The cornerstone of cognitive intelligence lies in extracting hidden patterns from observations and leveraging these principles to systematically predict future outcomes. However, current image tokenization methods demonstrate significant limitations in tasks requiring symbolic abstraction and logical reasoning capabilities essential for systematic inference. To address this challenge, we propose Discrete-JEPA, extending the latent predictive coding framework with semantic tokenization and novel complementary objectives to create robust tokenization for symbolic reasoning tasks. Discrete-JEPA dramatically outperforms baselines on visual symbolic prediction tasks, while striking visual evidence reveals the spontaneous emergence of deliberate systematic patterns within the learned semantic token space. Though an initial model, our approach promises a significant impact for advancing Symbolic world modeling and planning capabilities in artificial intelligence systems.

</details>


### [37] [DepthSeg: Depth prompting in remote sensing semantic segmentation](https://arxiv.org/abs/2506.14382)
*Ning Zhou,Shanxiong Chen,Mingting Zhou,Haigang Sui,Lieyun Hu,Han Li,Li Hua,Qiming Zhou*

Main category: cs.CV

TL;DR: DepthSeg框架通过深度提示改进2D遥感图像语义分割，解决光谱混淆和阴影遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有语义分割方法忽略目标高度差异，导致复杂场景下的土地覆盖分类错误。

Method: 提出DepthSeg框架，包括轻量适配器、深度提示器和语义分类解码器，集成深度信息。

Result: 在LiuZhou数据集上验证了DepthSeg在土地覆盖映射任务中的优势。

Conclusion: 深度提示对遥感语义分割具有重要意义。

Abstract: Remote sensing semantic segmentation is crucial for extracting detailed land surface information, enabling applications such as environmental monitoring, land use planning, and resource assessment. In recent years, advancements in artificial intelligence have spurred the development of automatic remote sensing semantic segmentation methods. However, the existing semantic segmentation methods focus on distinguishing spectral characteristics of different objects while ignoring the differences in the elevation of the different targets. This results in land cover misclassification in complex scenarios involving shadow occlusion and spectral confusion. In this paper, we introduce a depth prompting two-dimensional (2D) remote sensing semantic segmentation framework (DepthSeg). It automatically models depth/height information from 2D remote sensing images and integrates it into the semantic segmentation framework to mitigate the effects of spectral confusion and shadow occlusion. During the feature extraction phase of DepthSeg, we introduce a lightweight adapter to enable cost-effective fine-tuning of the large-parameter vision transformer encoder pre-trained by natural images. In the depth prompting phase, we propose a depth prompter to model depth/height features explicitly. In the semantic prediction phase, we introduce a semantic classification decoder that couples the depth prompts with high-dimensional land-cover features, enabling accurate extraction of land-cover types. Experiments on the LiuZhou dataset validate the advantages of the DepthSeg framework in land cover mapping tasks. Detailed ablation studies further highlight the significance of the depth prompts in remote sensing semantic segmentation.

</details>


### [38] [GrFormer: A Novel Transformer on Grassmann Manifold for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.14384)
*Huan Kang,Hui Li,Xiao-Jun Wu,Tianyang Xu,Rui Wang,Chunyang Cheng,Josef Kittler*

Main category: cs.CV

TL;DR: 提出了一种基于Grassmann流形的新型注意力机制（GrFormer），用于红外和可见光图像融合，通过低秩子空间映射实现多尺度语义融合。


<details>
  <summary>Details</summary>
Motivation: 现有方法在非欧几里得空间中无法捕捉图像的固有拓扑结构，导致融合性能下降。

Method: 利用Grassmann流形构建低秩子空间映射，并通过协方差掩模的跨模态融合策略（CMS）优化信息整合。

Result: 实验表明，该方法在多个图像融合基准上优于现有技术。

Conclusion: GrFormer通过流形学习和跨模态策略显著提升了图像融合效果。

Abstract: In the field of image fusion, promising progress has been made by modeling data from different modalities as linear subspaces.
  However, in practice, the source images are often located in a non-Euclidean space, where the Euclidean methods usually cannot
  encapsulate the intrinsic topological structure. Typically, the inner product performed in the Euclidean space calculates the algebraic
  similarity rather than the semantic similarity, which results in undesired attention output and a decrease in fusion performance.
  While the balance of low-level details and high-level semantics should be considered in infrared and visible image fusion task. To
  address this issue, in this paper, we propose a novel attention mechanism based on Grassmann manifold for infrared and visible
  image fusion (GrFormer). Specifically, our method constructs a low-rank subspace mapping through projection constraints on the
  Grassmann manifold, compressing attention features into subspaces of varying rank levels. This forces the features to decouple into
  high-frequency details (local low-rank) and low-frequency semantics (global low-rank), thereby achieving multi-scale semantic
  fusion. Additionally, to effectively integrate the significant information, we develop a cross-modal fusion strategy (CMS) based on
  a covariance mask to maximise the complementary properties between different modalities and to suppress the features with high
  correlation, which are deemed redundant. The experimental results demonstrate that our network outperforms SOTA methods both
  qualitatively and quantitatively on multiple image fusion benchmarks. The codes are available at https://github.com/Shaoyun2023.

</details>


### [39] [Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models](https://arxiv.org/abs/2506.14399)
*Tian Xia,Fabio De Sousa Ribeiro,Rajat R Rasal,Avinash Kori,Raghav Mehta,Ben Glocker*

Main category: cs.CV

TL;DR: 论文提出了一种解耦的无分类器引导（DCFG）方法，用于改进反事实图像生成中的属性控制和干预保真度。


<details>
  <summary>Details</summary>
Motivation: 标准无分类器引导（CFG）在全局权重下可能导致身份保留不佳和虚假属性变化（属性放大问题），因此需要更灵活的控制方法。

Method: 提出DCFG框架，通过属性分组嵌入策略实现选择性引导，基于因果图将属性分为干预组和不变组，并分别应用不同的引导。

Result: 在CelebA-HQ、MIMIC-CXR和EMBED数据集上的实验表明，DCFG提高了干预保真度，减少了意外变化，并增强了可逆性。

Conclusion: DCFG能够生成更忠实和可解释的反事实图像，解决了属性放大问题。

Abstract: Counterfactual image generation aims to simulate realistic visual outcomes under specific causal interventions. Diffusion models have recently emerged as a powerful tool for this task, combining DDIM inversion with conditional generation via classifier-free guidance (CFG). However, standard CFG applies a single global weight across all conditioning variables, which can lead to poor identity preservation and spurious attribute changes - a phenomenon known as attribute amplification. To address this, we propose Decoupled Classifier-Free Guidance (DCFG), a flexible and model-agnostic framework that introduces group-wise conditioning control. DCFG builds on an attribute-split embedding strategy that disentangles semantic inputs, enabling selective guidance on user-defined attribute groups. For counterfactual generation, we partition attributes into intervened and invariant sets based on a causal graph and apply distinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show that DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility, enabling more faithful and interpretable counterfactual image generation.

</details>


### [40] [Causally Steered Diffusion for Automated Video Counterfactual Generation](https://arxiv.org/abs/2506.14404)
*Nikos Spyrou,Athanasios Vlontzos,Paraskevas Pegios,Thomas Melistas,Nefeli Gkouti,Yannis Panagakis,Giorgos Papanastasiou,Sotirios A. Tsaftaris*

Main category: cs.CV

TL;DR: 本文提出了一种基于因果关系的视频编辑框架，通过优化文本提示生成反事实视频，无需访问底层系统或微调。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在视频编辑中难以保持因果关系的真实性，可能导致不现实或误导性结果。

Method: 利用视觉语言模型（VLM）指导，基于假设的因果图优化文本提示，控制潜在扩散模型（LDM）的生成过程。

Result: 实验表明，该方法能有效生成因果一致的反事实视频，并通过标准视频质量和反事实特定指标验证。

Conclusion: 该方法兼容任何黑盒视频编辑系统，在医疗和数字媒体等领域具有广泛应用潜力。

Abstract: Adapting text-to-image (T2I) latent diffusion models for video editing has shown strong visual fidelity and controllability, but challenges remain in maintaining causal relationships in video content. Edits affecting causally dependent attributes risk generating unrealistic or misleading outcomes if these relationships are ignored. In this work, we propose a causally faithful framework for counterfactual video generation, guided by a vision-language model (VLM). Our method is agnostic to the underlying video editing system and does not require access to its internal mechanisms or finetuning. Instead, we guide the generation by optimizing text prompts based on an assumed causal graph, addressing the challenge of latent space control in LDMs. We evaluate our approach using standard video quality metrics and counterfactual-specific criteria, such as causal effectiveness and minimality. Our results demonstrate that causally faithful video counterfactuals can be effectively generated within the learned distribution of LDMs through prompt-based causal steering. With its compatibility with any black-box video editing system, our method holds significant potential for generating realistic "what-if" video scenarios in diverse areas such as healthcare and digital media.

</details>


### [41] [Compositional Attribute Imbalance in Vision Datasets](https://arxiv.org/abs/2506.14418)
*Jiayi Chen,Yanbiao Ma,Andi Zhang,Weidong Tang,Wei Dai,Bowei Liu*

Main category: cs.CV

TL;DR: 论文提出了一种基于CLIP的框架，通过构建视觉属性字典解决图像分类中的属性不平衡问题，并通过调整采样概率和数据增强技术提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 视觉属性不平衡是图像分类中常见但未被充分研究的问题，显著影响模型性能和泛化能力。

Method: 定义图像的一级和二级属性，构建CLIP-based视觉属性字典，分析单属性和组合属性不平衡，调整采样概率并结合数据增强技术（如CutMix、Fmix等）。

Result: 实验表明，该方法有效缓解了属性不平衡，提升了深度神经网络的鲁棒性和公平性。

Conclusion: 研究强调了建模视觉属性分布的重要性，并为长尾图像分类任务提供了可扩展的解决方案。

Abstract: Visual attribute imbalance is a common yet underexplored issue in image classification, significantly impacting model performance and generalization. In this work, we first define the first-level and second-level attributes of images and then introduce a CLIP-based framework to construct a visual attribute dictionary, enabling automatic evaluation of image attributes. By systematically analyzing both single-attribute imbalance and compositional attribute imbalance, we reveal how the rarity of attributes affects model performance. To tackle these challenges, we propose adjusting the sampling probability of samples based on the rarity of their compositional attributes. This strategy is further integrated with various data augmentation techniques (such as CutMix, Fmix, and SaliencyMix) to enhance the model's ability to represent rare attributes. Extensive experiments on benchmark datasets demonstrate that our method effectively mitigates attribute imbalance, thereby improving the robustness and fairness of deep neural networks. Our research highlights the importance of modeling visual attribute distributions and provides a scalable solution for long-tail image classification tasks.

</details>


### [42] [Toward Rich Video Human-Motion2D Generation](https://arxiv.org/abs/2506.14428)
*Ruihao Xi,Xuekuan Wang,Yongcheng Li,Shuhua Li,Zichen Wang,Yiwei Wang,Feng Wei,Cairong Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的视频人体动作生成方法（RVHM2D），并引入了一个新的大规模数据集（Motion2D-Video-150K），用于解决多角色交互动作生成的数据稀缺和建模复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺和人际动态建模的复杂性，生成真实且可控的多角色交互动作仍是一个挑战。

Method: 提出了RVHM2D模型，采用双文本编码器（CLIP-L/B或T5-XXL）增强文本条件机制，并通过两阶段训练策略（扩散目标训练和基于FID奖励的强化学习微调）提升动作真实性和文本对齐。

Result: RVHM2D在Motion2D-Video-150K数据集上实现了单角色和双角色交互动作生成的领先性能。

Conclusion: RVHM2D通过新数据集和增强的文本条件机制，有效解决了多角色动作生成的挑战。

Abstract: Generating realistic and controllable human motions, particularly those involving rich multi-character interactions, remains a significant challenge due to data scarcity and the complexities of modeling inter-personal dynamics. To address these limitations, we first introduce a new large-scale rich video human motion 2D dataset (Motion2D-Video-150K) comprising 150,000 video sequences. Motion2D-Video-150K features a balanced distribution of diverse single-character and, crucially, double-character interactive actions, each paired with detailed textual descriptions. Building upon this dataset, we propose a novel diffusion-based rich video human motion2D generation (RVHM2D) model. RVHM2D incorporates an enhanced textual conditioning mechanism utilizing either dual text encoders (CLIP-L/B) or T5-XXL with both global and local features. We devise a two-stage training strategy: the model is first trained with a standard diffusion objective, and then fine-tuned using reinforcement learning with an FID-based reward to further enhance motion realism and text alignment. Extensive experiments demonstrate that RVHM2D achieves leading performance on the Motion2D-Video-150K benchmark in generating both single and interactive double-character scenarios.

</details>


### [43] [MoTE: Mixture of Ternary Experts for Memory-efficient Large Multimodal Models](https://arxiv.org/abs/2506.14435)
*Hongyu Wang,Jiayu Xu,Ruiping Wang,Yan Feng,Yitao Zhai,Peng Pei,Xunliang Cai,Xilin Chen*

Main category: cs.CV

TL;DR: MoTE是一种内存高效的混合三元专家模型训练方法，通过低精度专家减少内存占用，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态混合专家模型在边缘设备上部署时的高内存占用问题。

Method: 使用预训练的FFN作为共享专家，训练三元路由专家（参数为{-1, 0, 1}）。

Result: MoTE在相同内存占用下性能接近全精度基线，结合后训练量化后性能提升4.3%。

Conclusion: MoTE在内存受限设备上具有高效性和潜力。

Abstract: Large multimodal Mixture-of-Experts (MoEs) effectively scale the model size to boost performance while maintaining fixed active parameters. However, previous works primarily utilized full-precision experts during sparse up-cycling. Despite they show superior performance on end tasks, the large amount of experts introduces higher memory footprint, which poses significant challenges for the deployment on edge devices. In this work, we propose MoTE, a scalable and memory-efficient approach to train Mixture-of-Ternary-Experts models from dense checkpoint. Instead of training fewer high-precision experts, we propose to train more low-precision experts during up-cycling. Specifically, we use the pre-trained FFN as a shared expert and train ternary routed experts with parameters in {-1, 0, 1}. Extensive experiments show that our approach has promising scaling trend along model size. MoTE achieves comparable performance to full-precision baseline MoE-LLaVA while offering lower memory footprint. Furthermore, our approach is compatible with post-training quantization methods and the advantage further amplifies when memory-constraint goes lower. Given the same amount of expert memory footprint of 3.4GB and combined with post-training quantization, MoTE outperforms MoE-LLaVA by a gain of 4.3% average accuracy on end tasks, demonstrating its effectiveness and potential for memory-constrained devices.

</details>


### [44] [Model compression using knowledge distillation with integrated gradients](https://arxiv.org/abs/2506.14440)
*David E. Hernandez,Jose Chang,Torbjörn E. M. Nordling*

Main category: cs.CV

TL;DR: 论文提出了一种基于集成梯度（IG）增强的知识蒸馏方法，显著提升了模型压缩性能，并在CIFAR-10上实现了92.6%的测试准确率，同时压缩比为4.1倍。


<details>
  <summary>Details</summary>
Motivation: 在资源受限设备上部署深度学习模型需要高效的压缩技术，传统方法在压缩与性能之间难以平衡。

Method: 通过将IG图叠加到输入图像上，增强学生模型对教师模型决策过程的理解，并将IG图预处理为一次性步骤以减少运行时开销。

Result: 在CIFAR-10上，该方法比非蒸馏模型提升了1.1个百分点（p<0.001），推理时间从140ms降至13ms，且在ImageNet子集上验证了泛化性。

Conclusion: 基于IG的知识蒸馏在多种架构和压缩比下均优于传统方法，为边缘设备部署提供了可行的压缩框架。

Abstract: Model compression is critical for deploying deep learning models on resource-constrained devices. We introduce a novel method enhancing knowledge distillation with integrated gradients (IG) as a data augmentation strategy. Our approach overlays IG maps onto input images during training, providing student models with deeper insights into teacher models' decision-making processes. Extensive evaluation on CIFAR-10 demonstrates that our IG-augmented knowledge distillation achieves 92.6% testing accuracy with a 4.1x compression factor-a significant 1.1 percentage point improvement ($p<0.001$) over non-distilled models (91.5%). This compression reduces inference time from 140 ms to 13 ms. Our method precomputes IG maps before training, transforming substantial runtime costs into a one-time preprocessing step. Our comprehensive experiments include: (1) comparisons with attention transfer, revealing complementary benefits when combined with our approach; (2) Monte Carlo simulations confirming statistical robustness; (3) systematic evaluation of compression factor versus accuracy trade-offs across a wide range (2.2x-1122x); and (4) validation on an ImageNet subset aligned with CIFAR-10 classes, demonstrating generalisability beyond the initial dataset. These extensive ablation studies confirm that IG-based knowledge distillation consistently outperforms conventional approaches across varied architectures and compression ratios. Our results establish this framework as a viable compression technique for real-world deployment on edge devices while maintaining competitive accuracy.

</details>


### [45] [Adapting Lightweight Vision Language Models for Radiological Visual Question Answering](https://arxiv.org/abs/2506.14451)
*Aditya Shourya,Michel Dumontier,Chang Sun*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级3B参数的视觉语言模型，用于放射学视觉问答（VQA），通过合成数据生成和多阶段微调，证明了小模型在适当调优下也能实现稳健性能。


<details>
  <summary>Details</summary>
Motivation: 放射学VQA模型开发面临数据获取困难、图像模式复杂以及缺乏评估工具的挑战。

Method: 采用轻量级3B参数模型，通过合成问题-答案对生成和多阶段微调，结合放射学专用数据集（如ROCO v2.0、MedPix v2.0）。

Result: 尽管模型规模远小于LLaVA-Med等先进模型，但在有限数据下仍表现出色。

Conclusion: 小模型通过精心调优和专用数据集可实现高性能，并引入轻量级显著性诊断工具辅助专家评估。

Abstract: Recent advancements in vision-language systems have improved the accuracy of Radiological Visual Question Answering (VQA) Models. However, some challenges remain across each stage of model development: limited expert-labeled images hinders data procurement at scale; the intricate and nuanced patterns of radiological images make modeling inherently difficult; and the lack of evaluation evaluation efforts makes it difficult to identify cases where the model might be ill-conditioned. In this study, we fine-tune a lightweight 3B parameter vision-language model for Radiological VQA, demonstrating that small models, when appropriately tuned with curated data, can achieve robust performance across both open- and closed-ended questions. We propose a cost-effective training pipeline from synthetic question-answer pair generation to multi-stage fine-tuning on specialised radiological domain-targeted datasets (e.g., ROCO v2.0, MedPix v2.0). Our results show that despite operating at a fraction of the scale of state-of-the-art models such as LLaVA-Med, our model achieves promising performance given its small parameter size and the limited scale of training data. We introduce a lightweight saliency-based diagnostic tool that enables domain experts to inspect VQA model performance and identify ill-conditioned failure modes through saliency analysis.

</details>


### [46] [Dense360: Dense Understanding from Omnidirectional Panoramas](https://arxiv.org/abs/2506.14471)
*Yikang Zhou,Tao Zhang,Dizhe Zhang,Shunping Ji,Xiangtai Li,Lu Qi*

Main category: cs.CV

TL;DR: 该论文提出了一种基于全景图像的多模态大语言模型（MLLM）方法，解决了全景图像在视觉语言理解中的空间连续性和信息密度变化问题，并引入了新的数据集和基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM通过有限视场（FOV）输入实现世界理解，但全景图像能提供更完整、紧凑和连续的场景表示，因此需要研究如何利用全景图像实现密集视觉语言理解。

Method: 提出ERP-RoPE位置编码方案，专门针对全景图像的等距柱状投影（ERP）设计，解决了空间连续性和信息密度变化问题；并构建了包含160K全景图像的数据集Dense360-Bench。

Result: 成功开发了适用于全景图像的MLLM方法，并建立了首个全景图像标注和基准测试框架，推动了密集视觉语言理解的发展。

Conclusion: 通过ERP-RoPE和Dense360-Bench，论文为全景图像的多模态理解提供了有效解决方案，为未来研究奠定了基础。

Abstract: Multimodal Large Language Models (MLLMs) require comprehensive visual inputs to achieve dense understanding of the physical world. While existing MLLMs demonstrate impressive world understanding capabilities through limited field-of-view (FOV) visual inputs (e.g., 70 degree), we take the first step toward dense understanding from omnidirectional panoramas. We first introduce an omnidirectional panoramas dataset featuring a comprehensive suite of reliability-scored annotations. Specifically, our dataset contains 160K panoramas with 5M dense entity-level captions, 1M unique referring expressions, and 100K entity-grounded panoramic scene descriptions. Compared to multi-view alternatives, panoramas can provide more complete, compact, and continuous scene representations through equirectangular projections (ERP). However, the use of ERP introduces two key challenges for MLLMs: i) spatial continuity along the circle of latitude, and ii) latitude-dependent variation in information density. We address these challenges through ERP-RoPE, a position encoding scheme specifically designed for panoramic ERP. In addition, we introduce Dense360-Bench, the first benchmark for evaluating MLLMs on omnidirectional captioning and grounding, establishing a comprehensive framework for advancing dense visual-language understanding in panoramic settings.

</details>


### [47] [Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection](https://arxiv.org/abs/2506.14473)
*Zhijing Wan,Zhixiang Wang,Zheng Wang,Xin Xu,Shin'ichi Satoh*

Main category: cs.CV

TL;DR: 论文研究了基于基础模型（FMs）的一次性子集选择方法，发现其在细粒度数据集上优于传统信息提取器（IEs），并提出RAM-APL方法以进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统信息提取器（IEs）依赖于目标数据集，限制了其通用性。基础模型（FMs）可能克服这一限制，但需要验证其在不同数据集上的表现。

Method: 提出RAM-APL方法，利用多个FMs的互补优势，针对细粒度图像数据集优化子集选择。

Result: FMs在细粒度数据集上表现优于传统IEs，但在粗粒度数据集上优势减弱。RAM-APL在多个细粒度数据集上达到最优性能。

Conclusion: FMs在子集选择中具有潜力，尤其在细粒度数据集上。RAM-APL方法通过多模型协同进一步提升了性能。

Abstract: One-shot subset selection serves as an effective tool to reduce deep learning training costs by identifying an informative data subset based on the information extracted by an information extractor (IE). Traditional IEs, typically pre-trained on the target dataset, are inherently dataset-dependent. Foundation models (FMs) offer a promising alternative, potentially mitigating this limitation. This work investigates two key questions: (1) Can FM-based subset selection outperform traditional IE-based methods across diverse datasets? (2) Do all FMs perform equally well as IEs for subset selection? Extensive experiments uncovered surprising insights: FMs consistently outperform traditional IEs on fine-grained datasets, whereas their advantage diminishes on coarse-grained datasets with noisy labels. Motivated by these finding, we propose RAM-APL (RAnking Mean-Accuracy of Pseudo-class Labels), a method tailored for fine-grained image datasets. RAM-APL leverages multiple FMs to enhance subset selection by exploiting their complementary strengths. Our approach achieves state-of-the-art performance on fine-grained datasets, including Oxford-IIIT Pet, Food-101, and Caltech-UCSD Birds-200-2011.

</details>


### [48] [I Speak and You Find: Robust 3D Visual Grounding with Noisy and Ambiguous Speech Inputs](https://arxiv.org/abs/2506.14495)
*Yu Qi,Lipeng Gu,Honghua Chen,Liangliang Nan,Mingqiang Wei*

Main category: cs.CV

TL;DR: 论文提出了一种名为SpeechRefer的新框架，旨在解决3D视觉定位中因语音转录错误导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉定位方法依赖精确的文本提示，而语音输入常因口音、背景噪声等问题产生转录错误，限制了方法的实用性。

Method: SpeechRefer通过语音互补模块和对比互补模块，分别从语音信号中提取补充信息并利用对比学习对齐错误文本与语音特征。

Result: 在SpeechRefer和SpeechNr3D数据集上的实验表明，该方法显著提升了现有3DVG模型的性能。

Conclusion: SpeechRefer能够有效处理噪声语音输入，为更直观、实用的多模态系统提供了可能。

Abstract: Existing 3D visual grounding methods rely on precise text prompts to locate objects within 3D scenes. Speech, as a natural and intuitive modality, offers a promising alternative. Real-world speech inputs, however, often suffer from transcription errors due to accents, background noise, and varying speech rates, limiting the applicability of existing 3DVG methods. To address these challenges, we propose \textbf{SpeechRefer}, a novel 3DVG framework designed to enhance performance in the presence of noisy and ambiguous speech-to-text transcriptions. SpeechRefer integrates seamlessly with xisting 3DVG models and introduces two key innovations. First, the Speech Complementary Module captures acoustic similarities between phonetically related words and highlights subtle distinctions, generating complementary proposal scores from the speech signal. This reduces dependence on potentially erroneous transcriptions. Second, the Contrastive Complementary Module employs contrastive learning to align erroneous text features with corresponding speech features, ensuring robust performance even when transcription errors dominate. Extensive experiments on the SpeechRefer and peechNr3D datasets demonstrate that SpeechRefer improves the performance of existing 3DVG methods by a large margin, which highlights SpeechRefer's potential to bridge the gap between noisy speech inputs and reliable 3DVG, enabling more intuitive and practical multimodal systems.

</details>


### [49] [MOL: Joint Estimation of Micro-Expression, Optical Flow, and Landmark via Transformer-Graph-Style Convolution](https://arxiv.org/abs/2506.14511)
*Zhiwen Shao,Yifan Cheng,Feiran Li,Yong Zhou,Xuequan Lu,Yuan Xie,Lizhuang Ma*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer、图卷积和普通卷积的端到端微动作感知深度学习框架，用于面部微表情识别（MER），无需关键帧先验知识。


<details>
  <summary>Details</summary>
Motivation: 面部微表情识别因动作短暂且细微而具有挑战性，现有方法依赖手工特征或受限于小规模数据集。

Method: 设计了F5C块（全连接卷积和通道对应卷积），结合Transformer和图卷积，直接从原始帧序列提取局部-全局特征，并联合训练MER、光流估计和面部标志点检测任务。

Result: 在CASME II、SAMM和SMIC基准测试中优于现有方法，同时能有效捕捉与微表情相关的局部肌肉动作。

Conclusion: 该框架不仅提升了MER性能，还能通过多任务学习缓解数据不足问题，为微表情分析提供了新思路。

Abstract: Facial micro-expression recognition (MER) is a challenging problem, due to transient and subtle micro-expression (ME) actions. Most existing methods depend on hand-crafted features, key frames like onset, apex, and offset frames, or deep networks limited by small-scale and low-diversity datasets. In this paper, we propose an end-to-end micro-action-aware deep learning framework with advantages from transformer, graph convolution, and vanilla convolution. In particular, we propose a novel F5C block composed of fully-connected convolution and channel correspondence convolution to directly extract local-global features from a sequence of raw frames, without the prior knowledge of key frames. The transformer-style fully-connected convolution is proposed to extract local features while maintaining global receptive fields, and the graph-style channel correspondence convolution is introduced to model the correlations among feature patterns. Moreover, MER, optical flow estimation, and facial landmark detection are jointly trained by sharing the local-global features. The two latter tasks contribute to capturing facial subtle action information for MER, which can alleviate the impact of insufficient training data. Extensive experiments demonstrate that our framework (i) outperforms the state-of-the-art MER methods on CASME II, SAMM, and SMIC benchmarks, (ii) works well for optical flow estimation and facial landmark detection, and (iii) can capture facial subtle muscle actions in local regions associated with MEs. The code is available at https://github.com/CYF-cuber/MOL.

</details>


### [50] [SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks](https://arxiv.org/abs/2506.14512)
*Zijian Song,Xiaoxin Lin,Qiuming Huang,Guangrun Wang,Liang Lin*

Main category: cs.CV

TL;DR: SIRI-Bench是一个评估视觉语言模型（VLMs）空间智能的基准测试，通过视频推理任务测试其空间理解与高级推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在复杂推理方面进展迅速，但视觉语言模型（VLMs）在空间智能方面的系统评估仍不足。

Method: 开发了SIRI-Bench基准，包含近1K个视频-问题-答案三元组，并设计了自动场景生成引擎（LLM驱动）以合成大规模数据。

Result: 实验表明，现有VLMs在SIRI-Bench上表现不佳，凸显了空间推理的挑战性。

Conclusion: 研究旨在推动VLMs在空间推理和视觉问题解决方面的进步。

Abstract: Large Language Models (LLMs) are experiencing rapid advancements in complex reasoning, exhibiting remarkable generalization in mathematics and programming. In contrast, while spatial intelligence is fundamental for Vision-Language Models (VLMs) in real-world interaction, the systematic evaluation of their complex reasoning ability within spatial contexts remains underexplored. To bridge this gap, we introduce SIRI-Bench, a benchmark designed to evaluate VLMs' spatial intelligence through video-based reasoning tasks. SIRI-Bench comprises nearly 1K video-question-answer triplets, where each problem is embedded in a realistic 3D scene and captured by video. By carefully designing questions and corresponding 3D scenes, our benchmark ensures that solving the questions requires both spatial comprehension for extracting information and high-level reasoning for deriving solutions, making it a challenging benchmark for evaluating VLMs. To facilitate large-scale data synthesis, we develop an Automatic Scene Creation Engine. This engine, leveraging multiple specialized LLM agents, can generate realistic 3D scenes from abstract math problems, ensuring faithfulness to the original descriptions. Experimental results reveal that state-of-the-art VLMs struggle significantly on SIRI-Bench, underscoring the challenge of spatial reasoning. We hope that our study will bring researchers' attention to spatially grounded reasoning and advance VLMs in visual problem-solving.

</details>


### [51] [VisLanding: Monocular 3D Perception for UAV Safe Landing via Depth-Normal Synergy](https://arxiv.org/abs/2506.14525)
*Zhuoyue Tan,Boyong He,Yuxiang Ji,Liaoni Wu*

Main category: cs.CV

TL;DR: VisLanding是一个基于单目3D感知的无人机安全着陆框架，通过深度-法线协同预测和语义分割，显著提高了安全着陆区域的识别精度。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在复杂未知环境中自主着陆的核心挑战。

Method: 利用Metric3D V2模型的深度-法线协同预测能力，构建端到端的安全着陆区域估计框架，并通过语义分割任务实现。

Result: 实验表明，VisLanding通过深度-法线联合优化机制显著提高了安全区域识别的准确性，并保持了Metric3D V2的零样本泛化优势。

Conclusion: 该方法在跨域测试中表现出优越的泛化性和鲁棒性，并为实际应用提供了关键决策支持。

Abstract: This paper presents VisLanding, a monocular 3D perception-based framework for safe UAV (Unmanned Aerial Vehicle) landing. Addressing the core challenge of autonomous UAV landing in complex and unknown environments, this study innovatively leverages the depth-normal synergy prediction capabilities of the Metric3D V2 model to construct an end-to-end safe landing zones (SLZ) estimation framework. By introducing a safe zone segmentation branch, we transform the landing zone estimation task into a binary semantic segmentation problem. The model is fine-tuned and annotated using the WildUAV dataset from a UAV perspective, while a cross-domain evaluation dataset is constructed to validate the model's robustness. Experimental results demonstrate that VisLanding significantly enhances the accuracy of safe zone identification through a depth-normal joint optimization mechanism, while retaining the zero-shot generalization advantages of Metric3D V2. The proposed method exhibits superior generalization and robustness in cross-domain testing compared to other approaches. Furthermore, it enables the estimation of landing zone area by integrating predicted depth and normal information, providing critical decision-making support for practical applications.

</details>


### [52] [Exploring Diffusion with Test-Time Training on Efficient Image Restoration](https://arxiv.org/abs/2506.14541)
*Rongchang Lu,Tianduo Luo,Yunzhi Zhang,Conghan Yue,Pei Yang,Guibao Liu,Changyang Gu*

Main category: cs.CV

TL;DR: DiffRWKVIR提出了一种结合测试时训练和高效扩散的新框架，解决了图像恢复中的特征融合、计算瓶颈和扩散效率问题，通过三项创新技术显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 图像恢复中存在特征融合不充分、计算瓶颈和扩散过程低效等问题，需要一种更高效的方法。

Method: 1. Omni-Scale 2D State Evolution实现全局上下文感知；2. Chunk-Optimized Flash Processing加速并行处理；3. Prior-Guided Efficient Diffusion提取紧凑图像先验表示。

Result: 在多个基准测试中，DiffRWKVIR在PSNR、SSIM、LPIPS和效率指标上优于SwinIR、HAT和MambaIR/v2。

Conclusion: DiffRWKVIR为高效自适应的图像恢复提供了新范式，优化了硬件利用率。

Abstract: Image restoration faces challenges including ineffective feature fusion, computational bottlenecks and inefficient diffusion processes. To address these, we propose DiffRWKVIR, a novel framework unifying Test-Time Training (TTT) with efficient diffusion. Our approach introduces three key innovations: (1) Omni-Scale 2D State Evolution extends RWKV's location-dependent parameterization to hierarchical multi-directional 2D scanning, enabling global contextual awareness with linear complexity O(L); (2) Chunk-Optimized Flash Processing accelerates intra-chunk parallelism by 3.2x via contiguous chunk processing (O(LCd) complexity), reducing sequential dependencies and computational overhead; (3) Prior-Guided Efficient Diffusion extracts a compact Image Prior Representation (IPR) in only 5-20 steps, proving 45% faster training/inference than DiffIR while solving computational inefficiency in denoising. Evaluated across super-resolution and inpainting benchmarks (Set5, Set14, BSD100, Urban100, Places365), DiffRWKVIR outperforms SwinIR, HAT, and MambaIR/v2 in PSNR, SSIM, LPIPS, and efficiency metrics. Our method establishes a new paradigm for adaptive, high-efficiency image restoration with optimized hardware utilization.

</details>


### [53] [DreamLight: Towards Harmonious and Consistent Image Relighting](https://arxiv.org/abs/2506.14549)
*Yong Liu,Wenpeng Xiao,Qianqian Wang,Junlin Chen,Shiyin Wang,Yitong Wang,Xinglong Wu,Yansong Tang*

Main category: cs.CV

TL;DR: DreamLight是一个通用图像重照明模型，支持基于图像或文本的背景重照明，通过语义先验和新型适配器实现自然光照效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注基于图像的重照明，文本场景探索不足，且难以实现前景与背景的自然光照交互。

Method: 采用统一输入格式，利用预训练扩散模型的语义先验，提出PGLA适配器捕捉背景光照方向，并通过SFF模块增强前景一致性。

Result: 实验和用户研究表明，DreamLight在重照明任务中表现优异。

Conclusion: DreamLight通过创新设计和模块组合，显著提升了图像重照明的自然性和一致性。

Abstract: We introduce a model named DreamLight for universal image relighting in this work, which can seamlessly composite subjects into a new background while maintaining aesthetic uniformity in terms of lighting and color tone. The background can be specified by natural images (image-based relighting) or generated from unlimited text prompts (text-based relighting). Existing studies primarily focus on image-based relighting, while with scant exploration into text-based scenarios. Some works employ intricate disentanglement pipeline designs relying on environment maps to provide relevant information, which grapples with the expensive data cost required for intrinsic decomposition and light source. Other methods take this task as an image translation problem and perform pixel-level transformation with autoencoder architecture. While these methods have achieved decent harmonization effects, they struggle to generate realistic and natural light interaction effects between the foreground and background. To alleviate these challenges, we reorganize the input data into a unified format and leverage the semantic prior provided by the pretrained diffusion model to facilitate the generation of natural results. Moreover, we propose a Position-Guided Light Adapter (PGLA) that condenses light information from different directions in the background into designed light query embeddings, and modulates the foreground with direction-biased masked attention. In addition, we present a post-processing module named Spectral Foreground Fixer (SFF) to adaptively reorganize different frequency components of subject and relighted background, which helps enhance the consistency of foreground appearance. Extensive comparisons and user study demonstrate that our DreamLight achieves remarkable relighting performance.

</details>


### [54] [Risk Estimation of Knee Osteoarthritis Progression via Predictive Multi-task Modelling from Efficient Diffusion Model using X-ray Images](https://arxiv.org/abs/2506.14560)
*David Butler,Adrian Hilton,Gustavo Carneiro*

Main category: cs.CV

TL;DR: 提出了一种新的可解释机器学习方法，通过多任务预测模型估计膝关节骨关节炎（OA）进展风险，结合分类和关键点预测，并利用扩散模型生成高质量未来图像。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏可解释性且复杂，无法定位解剖标志，限制了临床应用。

Method: 采用多任务预测模型，结合分类和关键点预测，利用扩散模型在类别条件潜在空间中生成未来图像。

Result: 在Osteoarthritis Initiative数据集上，AUC提升2%至0.71，推理时间减少约9%。

Conclusion: 新方法在提升预测性能的同时增强了可解释性，为临床提供了实用工具。

Abstract: Medical imaging plays a crucial role in assessing knee osteoarthritis (OA) risk by enabling early detection and disease monitoring. Recent machine learning methods have improved risk estimation (i.e., predicting the likelihood of disease progression) and predictive modelling (i.e., the forecasting of future outcomes based on current data) using medical images, but clinical adoption remains limited due to their lack of interpretability. Existing approaches that generate future images for risk estimation are complex and impractical. Additionally, previous methods fail to localize anatomical knee landmarks, limiting interpretability. We address these gaps with a new interpretable machine learning method to estimate the risk of knee OA progression via multi-task predictive modelling that classifies future knee OA severity and predicts anatomical knee landmarks from efficiently generated high-quality future images. Such image generation is achieved by leveraging a diffusion model in a class-conditioned latent space to forecast disease progression, offering a visual representation of how particular health conditions may evolve. Applied to the Osteoarthritis Initiative dataset, our approach improves the state-of-the-art (SOTA) by 2\%, achieving an AUC of 0.71 in predicting knee OA progression while offering ~9% faster inference time.

</details>


### [55] [Synthetic Data Augmentation for Table Detection: Re-evaluating TableNet's Performance with Automatically Generated Document Images](https://arxiv.org/abs/2506.14583)
*Krishna Sahukara,Zineddine Bettouche,Andreas Fischer*

Main category: cs.CV

TL;DR: 论文提出了一种自动化LaTeX管道，用于生成多样化的表格布局合成数据，以增强真实数据集Marmot，并提升TableNet在表格提取任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 手动提取文档中的表格效率低且易出错，需要自动化解决方案。

Method: 使用LaTeX生成多样化的两栏页面和表格布局，合成数据增强Marmot数据集，并训练TableNet。

Result: 在合成测试集上，TableNet的像素级XOR误差为4.04%（256x256）和4.33%（1024x1024）；在Marmot数据集上为9.18%（256x256）。

Conclusion: 合成数据显著提升了TableNet的性能，同时减少了人工标注需求。

Abstract: Document pages captured by smartphones or scanners often contain tables, yet manual extraction is slow and error-prone. We introduce an automated LaTeX-based pipeline that synthesizes realistic two-column pages with visually diverse table layouts and aligned ground-truth masks. The generated corpus augments the real-world Marmot benchmark and enables a systematic resolution study of TableNet. Training TableNet on our synthetic data achieves a pixel-wise XOR error of 4.04% on our synthetic test set with a 256x256 input resolution, and 4.33% with 1024x1024. The best performance on the Marmot benchmark is 9.18% (at 256x256), while cutting manual annotation effort through automation.

</details>


### [56] [PoseGRAF: Geometric-Reinforced Adaptive Fusion for Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2506.14596)
*Ming Xu,Xu Zhang*

Main category: cs.CV

TL;DR: PoseGRAF框架通过双图卷积结构和交叉注意力模块，解决了现有单目3D姿态估计方法忽略骨骼内在方向性和角度相关性的问题，提升了遮挡和快速运动下的姿态估计效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖关节位置特征，忽略了骨骼内在的方向和角度相关性，导致在关节遮挡或快速运动时产生不合理姿态。

Method: 提出PoseGRAF框架，包括双图卷积结构（分别处理关节和骨骼图）、交叉注意力模块建模骨骼方向与关节特征的相互依赖，动态融合模块自适应整合特征，以及改进的Transformer编码器。

Result: 在Human3.6M和MPI-INF-3DHP数据集上表现优于现有方法，野外视频评估验证了其泛化能力。

Conclusion: PoseGRAF通过结合关节和骨骼特征，显著提升了3D姿态估计的准确性和鲁棒性。

Abstract: Existing monocular 3D pose estimation methods primarily rely on joint positional features, while overlooking intrinsic directional and angular correlations within the skeleton. As a result, they often produce implausible poses under joint occlusions or rapid motion changes. To address these challenges, we propose the PoseGRAF framework. We first construct a dual graph convolutional structure that separately processes joint and bone graphs, effectively capturing their local dependencies. A Cross-Attention module is then introduced to model interdependencies between bone directions and joint features. Building upon this, a dynamic fusion module is designed to adaptively integrate both feature types by leveraging the relational dependencies between joints and bones. An improved Transformer encoder is further incorporated in a residual manner to generate the final output. Experimental results on the Human3.6M and MPI-INF-3DHP datasets show that our method exceeds state-of-the-art approaches. Additional evaluations on in-the-wild videos further validate its generalizability. The code is publicly available at https://github.com/iCityLab/PoseGRAF.

</details>


### [57] [Align Your Flow: Scaling Continuous-Time Flow Map Distillation](https://arxiv.org/abs/2506.14603)
*Amirmojtaba Sabour,Sanja Fidler,Karsten Kreis*

Main category: cs.CV

TL;DR: 论文提出了一种名为Align Your Flow的流映射模型，通过连续时间目标和新技术训练，改进了现有一致性模型和流匹配目标，实现了高效的多步生成。


<details>
  <summary>Details</summary>
Motivation: 扩散和流模型需要多步采样，一致性模型虽能一步生成但性能随步数增加而下降，流映射模型旨在解决这些问题。

Method: 引入两种连续时间训练目标和新训练技术，结合自引导和对抗微调提升性能。

Result: 在ImageNet 64x64和512x512上实现少步生成SOTA性能，文本到图像生成也优于现有非对抗训练方法。

Conclusion: 流映射模型在少步生成任务中表现出色，结合新技术可进一步提升性能。

Abstract: Diffusion- and flow-based models have emerged as state-of-the-art generative modeling approaches, but they require many sampling steps. Consistency models can distill these models into efficient one-step generators; however, unlike flow- and diffusion-based methods, their performance inevitably degrades when increasing the number of steps, which we show both analytically and empirically. Flow maps generalize these approaches by connecting any two noise levels in a single step and remain effective across all step counts. In this paper, we introduce two new continuous-time objectives for training flow maps, along with additional novel training techniques, generalizing existing consistency and flow matching objectives. We further demonstrate that autoguidance can improve performance, using a low-quality model for guidance during distillation, and an additional boost can be achieved by adversarial finetuning, with minimal loss in sample diversity. We extensively validate our flow map models, called Align Your Flow, on challenging image generation benchmarks and achieve state-of-the-art few-step generation performance on both ImageNet 64x64 and 512x512, using small and efficient neural networks. Finally, we show text-to-image flow map models that outperform all existing non-adversarially trained few-step samplers in text-conditioned synthesis.

</details>


### [58] [Unsupervised Imaging Inverse Problems with Diffusion Distribution Matching](https://arxiv.org/abs/2506.14605)
*Giacomo Meanti,Thomas Ryckeboer,Michael Arbel,Julien Mairal*

Main category: cs.CV

TL;DR: 该论文提出了一种基于未配对数据集的图像恢复方法，适用于真实场景中前向模型未知或难以获取配对数据的情况。通过条件流匹配和分布匹配损失，该方法在去模糊和非均匀点扩散函数校准任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统图像恢复方法依赖完整前向模型或配对数据的局限性，适用于真实场景中数据获取困难的情况。

Method: 利用条件流匹配建模退化观测分布，并通过分布匹配损失学习前向模型。

Result: 在去模糊和非均匀点扩散函数校准任务中优于单图像盲方法和无监督方法，盲超分辨率任务达到最先进水平。

Conclusion: 该方法在数据获取困难的实际应用中具有显著优势，例如镜头校准，无需复杂设备或大量数据。

Abstract: This work addresses image restoration tasks through the lens of inverse problems using unpaired datasets. In contrast to traditional approaches -- which typically assume full knowledge of the forward model or access to paired degraded and ground-truth images -- the proposed method operates under minimal assumptions and relies only on small, unpaired datasets. This makes it particularly well-suited for real-world scenarios, where the forward model is often unknown or misspecified, and collecting paired data is costly or infeasible. The method leverages conditional flow matching to model the distribution of degraded observations, while simultaneously learning the forward model via a distribution-matching loss that arises naturally from the framework. Empirically, it outperforms both single-image blind and unsupervised approaches on deblurring and non-uniform point spread function (PSF) calibration tasks. It also matches state-of-the-art performance on blind super-resolution. We also showcase the effectiveness of our method with a proof of concept for lens calibration: a real-world application traditionally requiring time-consuming experiments and specialized equipment. In contrast, our approach achieves this with minimal data acquisition effort.

</details>


### [59] [VisText-Mosquito: A Multimodal Dataset and Benchmark for AI-Based Mosquito Breeding Site Detection and Reasoning](https://arxiv.org/abs/2506.14629)
*Md. Adnanul Islam,Md. Faiyaz Abdullah Sayeedi,Md. Asaduzzaman Shuvo,Muhammad Ziaur Rahman,Shahanur Rahman Bappy,Raiyan Rahman,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: VisText-Mosquito是一个多模态数据集，结合视觉和文本数据，用于蚊虫滋生地的自动化检测、分割和推理分析。YOLOv9s和YOLOv11n-Seg模型在检测和分割任务中表现优异，BLIP模型在推理生成任务中取得高分。


<details>
  <summary>Details</summary>
Motivation: 蚊媒疾病是全球重大健康威胁，需通过早期检测和主动控制滋生地来预防疫情。

Method: 构建VisText-Mosquito数据集，包含标注图像和自然语言文本，使用YOLO系列模型进行检测和分割，BLIP模型进行推理生成。

Result: YOLOv9s检测精度0.92926，mAP@50为0.92891；YOLOv11n-Seg分割精度0.91587，mAP@50为0.79795；BLIP模型BLEU得分54.7，BERTScore 0.91，ROUGE-L 0.87。

Conclusion: 数据集和模型框架展示了AI在主动预防蚊媒疾病中的潜力，强调“预防胜于治疗”。

Abstract: Mosquito-borne diseases pose a major global health risk, requiring early detection and proactive control of breeding sites to prevent outbreaks. In this paper, we present VisText-Mosquito, a multimodal dataset that integrates visual and textual data to support automated detection, segmentation, and reasoning for mosquito breeding site analysis. The dataset includes 1,828 annotated images for object detection, 142 images for water surface segmentation, and natural language reasoning texts linked to each image. The YOLOv9s model achieves the highest precision of 0.92926 and mAP@50 of 0.92891 for object detection, while YOLOv11n-Seg reaches a segmentation precision of 0.91587 and mAP@50 of 0.79795. For reasoning generation, our fine-tuned BLIP model achieves a final loss of 0.0028, with a BLEU score of 54.7, BERTScore of 0.91, and ROUGE-L of 0.87. This dataset and model framework emphasize the theme "Prevention is Better than Cure", showcasing how AI-based detection can proactively address mosquito-borne disease risks. The dataset and implementation code are publicly available at GitHub: https://github.com/adnanul-islam-jisun/VisText-Mosquito

</details>


### [60] [3DGS-IEval-15K: A Large-scale Image Quality Evaluation Database for 3D Gaussian-Splatting](https://arxiv.org/abs/2506.14642)
*Yuke Xing,Jiarui Wang,Peizhi Niu,Wenjie Huang,Guangtao Zhai,Yiling Xu*

Main category: cs.CV

TL;DR: 3DGS-IEval-15K是首个针对压缩3D高斯泼溅（3DGS）表示的大规模图像质量评估数据集，包含15,200张图像，用于评估压缩对感知质量的影响。


<details>
  <summary>Details</summary>
Motivation: 3DGS在实时渲染中表现优异，但存储需求高，现有压缩方法缺乏统一的感知质量评估框架。

Method: 构建包含10个真实场景、6种3DGS算法、20个视角和不同压缩级别的数据集，并通过60名观众的主观实验收集数据。

Result: 数据集通过场景多样性和MOS分布验证质量，并建立了30种IQA指标的基准。

Conclusion: 该数据集为开发3DGS专用IQA指标和探索其视角依赖质量分布模式提供了基础。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a promising approach for novel view synthesis, offering real-time rendering with high visual fidelity. However, its substantial storage requirements present significant challenges for practical applications. While recent state-of-the-art (SOTA) 3DGS methods increasingly incorporate dedicated compression modules, there is a lack of a comprehensive framework to evaluate their perceptual impact. Therefore we present 3DGS-IEval-15K, the first large-scale image quality assessment (IQA) dataset specifically designed for compressed 3DGS representations. Our dataset encompasses 15,200 images rendered from 10 real-world scenes through 6 representative 3DGS algorithms at 20 strategically selected viewpoints, with different compression levels leading to various distortion effects. Through controlled subjective experiments, we collect human perception data from 60 viewers. We validate dataset quality through scene diversity and MOS distribution analysis, and establish a comprehensive benchmark with 30 representative IQA metrics covering diverse types. As the largest-scale 3DGS quality assessment dataset to date, our work provides a foundation for developing 3DGS specialized IQA metrics, and offers essential data for investigating view-dependent quality distribution patterns unique to 3DGS. The database is publicly available at https://github.com/YukeXing/3DGS-IEval-15K.

</details>


### [61] [DDS-NAS: Dynamic Data Selection within Neural Architecture Search via On-line Hard Example Mining applied to Image Classification](https://arxiv.org/abs/2506.14667)
*Matt Poyser,Toby P. Breckon*

Main category: cs.CV

TL;DR: 通过动态硬样本挖掘和课程学习框架加速神经架构搜索（NAS）训练，提升效率27倍且不损失性能。


<details>
  <summary>Details</summary>
Motivation: 解决神经架构搜索（NAS）中的可扩展性挑战，通过动态优化训练数据子集来加速训练。

Method: 利用自编码器构建低维嵌入空间中的kd树结构，动态选择最不相似的图像样本，重新构建无偏子集用于NAS优化。

Result: DDS-NAS框架将基于梯度的NAS策略加速高达27倍，同时保持性能不变。

Conclusion: 通过最大化每个样本的训练贡献，显著减少NAS训练周期和收敛所需的迭代次数。

Abstract: In order to address the scalability challenge within Neural Architecture Search (NAS), we speed up NAS training via dynamic hard example mining within a curriculum learning framework. By utilizing an autoencoder that enforces an image similarity embedding in latent space, we construct an efficient kd-tree structure to order images by furthest neighbour dissimilarity in a low-dimensional embedding. From a given query image from our subsample dataset, we can identify the most dissimilar image within the global dataset in logarithmic time. Via curriculum learning, we then dynamically re-formulate an unbiased subsample dataset for NAS optimisation, upon which the current NAS solution architecture performs poorly. We show that our DDS-NAS framework speeds up gradient-based NAS strategies by up to 27x without loss in performance. By maximising the contribution of each image sample during training, we reduce the duration of a NAS training cycle and the number of iterations required for convergence.

</details>


### [62] [Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models](https://arxiv.org/abs/2506.14674)
*Ling Li,Yao Zhou,Yuxuan Liang,Fugee Tsung,Jiaheng Wei*

Main category: cs.CV

TL;DR: 论文提出了一种新的图像地理定位方法GLOBE，通过构建多样性数据集MP16-Reason和优化视觉语言模型的推理能力，显著提升了地理定位的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有地理定位方法缺乏可解释性，且数据集和模型推理能力有限。

Method: 提出GLOBE框架，结合MP16-Reason数据集和双目标优化策略，增强视觉线索推理和定位能力。

Result: GLOBE在多样视觉场景中表现优于现有方法，并生成更具洞察力的推理轨迹。

Conclusion: GLOBE为地理定位任务提供了更高效、可解释的解决方案。

Abstract: Previous methods for image geo-localization have typically treated the task as either classification or retrieval, often relying on black-box decisions that lack interpretability. The rise of large vision-language models (LVLMs) has enabled a rethinking of geo-localization as a reasoning-driven task grounded in visual cues. However, two major challenges persist. On the data side, existing reasoning-focused datasets are primarily based on street-view imagery, offering limited scene diversity and constrained viewpoints. On the modeling side, current approaches predominantly rely on supervised fine-tuning, which yields only marginal improvements in reasoning capabilities. To address these challenges, we propose a novel pipeline that constructs a reasoning-oriented geo-localization dataset, MP16-Reason, using diverse social media images. We introduce GLOBE, Group-relative policy optimization for Locatability assessment and Optimized visual-clue reasoning, yielding Bi-objective geo-Enhancement for the VLM in recognition and reasoning. GLOBE incorporates task-specific rewards that jointly enhance locatability assessment, visual clue reasoning, and geolocation accuracy. Both qualitative and quantitative results demonstrate that GLOBE outperforms state-of-the-art open-source LVLMs on geo-localization tasks, particularly in diverse visual scenes, while also generating more insightful and interpretable reasoning trajectories.

</details>


### [63] [FocalClick-XL: Towards Unified and High-quality Interactive Segmentation](https://arxiv.org/abs/2506.14686)
*Xi Chen,Hengshuang Zhao*

Main category: cs.CV

TL;DR: FocalClick-XL扩展了FocalClick的粗到细设计，通过多级子网络和预训练解决交互分割中的灵活性和细节问题，支持多种交互形式并实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有交互分割方法支持交互形式有限且难以捕捉细节，需改进灵活性和精度。

Method: 提出FocalClick-XL，分解任务为上下文、对象和细节三级子网络，分别预训练，并通过提示层编码交互类型。

Result: 在点击基准测试中表现最佳，支持多种交互形式（如框、涂鸦、粗掩模），并能预测精细alpha遮罩。

Conclusion: FocalClick-XL是灵活、强大的交互分割工具，适用于多种任务。

Abstract: Interactive segmentation enables users to extract binary masks of target objects through simple interactions such as clicks, scribbles, and boxes. However, existing methods often support only limited interaction forms and struggle to capture fine details. In this paper, we revisit the classical coarse-to-fine design of FocalClick and introduce significant extensions. Inspired by its multi-stage strategy, we propose a novel pipeline, FocalClick-XL, to address these challenges simultaneously. Following the emerging trend of large-scale pretraining, we decompose interactive segmentation into meta-tasks that capture different levels of information -- context, object, and detail -- assigning a dedicated subnet to each level.This decomposition allows each subnet to undergo scaled pretraining with independent data and supervision, maximizing its effectiveness. To enhance flexibility, we share context- and detail-level information across different interaction forms as common knowledge while introducing a prompting layer at the object level to encode specific interaction types. As a result, FocalClick-XL achieves state-of-the-art performance on click-based benchmarks and demonstrates remarkable adaptability to diverse interaction formats, including boxes, scribbles, and coarse masks. Beyond binary mask generation, it is also capable of predicting alpha mattes with fine-grained details, making it a versatile and powerful tool for interactive segmentation.

</details>


### [64] [YOLOv11-RGBT: Towards a Comprehensive Single-Stage Multispectral Object Detection Framework](https://arxiv.org/abs/2506.14696)
*Dahang Wan,Rongsheng Lu,Yang Fang,Xianli Lang,Shuangbao Shu,Jingjing Chen,Siyuan Shen,Ting Xu,Zecong Ye*

Main category: cs.CV

TL;DR: 论文提出YOLOv11-RGBT，一种基于YOLOv11的多模态目标检测框架，通过六种多光谱融合模式和P3中融合策略优化性能，实验验证其在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在统一单阶段框架、性能与融合策略平衡及模态权重分配不合理等问题。

Method: 基于YOLOv11设计六种多光谱融合模式，提出P3中融合策略和多光谱可控微调（MCF）策略。

Result: 在LLVIP和FLIR等数据集上表现优异，FLIR数据集上mAP提升3.41%-5.65%，最高达47.61%。

Conclusion: YOLOv11-RGBT框架和策略有效提升了多光谱目标检测的性能和鲁棒性。

Abstract: Multispectral object detection, which integrates information from multiple bands, can enhance detection accuracy and environmental adaptability, holding great application potential across various fields. Although existing methods have made progress in cross-modal interaction, low-light conditions, and model lightweight, there are still challenges like the lack of a unified single-stage framework, difficulty in balancing performance and fusion strategy, and unreasonable modality weight allocation. To address these, based on the YOLOv11 framework, we present YOLOv11-RGBT, a new comprehensive multimodal object detection framework. We designed six multispectral fusion modes and successfully applied them to models from YOLOv3 to YOLOv12 and RT-DETR. After reevaluating the importance of the two modalities, we proposed a P3 mid-fusion strategy and multispectral controllable fine-tuning (MCF) strategy for multispectral models. These improvements optimize feature fusion, reduce redundancy and mismatches, and boost overall model performance. Experiments show our framework excels on three major open-source multispectral object detection datasets, like LLVIP and FLIR. Particularly, the multispectral controllable fine-tuning strategy significantly enhanced model adaptability and robustness. On the FLIR dataset, it consistently improved YOLOv11 models' mAP by 3.41%-5.65%, reaching a maximum of 47.61%, verifying the framework and strategies' effectiveness. The code is available at: https://github.com/wandahangFY/YOLOv11-RGBT.

</details>


### [65] [Iterative Camera-LiDAR Extrinsic Optimization via Surrogate Diffusion](https://arxiv.org/abs/2506.14706)
*Ni Ou,Zhuo Chen,Xinru Zhang,Junzheng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于替代扩散的迭代框架，用于提升相机和LiDAR外参标定方法的性能，无需修改原方法架构。


<details>
  <summary>Details</summary>
Motivation: 现有端到端标定方法多为单步预测，缺乏迭代优化能力，难以满足高精度需求。

Method: 通过替代扩散框架对初始外参进行迭代优化，原始标定方法作为替代去噪器逐步估计最终外参。

Result: 实验表明，该框架显著提升了四种先进标定方法的精度、鲁棒性和稳定性。

Conclusion: 提出的迭代框架为外参标定提供了通用且高效的优化方案。

Abstract: Cameras and LiDAR are essential sensors for autonomous vehicles. The fusion of camera and LiDAR data addresses the limitations of individual sensors but relies on precise extrinsic calibration. Recently, numerous end-to-end calibration methods have been proposed; however, most predict extrinsic parameters in a single step and lack iterative optimization capabilities. To address the increasing demand for higher accuracy, we propose a versatile iterative framework based on surrogate diffusion. This framework can enhance the performance of any calibration method without requiring architectural modifications. Specifically, the initial extrinsic parameters undergo iterative refinement through a denoising process, in which the original calibration method serves as a surrogate denoiser to estimate the final extrinsics at each step. For comparative analysis, we selected four state-of-the-art calibration methods as surrogate denoisers and compared the results of our diffusion process with those of two other iterative approaches. Extensive experiments demonstrate that when integrated with our diffusion model, all calibration methods achieve higher accuracy, improved robustness, and greater stability compared to other iterative techniques and their single-step counterparts.

</details>


### [66] [DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning](https://arxiv.org/abs/2506.14709)
*Kunal Swami,Debtanu Gupta,Amrit Kumar Muduli,Chirag Jaiswal,Pankaj Kumar Bajpai*

Main category: cs.CV

TL;DR: DiFuse-Net是一种新型网络设计，用于解耦RGB和双像素（DP）深度估计，通过窗口双向视差注意力机制（WBiPAM）和跨模态迁移学习（CmTL）提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统深度传感器在成本、功耗和鲁棒性方面存在局限，而双像素技术提供了一种替代方案。

Method: DiFuse-Net采用WBiPAM捕捉DP视差线索，并通过RGB编码器提取上下文信息，结合跨模态迁移学习利用RGB-D数据集。

Result: DiFuse-Net在深度估计上优于DP和基于立体的基线方法，并贡献了新的高质量RGB-DP-D数据集DCDP。

Conclusion: DiFuse-Net为智能手机相机提供了一种高效的深度估计解决方案，并通过新数据集推动了相关研究。

Abstract: Depth estimation is crucial for intelligent systems, enabling applications from autonomous navigation to augmented reality. While traditional stereo and active depth sensors have limitations in cost, power, and robustness, dual-pixel (DP) technology, ubiquitous in modern cameras, offers a compelling alternative. This paper introduces DiFuse-Net, a novel modality decoupled network design for disentangled RGB and DP based depth estimation. DiFuse-Net features a window bi-directional parallax attention mechanism (WBiPAM) specifically designed to capture the subtle DP disparity cues unique to smartphone cameras with small aperture. A separate encoder extracts contextual information from the RGB image, and these features are fused to enhance depth prediction. We also propose a Cross-modal Transfer Learning (CmTL) mechanism to utilize large-scale RGB-D datasets in the literature to cope with the limitations of obtaining large-scale RGB-DP-D dataset. Our evaluation and comparison of the proposed method demonstrates its superiority over the DP and stereo-based baseline methods. Additionally, we contribute a new, high-quality, real-world RGB-DP-D training dataset, named Dual-Camera Dual-Pixel (DCDP) dataset, created using our novel symmetric stereo camera hardware setup, stereo calibration and rectification protocol, and AI stereo disparity estimation method.

</details>


### [67] [Active InSAR monitoring of building damage in Gaza during the Israel-Hamas War](https://arxiv.org/abs/2506.14730)
*Corey Scher,Jamon Van Den Hoek*

Main category: cs.CV

TL;DR: 论文提出了一种基于合成孔径雷达（SAR）的低成本、低延迟方法，用于实时监测加沙地带在2023年10月7日开始的空袭中的建筑损毁情况。


<details>
  <summary>Details</summary>
Motivation: 加沙地带的持续冲突导致大规模城市损毁，需要一种动态监测方法。传统SAR方法在持续危机中的应用有限，因此需要改进。

Method: 使用Sentinel-1的干涉SAR数据，采用长时间相干变化检测（LT-CCD）方法，每周跟踪损毁趋势。

Result: 检测到联合国参考数据中92.5%的损毁标签，误报率仅1.2%。研究发现北部损毁集中，临时停火期间损毁暂停，冲突热点南移后损毁激增。研究结束时，60%的建筑受损或摧毁。

Conclusion: 该方法为冲突地区提供了及时、低成本的损毁数据，适用于人道主义和新闻机构。

Abstract: Aerial bombardment of the Gaza Strip beginning October 7, 2023 is one of the most intense bombing campaigns of the twenty-first century, driving widespread urban damage. Characterizing damage over a geographically dynamic and protracted armed conflict requires active monitoring. Synthetic aperture radar (SAR) has precedence for mapping disaster-induced damage with bi-temporal methods but applications to active monitoring during sustained crises are limited. Using interferometric SAR data from Sentinel-1, we apply a long temporal-arc coherent change detection (LT-CCD) approach to track weekly damage trends over the first year of the 2023- Israel-Hamas War. We detect 92.5% of damage labels in reference data from the United Nations with a negligible (1.2%) false positive rate. The temporal fidelity of our approach reveals rapidly increasing damage during the first three months of the war focused in northern Gaza, a notable pause in damage during a temporary ceasefire, and surges of new damage as conflict hot-spots shift from north to south. Three-fifths (191,263) of all buildings are damaged or destroyed by the end of the study. With massive need for timely data on damage in armed conflict zones, our low-cost and low-latency approach enables rapid uptake of damage information at humanitarian and journalistic organizations.

</details>


### [68] [SyncTalk++: High-Fidelity and Efficient Synchronized Talking Heads Synthesis Using Gaussian Splatting](https://arxiv.org/abs/2506.14742)
*Ziqiao Peng,Wentao Hu,Junyuan Ma,Xiangyu Zhu,Xiaomei Zhang,Hao Zhao,Hui Tian,Jun He,Hongyan Liu,Zhaoxin Fan*

Main category: cs.CV

TL;DR: SyncTalk++通过动态肖像渲染器和面部同步控制器解决语音驱动视频中的同步问题，提升真实感和渲染速度。


<details>
  <summary>Details</summary>
Motivation: 语音驱动视频中身份、唇部动作、表情和头部姿势的同步是核心挑战，缺乏同步会导致不真实的结果。

Method: 采用高斯散射的动态肖像渲染器、3D面部混合形状模型、头部同步稳定器，以及表达生成器和躯干恢复器。

Result: 在同步性和真实感上优于现有方法，渲染速度达101帧/秒。

Conclusion: SyncTalk++显著提升了语音驱动视频的同步性和真实感，推荐观看补充视频。

Abstract: Achieving high synchronization in the synthesis of realistic, speech-driven talking head videos presents a significant challenge. A lifelike talking head requires synchronized coordination of subject identity, lip movements, facial expressions, and head poses. The absence of these synchronizations is a fundamental flaw, leading to unrealistic results. To address the critical issue of synchronization, identified as the ''devil'' in creating realistic talking heads, we introduce SyncTalk++, which features a Dynamic Portrait Renderer with Gaussian Splatting to ensure consistent subject identity preservation and a Face-Sync Controller that aligns lip movements with speech while innovatively using a 3D facial blendshape model to reconstruct accurate facial expressions. To ensure natural head movements, we propose a Head-Sync Stabilizer, which optimizes head poses for greater stability. Additionally, SyncTalk++ enhances robustness to out-of-distribution (OOD) audio by incorporating an Expression Generator and a Torso Restorer, which generate speech-matched facial expressions and seamless torso regions. Our approach maintains consistency and continuity in visual details across frames and significantly improves rendering speed and quality, achieving up to 101 frames per second. Extensive experiments and user studies demonstrate that SyncTalk++ outperforms state-of-the-art methods in synchronization and realism. We recommend watching the supplementary video: https://ziqiaopeng.github.io/synctalk++.

</details>


### [69] [Cost-Aware Routing for Efficient Text-To-Image Generation](https://arxiv.org/abs/2506.14753)
*Qinchan,Li,Kenneth Chen,Changyue,Su,Wittawat Jitkrittum,Qi Sun,Patsorn Sangkloy*

Main category: cs.CV

TL;DR: 该论文提出了一种动态路由框架，根据提示的复杂度自动选择最适合的文本到图像生成方法，以平衡质量和计算成本。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成高质量图像但计算成本高，需要一种方法根据提示复杂度动态调整计算资源。

Method: 通过自动路由机制，将提示分配到不同的文本到图像生成函数，包括不同步数的扩散模型或其他独立模型。

Result: 在COCO和DiffusionDB数据集上，该方法通过路由到九个预训练模型，实现了比单一模型更高的平均质量。

Conclusion: 动态路由框架能够根据提示复杂度优化计算资源分配，显著提升效率和质量。

Abstract: Diffusion models are well known for their ability to generate a high-fidelity image for an input prompt through an iterative denoising process. Unfortunately, the high fidelity also comes at a high computational cost due the inherently sequential generative process. In this work, we seek to optimally balance quality and computational cost, and propose a framework to allow the amount of computation to vary for each prompt, depending on its complexity. Each prompt is automatically routed to the most appropriate text-to-image generation function, which may correspond to a distinct number of denoising steps of a diffusion model, or a disparate, independent text-to-image model. Unlike uniform cost reduction techniques (e.g., distillation, model quantization), our approach achieves the optimal trade-off by learning to reserve expensive choices (e.g., 100+ denoising steps) only for a few complex prompts, and employ more economical choices (e.g., small distilled model) for less sophisticated prompts. We empirically demonstrate on COCO and DiffusionDB that by learning to route to nine already-trained text-to-image models, our approach is able to deliver an average quality that is higher than that achievable by any of these models alone.

</details>


### [70] [Scaling-Up the Pretraining of the Earth Observation Foundation Model PhilEO to the MajorTOM Dataset](https://arxiv.org/abs/2506.14765)
*Nikolaos Dionelis,Jente Bosmans,Riccardo Musto,Giancarlo Paoletti,Simone Sarti,Giacomo Cascarano,Casper Fibaek,Luke Camilleri,Bertrand Le Saux,Nicolas Longépé*

Main category: cs.CV

TL;DR: 论文提出了一种基于大规模无标签数据的EO基础模型PhilEO，并在23TB数据集MajorTOM和2TB子集FastTOM上进行训练和评估，验证了数据和模型规模扩展的有效性。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星生成海量数据，需通过预训练基础模型以高效适应不同下游任务。

Method: 开发并评估不同参数和架构的PhilEO模型变体，并在PhilEO Bench上进行微调和性能评估。

Result: PhilEO 44M MajorTOM 23TB模型在道路密度回归任务中表现最佳，PhilEO 200M FastTOM在多数任务中优于其他模型。

Conclusion: 数据和模型规模扩展有效，架构从U-Net CNN过渡到ViT的研究也展示了潜力。

Abstract: Today, Earth Observation (EO) satellites generate massive volumes of data, with the Copernicus Sentinel-2 constellation alone producing approximately 1.6TB per day. To fully exploit this information, it is essential to pretrain EO Foundation Models (FMs) on large unlabeled datasets, enabling efficient fine-tuning for several different downstream tasks with minimal labeled data. In this work, we present the scaling-up of our recently proposed EO Foundation Model, PhilEO Geo-Aware U-Net, on the unlabeled 23TB dataset MajorTOM, which covers the vast majority of the Earth's surface, as well as on the specialized subset FastTOM 2TB that does not include oceans and ice. We develop and study various PhilEO model variants with different numbers of parameters and architectures. Finally, we fine-tune the models on the PhilEO Bench for road density estimation, building density pixel-wise regression, and land cover semantic segmentation, and we evaluate the performance. Our results demonstrate that for all n-shots for road density regression, the PhilEO 44M MajorTOM 23TB model outperforms PhilEO Globe 0.5TB 44M. We also show that for most n-shots for road density estimation and building density regression, PhilEO 200M FastTOM outperforms all the other models. The effectiveness of both dataset and model scaling is validated using the PhilEO Bench. We also study the impact of architecture scaling, transitioning from U-Net Convolutional Neural Networks (CNN) to Vision Transformers (ViT).

</details>


### [71] [ASCD: Attention-Steerable Contrastive Decoding for Reducing Hallucination in MLLM](https://arxiv.org/abs/2506.14766)
*Yujun Wang,Jinhe Bi,Yunpu Ma,Soeren Pirk*

Main category: cs.CV

TL;DR: 本文提出了一种基于注意力机制的对比解码框架，通过直接干预模型内部注意力分布，显著减少多模态大语言模型的幻觉问题，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）常因过度依赖部分线索而产生幻觉，现有方法（如VCD和ICD）虽有效但未深入探索其内部机制。本文发现这些方法通过改变注意力分布发挥作用，从而提出更直接的干预方法。

Method: 提出了一种注意力可引导的对比解码框架，直接干预模型的注意力机制，以更系统地减少幻觉。

Result: 实验表明，该方法在POPE、CHAIR和MMHal-Bench等基准测试中显著减少幻觉，同时在标准VQA任务中提升性能。

Conclusion: 通过直接干预注意力机制，本文提出的框架为减少MLLM幻觉提供了更有效和理论支持的方法。

Abstract: Multimodal Large Language Model (MLLM) often suffer from hallucinations. They over-rely on partial cues and generate incorrect responses. Recently, methods like Visual Contrastive Decoding (VCD) and Instruction Contrastive Decoding (ICD) have been proposed to mitigate hallucinations by contrasting predictions from perturbed or negatively prefixed inputs against original outputs. In this work, we uncover that methods like VCD and ICD fundamentally influence internal attention dynamics of the model. This observation suggests that their effectiveness may not stem merely from surface-level modifications to logits but from deeper shifts in attention distribution. Inspired by this insight, we propose an attention-steerable contrastive decoding framework that directly intervenes in attention mechanisms of the model to offer a more principled approach to mitigating hallucinations. Our experiments across multiple MLLM architectures and diverse decoding methods demonstrate that our approach significantly reduces hallucinations and improves the performance on benchmarks such as POPE, CHAIR, and MMHal-Bench, while simultaneously enhancing performance on standard VQA benchmarks.

</details>


### [72] [CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal Diffusion](https://arxiv.org/abs/2506.14769)
*Jiahua Ma,Yiran Qin,Yixiong Li,Xuanqi Liao,Yulan Guo,Ruimao Zhang*

Main category: cs.CV

TL;DR: CDP（因果扩散策略）通过结合历史动作序列提升动作预测能力，解决了传统扩散策略在硬件限制和实时约束下的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 硬件限制和实时约束导致专家示范数据质量下降，影响机器人行为学习效果，特别是在物体定位、抓取规划和长时任务执行中。

Method: 提出基于Transformer的扩散模型CDP，利用历史动作序列进行条件预测，并引入缓存机制减少计算冗余。

Result: 在模拟和真实环境中，CDP在多种2D和3D操作任务中显著优于现有方法，且在输入质量下降时仍保持高精度。

Conclusion: CDP通过时间连续性推理提升了机器人控制的鲁棒性，适用于实际不完美条件。

Abstract: Diffusion Policy (DP) enables robots to learn complex behaviors by imitating expert demonstrations through action diffusion. However, in practical applications, hardware limitations often degrade data quality, while real-time constraints restrict model inference to instantaneous state and scene observations. These limitations seriously reduce the efficacy of learning from expert demonstrations, resulting in failures in object localization, grasp planning, and long-horizon task execution. To address these challenges, we propose Causal Diffusion Policy (CDP), a novel transformer-based diffusion model that enhances action prediction by conditioning on historical action sequences, thereby enabling more coherent and context-aware visuomotor policy learning. To further mitigate the computational cost associated with autoregressive inference, a caching mechanism is also introduced to store attention key-value pairs from previous timesteps, substantially reducing redundant computations during execution. Extensive experiments in both simulated and real-world environments, spanning diverse 2D and 3D manipulation tasks, demonstrate that CDP uniquely leverages historical action sequences to achieve significantly higher accuracy than existing methods. Moreover, even when faced with degraded input observation quality, CDP maintains remarkable precision by reasoning through temporal continuity, which highlights its practical robustness for robotic control under realistic, imperfect conditions.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [73] [ReFrame: Layer Caching for Accelerated Inference in Real-Time Rendering](https://arxiv.org/abs/2506.13814)
*Lufei Liu,Tor M. Aamodt*

Main category: cs.GR

TL;DR: ReFrame通过缓存中间特征优化实时渲染任务，在质量损失可忽略的情况下实现平均1.4倍加速。


<details>
  <summary>Details</summary>
Motivation: 利用渲染任务中的时间一致性，避免冗余计算以提高效率。

Method: 扩展缓存中间特征的方法至实时渲染，探索不同缓存策略以平衡质量与性能。

Result: 在三种实时渲染任务中实现平均1.4倍加速，质量损失可忽略。

Conclusion: ReFrame适用于多种编码器-解码器网络，有效优化渲染性能。

Abstract: Graphics rendering applications increasingly leverage neural networks in tasks such as denoising, supersampling, and frame extrapolation to improve image quality while maintaining frame rates. The temporal coherence inherent in these tasks presents an opportunity to reuse intermediate results from previous frames and avoid redundant computations. Recent work has shown that caching intermediate features to be reused in subsequent inferences is an effective method to reduce latency in diffusion models. We extend this idea to real-time rendering and present ReFrame, which explores different caching policies to optimize trade-offs between quality and performance in rendering workloads. ReFrame can be applied to a variety of encoder-decoder style networks commonly found in rendering pipelines. Experimental results show that we achieve 1.4x speedup on average with negligible quality loss in three real-time rendering tasks. Code available: https://ubc-aamodt-group.github.io/reframe-layer-caching/

</details>


### [74] [Balancing Preservation and Modification: A Region and Semantic Aware Metric for Instruction-Based Image Editing](https://arxiv.org/abs/2506.13827)
*Zhuoying Li,Zhu Xu,Yuxin Peng,Yang Liu*

Main category: cs.GR

TL;DR: 论文提出了一种名为BPM的新指标，用于评估基于指令的图像编辑质量，通过明确分离编辑相关和无关区域，实现全面评估。


<details>
  <summary>Details</summary>
Motivation: 现有指标要么成本高，要么无法全面评估编辑质量和无关区域保留，导致评估偏差。

Method: BPM通过定位编辑相关区域，采用两阶段评估（区域感知和语义感知）来综合评估编辑质量。

Result: BPM在实验数据上表现最佳，与人工评估一致性最高。

Conclusion: BPM是一种高效且全面的评估指标，并可集成到图像编辑方法中提升质量。

Abstract: Instruction-based image editing, which aims to modify the image faithfully according to the instruction while preserving irrelevant content unchanged, has made significant progress. However, there still lacks a comprehensive metric for assessing the editing quality. Existing metrics either require high human evaluation costs, which hinder large-scale evaluation, or are adapted from other tasks and lose task-specific concerns, failing to comprehensively evaluate both instruction-based modification and preservation of irrelevant regions, resulting in biased evaluation. To tackle this, we introduce a new metric called Balancing Preservation and Modification (BPM), tailored for instruction-based image editing by explicitly disentangling the image into editing-relevant and irrelevant regions for specific consideration. We first identify and locate editing-relevant regions, followed by a two-tier process to assess editing quality: Region-Aware Judge evaluates whether the position and size of the edited region align with the instruction, and Semantic-Aware Judge further assesses the instruction content compliance within editing-relevant regions as well as content preservation within irrelevant regions, yielding comprehensive and interpretable quality assessment. Moreover, the editing-relevant region localization in BPM can be integrated into image editing approaches to improve editing quality, demonstrating its broad applicability. We verify the effectiveness of the BPM metric on comprehensive instruction-editing data, and the results show the highest alignment with human evaluation compared to existing metrics, indicating its efficacy. Code is available at: https://joyli-x.github.io/BPM/

</details>


### [75] [Innovating China's Intangible Cultural Heritage with DeepSeek + MidJourney: The Case of Yangliuqing theme Woodblock Prints](https://arxiv.org/abs/2506.14104)
*RuiKun Yang,ZhongLiang Wei,Longdi Xian*

Main category: cs.GR

TL;DR: 研究采用DeepSeek + MidJourney方法生成杨柳青年画主题图像，结合传统元素与AI创造力，取得最低FID分数（150.2）和最高参与者认可。


<details>
  <summary>Details</summary>
Motivation: 解决传统杨柳青年画在创新与保存中的挑战，探索AI与传统艺术的结合。

Method: 结合DeepSeek生成主题提示、MidJourney生成主题图像、原始年画及关键提示，通过FID评分和问卷调查评估。

Result: 混合方法FID分数最低（150.2），参与者反馈最积极，认可其代表性和文化推广意愿。

Conclusion: AI与传统艺术的结合有效促进文化保存与创新，具有当代意义。

Abstract: Yangliuqing woodblock prints, a cornerstone of China's intangible cultural heritage, are celebrated for their intricate designs and vibrant colors. However, preserving these traditional art forms while fostering innovation presents significant challenges. This study explores the DeepSeek + MidJourney approach to generating creative, themed Yangliuqing woodblock prints focused on the fight against COVID-19 and depicting joyous winners. Using Fréchet Inception Distance (FID) scores for evaluation, the method that combined DeepSeek-generated thematic prompts, MidJourney-generated thematic images, original Yangliuqing prints, and DeepSeek-generated key prompts in MidJourney-generated outputs achieved the lowest mean FID score (150.2) with minimal variability (σ = 4.9). Additionally, feedback from 62 participants, collected via questionnaires, confirmed that this hybrid approach produced the most representative results. Moreover, the questionnaire data revealed that participants demonstrated the highest willingness to promote traditional culture and the strongest interest in consuming the AI-generated images produced through this method. These findings underscore the effectiveness of an innovative approach that seamlessly blends traditional artistic elements with modern AI-driven creativity, ensuring both cultural preservation and contemporary relevance.

</details>


### [76] [ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies](https://arxiv.org/abs/2506.14315)
*Jinyan Yuan,Bangbang Yang,Keke Wang,Panwang Pan,Lin Ma,Xuehai Zhang,Xiao Liu,Zhaopeng Cui,Yuewen Ma*

Main category: cs.GR

TL;DR: ImmerseGen提出了一种基于代理引导的轻量级几何代理和纹理合成方法，用于高效生成逼真的3D VR场景，简化了传统复杂的建模流程。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法依赖高多边形建模或大量3D高斯分布，导致流程复杂或视觉真实感不足。ImmerseGen旨在通过轻量级代理和纹理合成实现高效且逼真的场景建模。

Method: ImmerseGen使用分层轻量级几何代理（如简化地形和广告牌网格）表示场景，并通过合成RGBA纹理生成逼真外观。结合地形条件纹理和RGBA资产纹理，利用VLM代理进行语义网格分析以自动化场景生成。

Result: 实验表明，ImmerseGen在视觉真实感、空间一致性和渲染效率上优于现有方法，适用于移动VR设备的实时渲染。

Conclusion: ImmerseGen通过简化建模流程和直接纹理合成，实现了高效且逼真的3D场景生成，为VR沉浸式体验提供了新思路。

Abstract: Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground scenery.This reformulation offers several advantages: (i) it simplifies modeling by enabling agents to guide generative models in producing coherent textures that integrate seamlessly with the scene; (ii) it bypasses complex geometry creation and decimation by directly synthesizing photorealistic textures on proxies, preserving visual quality without degradation; (iii) it enables compact representations suitable for real-time rendering on mobile VR headsets. To automate scene creation from text prompts, we introduce VLM-based modeling agents enhanced with semantic grid-based analysis for improved spatial reasoning and accurate asset placement. ImmerseGen further enriches scenes with dynamic effects and ambient audio to support multisensory immersion. Experiments on scene generation and live VR showcases demonstrate that ImmerseGen achieves superior photorealism, spatial coherence and rendering efficiency compared to prior methods. Project webpage: https://immersegen.github.io.

</details>


### [77] [GHAR: GeoPose-based Handheld Augmented Reality for Architectural Positioning, Manipulation and Visual Exploration](https://arxiv.org/abs/2506.14414)
*Sabahat Israr,Dawar Khan,Zhanglin Cheng,Mukhtaj Khan,Kiyoshi Kiyokawa*

Main category: cs.GR

TL;DR: 提出了一种基于GeoPose的无标记手持增强现实（HAR）框架GHAR，用于建筑模型的可视化和操作，相比传统标记系统在可用性、操作性和理解性上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前标记跟踪技术在HAR中存在使用和安装困难、对光线敏感等问题，限制了其在基础设施领域的应用。

Method: 采用GeoPose跟踪技术，支持7自由度操作（平移、旋转和缩放），并通过手势实现交互。

Result: 用户研究表明，GHAR在可用性、操作性和理解性上显著优于传统标记系统。

Conclusion: 无标记HAR框架GHAR为建筑模型的可视化和规划提供了更高效的工具，具有实际应用潜力。

Abstract: Handheld Augmented Reality (HAR) is revolutionizing the civil infrastructure application domain. The current trend in HAR relies on marker tracking technology. However, marker-based systems have several limitations, such as difficulty in use and installation, sensitivity to light, and marker design. In this paper, we propose a markerless HAR framework with GeoPose-based tracking. We use different gestures for manipulation and achieve 7 DOF (3 DOF each for translation and rotation, and 1 DOF for scaling). The proposed framework, called GHAR, is implemented for architectural building models. It augments virtual CAD models of buildings on the ground, enabling users to manipulate and visualize an architectural model before actual construction. The system offers a quick view of the building infrastructure, playing a vital role in requirement analysis and planning in construction technology. We evaluated the usability, manipulability, and comprehensibility of the proposed system using a standard user study with the System Usability Scale (SUS) and Handheld Augmented Reality User Study (HARUS). We compared our GeoPose-based markerless HAR framework with a marker-based HAR framework, finding significant improvement in the aforementioned three parameters with the markerless framework.

</details>


### [78] [SkinCells: Sparse Skinning using Voronoi Cells](https://arxiv.org/abs/2506.14714)
*Egor Larionov,Igor Santesteban,Hsiao-yu Chen,Gene Lin,Philipp Herholz,Ryan Goldade,Ladislav Kavan,Doug Roble,Tuur Stuyck*

Main category: cs.GR

TL;DR: 提出了一种全自动且鲁棒的方法，用于生成高质量的蒙皮权重，支持稀疏控制和多细节层次（LoD）优化。


<details>
  <summary>Details</summary>
Motivation: 当前自动化工具在复杂几何体上难以达到高质量蒙皮权重，仍需手动调整。

Method: 引入SkinCells函数家族，优化空间权重而非离散点，支持稀疏控制和LoD应用。

Result: 方法在双谐权重计算失败的情况下仍能鲁棒地计算蒙皮权重。

Conclusion: 该方法为大规模移动应用提供了高效的资产创建解决方案。

Abstract: For decades, efficient real-time skinning methods have played a crucial role in animating character rigs for visual effects and games. These methods remain a fundamental component of modern applications. However, animatable digital asset creation predominantly remains a manual process. Current automated tools often fall short of delivering the desired level of quality for intricate and complex geometries, requiring manual touch-ups. We propose a fully automatic and robust method for generating high quality skinning weights given a user-provided skeleton and mesh in A- or T-pose. Notably, our approach provides direct sparsity controls, limiting the number of bone influences per vertex, which is essential for efficient asset creation for large-scale mobile experiences with multiple concurrent users. Our method additionally addresses the need for level-of-detail (LoD) variations in performance-sensitive applications, which are exacerbated on mobile platforms. By optimizing weights in space rather than on discrete points, we enable a single optimization result to be seamlessly applied to all levels of detail of that asset or even variations of that asset. To achieve this, we introduce a novel parameterized family of functions called SkinCells. We demonstrate how our automatic method is able to robustly compute skinning weights in cases where biharmonic weight computation fails.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [79] [ClimateChat: Designing Data and Methods for Instruction Tuning LLMs to Answer Climate Change Queries](https://arxiv.org/abs/2506.13796)
*Zhou Chen,Xiao Wang,Yuanhong Liao,Ming Lin,Yuqi Bai*

Main category: cs.CL

TL;DR: 该研究提出了一种自动化构建气候变更指令数据的方法，并创建了ClimateChat-Corpus数据集，用于微调开源LLMs，显著提升了模型在气候变更问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 全球气候变更问题日益严重，但现有研究在高效生成高精度气候变更指令数据方面不足，限制了气候变更LLMs的进一步发展。

Method: 通过从文档中提取事实和背景知识生成指令，结合网络爬取和种子指令收集增强数据多样性，构建ClimateChat-Corpus数据集并微调LLMs。

Result: ClimateChat在气候变更问答任务中表现显著提升，同时评估了不同基础模型和指令数据对性能的影响。

Conclusion: 该研究为构建气候变更指令数据和训练专用LLMs提供了重要参考，强调了选择合适基础模型的重要性。

Abstract: As the issue of global climate change becomes increasingly severe, the demand for research in climate science continues to grow. Natural language processing technologies, represented by Large Language Models (LLMs), have been widely applied to climate change-specific research, providing essential information support for decision-makers and the public. Some studies have improved model performance on relevant tasks by constructing climate change-related instruction data and instruction-tuning LLMs. However, current research remains inadequate in efficiently producing large volumes of high-precision instruction data for climate change, which limits further development of climate change LLMs. This study introduces an automated method for constructing instruction data. The method generates instructions using facts and background knowledge from documents and enhances the diversity of the instruction data through web scraping and the collection of seed instructions. Using this method, we constructed a climate change instruction dataset, named ClimateChat-Corpus, which was used to fine-tune open-source LLMs, resulting in an LLM named ClimateChat. Evaluation results show that ClimateChat significantly improves performance on climate change question-and-answer tasks. Additionally, we evaluated the impact of different base models and instruction data on LLM performance and demonstrated its capability to adapt to a wide range of climate change scientific discovery tasks, emphasizing the importance of selecting an appropriate base model for instruction tuning. This research provides valuable references and empirical support for constructing climate change instruction data and training climate change-specific LLMs.

</details>


### [80] [Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles](https://arxiv.org/abs/2506.13886)
*Antara Raaghavi Bhattacharya,Isabel Papadimitriou,Kathryn Davidson,David Alvarez-Melis*

Main category: cs.CL

TL;DR: LLMs struggle with cross-linguistic numeral systems due to inability to infer implicit compositional rules, unlike humans.


<details>
  <summary>Details</summary>
Motivation: Investigate why LLMs fail at linguistic-mathematical puzzles involving diverse numeral systems, while humans succeed.

Method: Conduct experiments to separate linguistic and mathematical aspects of numbers, testing LLMs with explicitly marked operations.

Result: LLMs only solve problems when mathematical operations are explicitly marked, lacking human-like inference of implicit numeral structure.

Conclusion: Flexible inference of compositional rules from implicit patterns remains a challenge for LLMs.

Abstract: Across languages, numeral systems vary widely in how they construct and combine numbers. While humans consistently learn to navigate this diversity, large language models (LLMs) struggle with linguistic-mathematical puzzles involving cross-linguistic numeral systems, which humans can learn to solve successfully. We investigate why this task is difficult for LLMs through a series of experiments that untangle the linguistic and mathematical aspects of numbers in language. Our experiments establish that models cannot consistently solve such problems unless the mathematical operations in the problems are explicitly marked using known symbols ($+$, $\times$, etc, as in "twenty + three"). In further ablation studies, we probe how individual parameters of numeral construction and combination affect performance. While humans use their linguistic understanding of numbers to make inferences about the implicit compositional structure of numerals, LLMs seem to lack this notion of implicit numeral structure. We conclude that the ability to flexibly infer compositional rules from implicit patterns in human-scale data remains an open challenge for current reasoning models.

</details>


### [81] [VL-GenRM: Enhancing Vision-Language Verification via Vision Experts and Iterative Training](https://arxiv.org/abs/2506.13888)
*Jipeng Zhang,Kehao Miao,Renjie Pi,Zhaowei Wang,Runtao Liu,Rui Pan,Tong Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种迭代训练框架，通过结合视觉专家、思维链（CoT）和基于边缘的拒绝采样，解决了视觉语言奖励模型（VL-RM）训练中的自举困境和模态偏差问题，显著提升了幻觉检测和多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 视觉语言奖励模型（VL-RM）在强化微调（RFT）中具有重要作用，但其训练面临自举困境和模态偏差问题，导致偏好数据质量低，影响模型对齐效果。

Method: 提出了一种迭代训练框架，结合视觉专家、思维链（CoT）和基于边缘的拒绝采样，优化偏好数据集并增强结构化反馈。

Result: 实验表明，该方法在幻觉检测和多模态推理任务中表现优异，显著提升了视觉语言模型的强化学习对齐效果。

Conclusion: 通过迭代训练和结构化反馈，该方法有效解决了VL-RM训练中的关键挑战，为视觉语言模型的强化学习对齐提供了新思路。

Abstract: Reinforcement Fine-Tuning (RFT) with verifiable rewards has advanced large language models but remains underexplored for Vision-Language (VL) models. The Vision-Language Reward Model (VL-RM) is key to aligning VL models by providing structured feedback, yet training effective VL-RMs faces two major challenges. First, the bootstrapping dilemma arises as high-quality training data depends on already strong VL models, creating a cycle where self-generated supervision reinforces existing biases. Second, modality bias and negative example amplification occur when VL models hallucinate incorrect visual attributes, leading to flawed preference data that further misguides training. To address these issues, we propose an iterative training framework leveraging vision experts, Chain-of-Thought (CoT) rationales, and Margin-based Rejection Sampling. Our approach refines preference datasets, enhances structured critiques, and iteratively improves reasoning. Experiments across VL-RM benchmarks demonstrate superior performance in hallucination detection and multimodal reasoning, advancing VL model alignment with reinforcement learning.

</details>


### [82] [EmoNews: A Spoken Dialogue System for Expressive News Conversations](https://arxiv.org/abs/2506.13894)
*Ryuki Matsuura,Shikhar Bharadwaj,Jiarui Liu,Dhatchi Kunde Govindarajan*

Main category: cs.CL

TL;DR: 开发了一个基于上下文的情感对话系统，用于新闻对话，通过情感分析和语音合成提升共情能力。


<details>
  <summary>Details</summary>
Motivation: 任务导向的情感对话系统研究不足，缺乏标准化评估指标，本文旨在填补这一空白。

Method: 利用大型语言模型进行情感分析，结合PromptTTS合成情感语音，并提出了主观评估量表。

Result: 实验表明，该系统在情感调节和用户参与度上优于基线系统。

Conclusion: 语音情感对提升对话参与度至关重要，代码已开源。

Abstract: We develop a task-oriented spoken dialogue system (SDS) that regulates emotional speech based on contextual cues to enable more empathetic news conversations. Despite advancements in emotional text-to-speech (TTS) techniques, task-oriented emotional SDSs remain underexplored due to the compartmentalized nature of SDS and emotional TTS research, as well as the lack of standardized evaluation metrics for social goals. We address these challenges by developing an emotional SDS for news conversations that utilizes a large language model (LLM)-based sentiment analyzer to identify appropriate emotions and PromptTTS to synthesize context-appropriate emotional speech. We also propose subjective evaluation scale for emotional SDSs and judge the emotion regulation performance of the proposed and baseline systems. Experiments showed that our emotional SDS outperformed a baseline system in terms of the emotion regulation and engagement. These results suggest the critical role of speech emotion for more engaging conversations. All our source code is open-sourced at https://github.com/dhatchi711/espnet-emotional-news/tree/emo-sds/egs2/emo_news_sds/sds1

</details>


### [83] [Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise Pooled Representations](https://arxiv.org/abs/2506.13901)
*Abhilekh Borah,Chhavi Sharma,Danush Khanna,Utkarsh Bhatt,Gurpreet Singh,Hasnat Md Abdullah,Raghav Kaushik Ravi,Vinija Jain,Jyoti Patel,Shubham Singh,Vasu Sharma,Arpita Vats,Rahul Raja,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 论文提出了一种新的对齐质量指数（AQI），用于评估大型语言模型（LLM）的对齐性，并通过潜在空间中安全与不安全激活的分离来检测隐藏的未对齐和越狱风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLM进入高风险领域，其行为必须可靠地反映人类对齐的价值观和安全约束，但现有评估方法存在盲点。

Method: 引入AQI，结合多种聚类质量指标（如DBS、DI、XBI、CHI），分析潜在空间中的激活分离，并提出LITMUS数据集以支持评估。

Result: AQI能够揭示传统拒绝指标忽略的漏洞，并与外部评判标准相关。

Conclusion: AQI为行为无关的安全审计提供了强大的工具，并可作为对齐伪造的早期预警信号。

Abstract: Alignment is no longer a luxury, it is a necessity. As large language models (LLMs) enter high-stakes domains like education, healthcare, governance, and law, their behavior must reliably reflect human-aligned values and safety constraints. Yet current evaluations rely heavily on behavioral proxies such as refusal rates, G-Eval scores, and toxicity classifiers, all of which have critical blind spots. Aligned models are often vulnerable to jailbreaking, stochasticity of generation, and alignment faking.
  To address this issue, we introduce the Alignment Quality Index (AQI). This novel geometric and prompt-invariant metric empirically assesses LLM alignment by analyzing the separation of safe and unsafe activations in latent space. By combining measures such as the Davies-Bouldin Score (DBS), Dunn Index (DI), Xie-Beni Index (XBI), and Calinski-Harabasz Index (CHI) across various formulations, AQI captures clustering quality to detect hidden misalignments and jailbreak risks, even when outputs appear compliant. AQI also serves as an early warning signal for alignment faking, offering a robust, decoding invariant tool for behavior agnostic safety auditing.
  Additionally, we propose the LITMUS dataset to facilitate robust evaluation under these challenging conditions. Empirical tests on LITMUS across different models trained under DPO, GRPO, and RLHF conditions demonstrate AQI's correlation with external judges and ability to reveal vulnerabilities missed by refusal metrics. We make our implementation publicly available to foster future research in this area.

</details>


### [84] [ASMR: Augmenting Life Scenario using Large Generative Models for Robotic Action Reflection](https://arxiv.org/abs/2506.13956)
*Shang-Chi Tsai,Seiya Kawano,Angel Garcia Contreras,Koichiro Yoshino,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 论文提出了一种通过数据增强提升机器人意图理解能力的新框架，结合对话和环境图像生成，显著提升了多模态模型的性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人辅助日常活动中，结合视觉和语言线索理解用户意图是一个多模态分类任务，但大规模数据收集困难。

Method: 利用大型语言模型模拟对话和环境上下文，再用稳定扩散模型生成相关图像，增强多模态模型训练。

Result: 实验表明，该方法显著提升了机器人在真实场景中的动作选择能力，达到最先进水平。

Conclusion: 提出的数据增强框架有效解决了多模态数据不足问题，提升了机器人意图理解的准确性。

Abstract: When designing robots to assist in everyday human activities, it is crucial to enhance user requests with visual cues from their surroundings for improved intent understanding. This process is defined as a multimodal classification task. However, gathering a large-scale dataset encompassing both visual and linguistic elements for model training is challenging and time-consuming. To address this issue, our paper introduces a novel framework focusing on data augmentation in robotic assistance scenarios, encompassing both dialogues and related environmental imagery. This approach involves leveraging a sophisticated large language model to simulate potential conversations and environmental contexts, followed by the use of a stable diffusion model to create images depicting these environments. The additionally generated data serves to refine the latest multimodal models, enabling them to more accurately determine appropriate actions in response to user interactions with the limited target data. Our experimental results, based on a dataset collected from real-world scenarios, demonstrate that our methodology significantly enhances the robot's action selection capabilities, achieving the state-of-the-art performance.

</details>


### [85] [Are manual annotations necessary for statutory interpretations retrieval?](https://arxiv.org/abs/2506.13965)
*Aleksander Smywiński-Pohl,Tomer Libal,Adam Kaczmarczyk,Magdalena Król*

Main category: cs.CL

TL;DR: 论文探讨了法律研究中法官对法律概念的扩展解释，并研究了如何优化相关注释过程以减少成本。


<details>
  <summary>Details</summary>
Motivation: 法律研究中需要依赖法官对法律概念的扩展解释作为先例，但现有方法依赖人工注释，成本高昂且需重复。

Method: 通过实验确定最佳注释数量、注释句子选择方式（随机或优选），以及利用LLM自动化注释的效果。

Result: 实验结果揭示了注释数量、句子选择方式及自动化注释对模型性能的影响。

Conclusion: 研究为减少法律概念注释成本提供了实用指导，并验证了自动化注释的潜力。

Abstract: One of the elements of legal research is looking for cases where judges have extended the meaning of a legal concept by providing interpretations of what a concept means or does not mean. This allow legal professionals to use such interpretations as precedents as well as laymen to better understand the legal concept. The state-of-the-art approach for retrieving the most relevant interpretations for these concepts currently depends on the ranking of sentences and the training of language models over annotated examples. That manual annotation process can be quite expensive and need to be repeated for each such concept, which prompted recent research in trying to automate this process. In this paper, we highlight the results of various experiments conducted to determine the volume, scope and even the need for manual annotation. First of all, we check what is the optimal number of annotations per a legal concept. Second, we check if we can draw the sentences for annotation randomly or there is a gain in the performance of the model, when only the best candidates are annotated. As the last question we check what is the outcome of automating the annotation process with the help of an LLM.

</details>


### [86] [AI shares emotion with humans across languages and cultures](https://arxiv.org/abs/2506.13978)
*Xiuwen Wu,Hao Wang,Zhiang Yan,Xiaohan Tang,Pengfei Xu,Wai-Ting Siok,Ping Li,Jia-Hong Gao,Bingjiang Lyu,Lang Qin*

Main category: cs.CL

TL;DR: 论文探讨了AI与人类情感对齐的问题，发现LLM的情感空间与人类感知一致，并能通过心理情感概念精确调控AI的情感输出。


<details>
  <summary>Details</summary>
Motivation: 研究AI系统是否能像人类一样表达情感，以及如何控制其情感输出，以实现更有效的人机协作。

Method: 通过跨语言文化群体和模型家族评估情感对齐，使用可解释的LLM特征分析二十多种情感类别，并利用人类情感概念调控模型输出。

Result: LLM的情感空间与人类感知结构一致，且能准确预测人类行为数据；通过人类情感概念可稳定调控AI的情感表达。

Conclusion: AI不仅与人类共享情感表征，还能通过心理学基础的情感概念精确引导其情感输出。

Abstract: Effective and safe human-machine collaboration requires the regulated and meaningful exchange of emotions between humans and artificial intelligence (AI). Current AI systems based on large language models (LLMs) can provide feedback that makes people feel heard. Yet it remains unclear whether LLMs represent emotion in language as humans do, or whether and how the emotional tone of their output can be controlled. We assess human-AI emotional alignment across linguistic-cultural groups and model-families, using interpretable LLM features translated from concept-sets for over twenty nuanced emotion categories (including six basic emotions). Our analyses reveal that LLM-derived emotion spaces are structurally congruent with human perception, underpinned by the fundamental affective dimensions of valence and arousal. Furthermore, these emotion-related features also accurately predict large-scale behavioural data on word ratings along these two core dimensions, reflecting both universal and language-specific patterns. Finally, by leveraging steering vectors derived solely from human-centric emotion concepts, we show that model expressions can be stably and naturally modulated across distinct emotion categories, which provides causal evidence that human emotion concepts can be used to systematically induce LLMs to produce corresponding affective states when conveying content. These findings suggest AI not only shares emotional representations with humans but its affective outputs can be precisely guided using psychologically grounded emotion concepts.

</details>


### [87] [Lost in the Mix: Evaluating LLM Understanding of Code-Switched Text](https://arxiv.org/abs/2506.14012)
*Amr Mohamed,Yang Zhang,Michalis Vazirgiannis,Guokan Shang*

Main category: cs.CL

TL;DR: 论文系统评估了大语言模型（LLM）对代码切换（CSW）文本的理解能力，发现外语词干扰会降低性能，但将英语嵌入其他语言可能提升理解。微调是缓解性能下降的有效方法。


<details>
  <summary>Details</summary>
Motivation: 代码切换在 multilingual 社区和在线内容中普遍存在，LLM 经常处理此类文本，因此需要研究其对混合语言文本的理解能力。

Method: 通过生成代码切换版本的推理和理解基准，评估 LLM 的表现。

Result: 外语词干扰会降低 LLM 性能，但英语嵌入其他语言可能提升理解；提示效果不稳定，微调更有效。

Conclusion: LLM 对代码切换文本的理解受语言干扰影响，微调是改善性能的稳定方法。

Abstract: Code-switching (CSW) is the act of alternating between two or more languages within a single discourse. This phenomenon is widespread in multilingual communities, and increasingly prevalent in online content, where users naturally mix languages in everyday communication. As a result, Large Language Models (LLMs), now central to content processing and generation, are frequently exposed to code-switched inputs. Given their widespread use, it is crucial to understand how LLMs process and reason about such mixed-language text. This paper presents a systematic evaluation of LLM comprehension under code-switching by generating CSW variants of established reasoning and comprehension benchmarks. While degradation is evident when foreign tokens disrupt English text$\unicode{x2013}$even under linguistic constraints$\unicode{x2013}$embedding English into other languages often improves comprehension. Though prompting yields mixed results, fine-tuning offers a more stable path to degradation mitigation.

</details>


### [88] [MultiFinBen: A Multilingual, Multimodal, and Difficulty-Aware Benchmark for Financial LLM Evaluation](https://arxiv.org/abs/2506.14028)
*Xueqing Peng,Lingfei Qian,Yan Wang,Ruoyu Xiang,Yueru He,Yang Ren,Mingyang Jiang,Jeff Zhao,Huan He,Yi Han,Yun Feng,Yuechen Jiang,Yupeng Cao,Haohang Li,Yangyang Yu,Xiaoyu Wang,Penglei Gao,Shengyuan Lin,Keyi Wang,Shanshan Yang,Yilun Zhao,Zhiwei Liu,Peng Lu,Jerry Huang,Suyuchen Wang,Triantafillos Papadopoulos,Polydoros Giannouris,Efstathia Soufleri,Nuo Chen,Guojun Xiong,Zhiyang Deng,Yijia Zhao,Mingquan Lin,Meikang Qiu,Kaleb E Smith,Arman Cohan,Xiao-Yang Liu,Jimin Huang,Alejandro Lopez-Lira,Xi Chen,Junichi Tsujii,Jian-Yun Nie,Sophia Ananiadou,Qianqian Xie*

Main category: cs.CL

TL;DR: MultiFinBen是首个针对全球金融领域的多语言多模态基准测试，评估LLMs在复杂跨语言和多模态任务中的表现，发现即使最强模型也面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有金融NLP基准测试局限于单语言和单模态，未能反映真实金融场景的复杂性，因此需要更全面的评估工具。

Method: 引入MultiFinBen基准，包含多语言金融QA任务（PolyFiQA-Easy和PolyFiQA-Expert）和OCR嵌入任务（EnglishOCR和SpanishOCR），采用动态难度选择机制。

Result: 评估22个先进模型显示，即使最强模型在复杂跨语言和多模态金融任务中表现不佳。

Conclusion: MultiFinBen的发布旨在推动金融研究和应用的透明、可重复和包容性发展。

Abstract: Recent advances in large language models (LLMs) have accelerated progress in financial NLP and applications, yet existing benchmarks remain limited to monolingual and unimodal settings, often over-relying on simple tasks and failing to reflect the complexity of real-world financial communication. We introduce MultiFinBen, the first multilingual and multimodal benchmark tailored to the global financial domain, evaluating LLMs across modalities (text, vision, audio) and linguistic settings (monolingual, bilingual, multilingual) on domain-specific tasks. We introduce two novel tasks, including PolyFiQA-Easy and PolyFiQA-Expert, the first multilingual financial benchmarks requiring models to perform complex reasoning over mixed-language inputs; and EnglishOCR and SpanishOCR, the first OCR-embedded financial QA tasks challenging models to extract and reason over information from visual-text financial documents. Moreover, we propose a dynamic, difficulty-aware selection mechanism and curate a compact, balanced benchmark rather than simple aggregation existing datasets. Extensive evaluation of 22 state-of-the-art models reveals that even the strongest models, despite their general multimodal and multilingual capabilities, struggle dramatically when faced with complex cross-lingual and multimodal tasks in financial domain. MultiFinBen is publicly released to foster transparent, reproducible, and inclusive progress in financial studies and applications.

</details>


### [89] [An Interdisciplinary Review of Commonsense Reasoning and Intent Detection](https://arxiv.org/abs/2506.14040)
*Md Nazmus Sakib*

Main category: cs.CL

TL;DR: 本文综述了常识推理和意图检测的最新进展，分析了28篇论文，总结了方法与应用，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨自然语言理解中的两大挑战——常识推理和意图检测，以推动更自适应、多语言和上下文感知的模型发展。

Method: 通过分析28篇论文（2020-2025年），按方法和应用分类，分别研究常识推理和意图检测的不同技术方向。

Result: 总结了常识推理和意图检测的当前趋势，包括零样本学习、文化适应、生成模型等，并指出了基准设计和泛化能力的不足。

Conclusion: 未来研究需关注模型的适应性、多语言能力和上下文感知，同时解决基准设计和泛化问题。

Abstract: This review explores recent advances in commonsense reasoning and intent detection, two key challenges in natural language understanding. We analyze 28 papers from ACL, EMNLP, and CHI (2020-2025), organizing them by methodology and application. Commonsense reasoning is reviewed across zero-shot learning, cultural adaptation, structured evaluation, and interactive contexts. Intent detection is examined through open-set models, generative formulations, clustering, and human-centered systems. By bridging insights from NLP and HCI, we highlight emerging trends toward more adaptive, multilingual, and context-aware models, and identify key gaps in grounding, generalization, and benchmark design.

</details>


### [90] [Ace-CEFR -- A Dataset for Automated Evaluation of the Linguistic Difficulty of Conversational Texts for LLM Applications](https://arxiv.org/abs/2506.14046)
*David Kogan,Max Schumacher,Sam Nguyen,Masanori Suzuki,Melissa Smith,Chloe Sophia Bellows,Jared Bernstein*

Main category: cs.CL

TL;DR: Ace-CEFR是一个专家标注的英语会话文本难度数据集，用于评估和训练大语言模型（LLMs），实验表明基于该数据集训练的模型在难度评估上优于人类专家。


<details>
  <summary>Details</summary>
Motivation: 评估短会话文本的语言难度对LLMs的训练和筛选至关重要，但目前缺乏相关数据集。

Method: 引入Ace-CEFR数据集，并使用Transformer模型和LLMs进行实验。

Result: 基于Ace-CEFR训练的模型在难度评估上比人类专家更准确，且延迟适合生产环境。

Conclusion: Ace-CEFR数据集公开发布，为研究和开发提供支持。

Abstract: There is an unmet need to evaluate the language difficulty of short, conversational passages of text, particularly for training and filtering Large Language Models (LLMs). We introduce Ace-CEFR, a dataset of English conversational text passages expert-annotated with their corresponding level of text difficulty. We experiment with several models on Ace-CEFR, including Transformer-based models and LLMs. We show that models trained on Ace-CEFR can measure text difficulty more accurately than human experts and have latency appropriate to production environments. Finally, we release the Ace-CEFR dataset to the public for research and development.

</details>


### [91] [Automatic Extraction of Clausal Embedding Based on Large-Scale English Text Data](https://arxiv.org/abs/2506.14064)
*Iona Carslaw,Sivan Milton,Nicolas Navarre,Ciyang Qing,Wataru Uegaki*

Main category: cs.CL

TL;DR: 提出了一种基于选区解析和启发式规则的方法，用于从大规模文本数据中检测和标注英语嵌入式从句的自然实例，并发布了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 当前研究依赖人工构造的语言示例，缺乏从大规模语料库中获取的统计信息和自然实例。

Method: 使用选区解析和一组解析启发式规则，检测和标注英语嵌入式从句的自然实例。

Result: 在Golden Embedded Clause Set（GECS）上评估了工具，并提取了Dolma语料库中的大规模自然嵌入式从句数据集。

Conclusion: 提出了一种有效的方法和工具，并发布了自然嵌入式从句的大规模数据集。

Abstract: For linguists, embedded clauses have been of special interest because of their intricate distribution of syntactic and semantic features. Yet, current research relies on schematically created language examples to investigate these constructions, missing out on statistical information and naturally-occurring examples that can be gained from large language corpora. Thus, we present a methodological approach for detecting and annotating naturally-occurring examples of English embedded clauses in large-scale text data using constituency parsing and a set of parsing heuristics. Our tool has been evaluated on our dataset Golden Embedded Clause Set (GECS), which includes hand-annotated examples of naturally-occurring English embedded clause sentences. Finally, we present a large-scale dataset of naturally-occurring English embedded clauses which we have extracted from the open-source corpus Dolma using our extraction tool.

</details>


### [92] [Abstract Meaning Representation for Hospital Discharge Summarization](https://arxiv.org/abs/2506.14101)
*Paul Landes,Sitara Rao,Aaron Jeremy Chaise,Barbara Di Eugenio*

Main category: cs.CL

TL;DR: 本文提出了一种结合语言图和深度学习模型的新方法，用于解决大型语言模型在自动生成出院摘要时的幻觉问题，提高了内容的可信度和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的幻觉问题在临床领域可能带来严重后果，尤其是自动生成长篇医疗文档（如出院摘要）时。解决这一问题可以减轻医生负担，提高效率。

Method: 结合语言图和深度学习模型，确保自动生成的出院摘要内容的可信度和可追溯性。

Result: 在公开的MIMIC-III数据集和匿名医院的临床笔记上，该方法表现出显著的可靠性。

Conclusion: 该方法为自动生成医疗文档提供了更可靠的解决方案，减少了幻觉问题，具有实际应用价值。

Abstract: The Achilles heel of Large Language Models (LLMs) is hallucination, which has drastic consequences for the clinical domain. This is particularly important with regards to automatically generating discharge summaries (a lengthy medical document that summarizes a hospital in-patient visit). Automatically generating these summaries would free physicians to care for patients and reduce documentation burden. The goal of this work is to discover new methods that combine language-based graphs and deep learning models to address provenance of content and trustworthiness in automatic summarization. Our method shows impressive reliability results on the publicly available Medical Information Mart for Intensive III (MIMIC-III) corpus and clinical notes written by physicians at Anonymous Hospital. rovide our method, generated discharge ary output examples, source code and trained models.

</details>


### [93] [Essential-Web v1.0: 24T tokens of organized web data](https://arxiv.org/abs/2506.14111)
*Essential AI,:,Andrew Hojel,Michael Pust,Tim Romanski,Yash Vanjani,Ritvik Kapila,Mohit Parmar,Adarsh Chaluvaraju,Alok Tripathy,Anil Thomas,Ashish Tanwer,Darsh J Shah,Ishaan Shah,Karl Stratos,Khoi Nguyen,Kurt Smith,Michael Callahan,Peter Rushton,Philip Monk,Platon Mazarakis,Saad Jamal,Saurabh Srivastava,Somanshu Singla,Ashish Vaswani*

Main category: cs.CL

TL;DR: Essential-Web v1.0是一个24万亿token的数据集，每个文档都标注了12类分类法，涵盖主题、格式、内容复杂度和质量。使用SQL式过滤器可生成高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 大规模、组织良好的预训练数据集缺乏，导致数据管道成本高且难以获取。

Method: 使用EAI-Distill-0.5b模型标注数据，并通过SQL式过滤器筛选数据。

Result: 在数学、网页代码、STEM和医学领域生成的数据集表现优异。

Conclusion: Essential-Web v1.0是一个高效且易于使用的数据集，显著提升了数据管道的可访问性。

Abstract: Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0

</details>


### [94] [Sampling from Your Language Model One Byte at a Time](https://arxiv.org/abs/2506.14123)
*Jonathan Hayase,Alisa Liu,Noah A. Smith,Sewoong Oh*

Main category: cs.CL

TL;DR: 本文提出一种推理时方法，将任何使用BPE分词的自回归语言模型转换为字符级或字节级模型，解决分词带来的问题（如Prompt Boundary Problem），并提升模型组合和互操作性。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型普遍使用分词，但分词会引入生成失真（如Prompt Boundary Problem），且不同分词器的不匹配阻碍模型组合和互操作性。

Method: 提出一种推理时方法，将BPE分词的自回归模型转换为字符级或字节级模型，不改变文本生成分布。

Result: 实验证明，该方法能有效解决Prompt Boundary Problem，并支持不同分词器模型的组合和代理调优，提升下游任务表现。

Conclusion: 该方法解决了分词带来的问题，提升了模型的组合能力和互操作性，实验验证了其有效性。

Abstract: Tokenization is used almost universally by modern language models, enabling efficient text representation using multi-byte or multi-character tokens. However, prior work has shown that tokenization can introduce distortion into the model's generations. For example, users are often advised not to end their prompts with a space because it prevents the model from including the space as part of the next token. This Prompt Boundary Problem (PBP) also arises in languages such as Chinese and in code generation, where tokens often do not line up with syntactic boundaries. Additionally mismatching tokenizers often hinder model composition and interoperability. For example, it is not possible to directly ensemble models with different tokenizers due to their mismatching vocabularies. To address these issues, we present an inference-time method to convert any autoregressive LM with a BPE tokenizer into a character-level or byte-level LM, without changing its generative distribution at the text level. Our method efficient solves the PBP and is also able to unify the vocabularies of language models with different tokenizers, allowing one to ensemble LMs with different tokenizers at inference time as well as transfer the post-training from one model to another using proxy-tuning. We demonstrate in experiments that the ensemble and proxy-tuned models outperform their constituents on downstream evals.

</details>


### [95] [DCRM: A Heuristic to Measure Response Pair Quality in Preference Optimization](https://arxiv.org/abs/2506.14157)
*Chengyu Huang,Tanya Goyal*

Main category: cs.CL

TL;DR: 论文提出了一种名为DCRM的指标，用于量化偏好优化中响应对的差异质量，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究发现偏好优化性能与底层偏好数据集相关，但现有方法可能无法捕捉到理想的学习差异。

Method: 使用距离和奖励边际量化响应差异，提出DCRM指标，并设计了一种基于DCRM的最佳配对方法。

Result: 实验表明，DCRM较高的训练集能带来更好的学习效果，新方法在多个基准测试中表现更优。

Conclusion: DCRM是衡量偏好数据集质量的有效指标，基于其的配对方法能进一步提升模型性能。

Abstract: Recent research has attempted to associate preference optimization (PO) performance with the underlying preference datasets. In this work, our observation is that the differences between the preferred response $y^+$ and dispreferred response $y^-$ influence what LLMs can learn, which may not match the desirable differences to learn. Therefore, we use distance and reward margin to quantify these differences, and combine them to get Distance Calibrated Reward Margin (DCRM), a metric that measures the quality of a response pair for PO. Intuitively, DCRM encourages minimal noisy differences and maximal desired differences. With this, we study 3 types of commonly used preference datasets, classified along two axes: the source of the responses and the preference labeling function. We establish a general correlation between higher DCRM of the training set and better learning outcome. Inspired by this, we propose a best-of-$N^2$ pairing method that selects response pairs with the highest DCRM. Empirically, in various settings, our method produces training datasets that can further improve models' performance on AlpacaEval, MT-Bench, and Arena-Hard over the existing training sets.

</details>


### [96] [S$^4$C: Speculative Sampling with Syntactic and Semantic Coherence for Efficient Inference of Large Language Models](https://arxiv.org/abs/2506.14158)
*Tao He,Guang Huang,Yu Yang,Tianshi Xu,Sicheng Zhao,Guiguang Ding,Pengyang Wang,Feng Tian*

Main category: cs.CL

TL;DR: S$^4$C框架通过引入语法和语义一致性改进推测采样，显著提升推理速度，减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决自回归语言模型推理延迟高的问题，同时提升文本生成的一致性和效率。

Method: 结合多头草稿生成和连续验证树，优化推测采样的并行性和特征复用。

Result: 在主流任务中表现优于基线方法，加速比达2.26x-2.60x。

Conclusion: S$^4$C框架在推理速度和资源效率上显著优于现有方法，适用于实时应用。

Abstract: Large language models (LLMs) exhibit remarkable reasoning capabilities across diverse downstream tasks. However, their autoregressive nature leads to substantial inference latency, posing challenges for real-time applications. Speculative sampling mitigates this issue by introducing a drafting phase followed by a parallel validation phase, enabling faster token generation and verification. Existing approaches, however, overlook the inherent coherence in text generation, limiting their efficiency. To address this gap, we propose a Speculative Sampling with Syntactic and Semantic Coherence (S$^4$C) framework, which extends speculative sampling by leveraging multi-head drafting for rapid token generation and a continuous verification tree for efficient candidate validation and feature reuse. Experimental results demonstrate that S$^4$C surpasses baseline methods across mainstream tasks, offering enhanced efficiency, parallelism, and the ability to generate more valid tokens with fewer computational resources. On Spec-bench benchmarks, S$^4$C achieves an acceleration ratio of 2.26x-2.60x, outperforming state-of-the-art methods.

</details>


### [97] [MIST: Towards Multi-dimensional Implicit Bias and Stereotype Evaluation of LLMs via Theory of Mind](https://arxiv.org/abs/2506.14161)
*Yanlin Li,Hao Liu,Huimin Liu,Yinwei Wei,Yupeng Hu*

Main category: cs.CL

TL;DR: 该论文提出了一种基于刻板印象内容模型（SCM）的评估框架，用于检测大型语言模型（ToM）中的多维隐性偏见，并通过间接任务（WABT和AAT）揭示其复杂结构。


<details>
  <summary>Details</summary>
Motivation: 传统直接查询方法难以捕捉隐性偏见的微妙多维特性，且易受社会期望效应影响，因此需要更稳健的评估方法。

Method: 提出基于SCM的框架，设计两种间接任务（WABT和AAT），分别评估词汇联想偏见和情感倾向，避免模型回避。

Result: 在8个先进LLM上的实验表明，该框架能揭示复杂偏见结构，如普遍的社会性偏见、多维分歧和非对称刻板印象放大。

Conclusion: 该框架为识别隐性偏见的结构性本质提供了更稳健的方法。

Abstract: Theory of Mind (ToM) in Large Language Models (LLMs) refers to their capacity for reasoning about mental states, yet failures in this capacity often manifest as systematic implicit bias. Evaluating this bias is challenging, as conventional direct-query methods are susceptible to social desirability effects and fail to capture its subtle, multi-dimensional nature. To this end, we propose an evaluation framework that leverages the Stereotype Content Model (SCM) to reconceptualize bias as a multi-dimensional failure in ToM across Competence, Sociability, and Morality. The framework introduces two indirect tasks: the Word Association Bias Test (WABT) to assess implicit lexical associations and the Affective Attribution Test (AAT) to measure covert affective leanings, both designed to probe latent stereotypes without triggering model avoidance. Extensive experiments on 8 State-of-the-Art LLMs demonstrate our framework's capacity to reveal complex bias structures, including pervasive sociability bias, multi-dimensional divergence, and asymmetric stereotype amplification, thereby providing a more robust methodology for identifying the structural nature of implicit bias.

</details>


### [98] [GRAM: A Generative Foundation Reward Model for Reward Generalization](https://arxiv.org/abs/2506.14175)
*Chenglong Wang,Yang Gan,Yifu Huo,Yongyu Mu,Qiaozhi He,Murun Yang,Bei Li,Tong Xiao,Chunliang Zhang,Tongran Liu,Jingbo Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种结合无监督和有监督学习的生成式奖励模型，通过标签平滑优化排序损失，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的奖励模型仅依赖标注的人类偏好数据，限制了其泛化能力。本文旨在利用无监督和有监督数据训练更通用的奖励模型。

Method: 开发了一种生成式奖励模型，先通过大规模无监督学习预训练，再通过有监督学习微调，并利用标签平滑优化排序损失。

Result: 模型在响应排序、人类反馈强化学习和任务适应等多个任务中表现优异，显著优于基线模型。

Conclusion: 生成式奖励模型结合无监督和有监督学习，为奖励模型训练提供了新视角，并在多任务中展现了强大的泛化能力。

Abstract: In aligning large language models (LLMs), reward models have played an important role, but are standardly trained as discriminative models and rely only on labeled human preference data. In this paper, we explore methods that train reward models using both unlabeled and labeled data. Building on the generative models in LLMs, we develop a generative reward model that is first trained via large-scale unsupervised learning and then fine-tuned via supervised learning. We also show that by using label smoothing, we are in fact optimizing a regularized pairwise ranking loss. This result, in turn, provides a new view of training reward models, which links generative models and discriminative models under the same class of training objectives. The outcome of these techniques is a foundation reward model, which can be applied to a wide range of tasks with little or no further fine-tuning effort. Extensive experiments show that this model generalizes well across several tasks, including response ranking, reinforcement learning from human feedback, and task adaptation with fine-tuning, achieving significant performance improvements over several strong baseline models.

</details>


### [99] [Can we train ASR systems on Code-switch without real code-switch data? Case study for Singapore's languages](https://arxiv.org/abs/2506.14177)
*Tuan Nguyen,Huy-Dat Tran*

Main category: cs.CL

TL;DR: 研究提出一种短语级混合方法生成合成代码切换数据，用于训练ASR模型，显著提升低资源东南亚语言的识别性能。


<details>
  <summary>Details</summary>
Motivation: 代码切换（CS）在ASR中因数据稀缺和标注成本高而具有挑战性，研究旨在通过合成数据解决这一问题。

Method: 提出短语级混合方法生成合成CS数据，结合单语数据微调预训练ASR模型（如Whisper、MMS、SeamlessM4T）。

Result: 实验显示该方法显著提升ASR性能，尤其在马来语-英语（BM-EN）上表现最佳。

Conclusion: 合成CS数据为低资源语言的CS-ASR开发提供了经济高效的解决方案。

Abstract: Code-switching (CS), common in multilingual settings, presents challenges for ASR due to scarce and costly transcribed data caused by linguistic complexity. This study investigates building CS-ASR using synthetic CS data. We propose a phrase-level mixing method to generate synthetic CS data that mimics natural patterns. Utilizing monolingual augmented with synthetic phrase-mixed CS data to fine-tune large pretrained ASR models (Whisper, MMS, SeamlessM4T). This paper focuses on three under-resourced Southeast Asian language pairs: Malay-English (BM-EN), Mandarin-Malay (ZH-BM), and Tamil-English (TA-EN), establishing a new comprehensive benchmark for CS-ASR to evaluate the performance of leading ASR models. Experimental results show that the proposed training strategy enhances ASR performance on monolingual and CS tests, with BM-EN showing highest gains, then TA-EN and ZH-BM. This finding offers a cost-effective approach for CS-ASR development, benefiting research and industry.

</details>


### [100] [AsyncSwitch: Asynchronous Text-Speech Adaptation for Code-Switched ASR](https://arxiv.org/abs/2506.14190)
*Tuan Nguyen,Huy-Dat Tran*

Main category: cs.CL

TL;DR: AsyncSwitch是一种异步适应框架，利用大规模文本数据预训练ASR模型，再通过有限语音-文本数据微调，显著降低代码切换语音识别的错误率。


<details>
  <summary>Details</summary>
Motivation: 开发代码切换ASR系统面临语言歧义和多语言数据不足的挑战，传统合成音频方法计算成本高且难以扩展。

Method: 采用三阶段方法：1）用代码切换文本训练解码器自注意力和前馈层；2）用有限语音-文本数据对齐解码器和编码器；3）完整微调模型。

Result: 在马来语-英语代码切换实验中，Whisper模型的WER相对降低9.02%，同时在单语任务（如新加坡英语、马来语等）中表现提升。

Conclusion: AsyncSwitch通过文本数据预训练和分阶段微调，有效提升代码切换ASR性能，同时优化单语任务表现。

Abstract: Developing code-switched ASR systems is challenging due to language ambiguity and limited exposure to multilingual, code-switched data, while collecting such speech is costly. Prior work generates synthetic audio from text, but these methods are computationally intensive and hard to scale. We introduce AsyncSwitch, a novel asynchronous adaptation framework that leverages large-scale, text-rich web data to pre-expose ASR models to diverse code-switched domains before fine-tuning on paired speech-text corpora. Our three-stage process (1) trains decoder self-attention and feedforward layers on code-switched text, (2) aligns decoder and encoder via cross-attention using limited speech-text data, and (3) fully fine-tunes the entire model. Experiments with Whisper on Malay-English code-switching demonstrate a 9.02% relative WER reduction, while improving monolingual performance in Singlish, Malay, and other English variants.

</details>


### [101] [MAS-LitEval : Multi-Agent System for Literary Translation Quality Assessment](https://arxiv.org/abs/2506.14199)
*Junghwan Kim,Kieun Park,Sohee Park,Hyunggug Kim,Bongwon Suh*

Main category: cs.CL

TL;DR: MAS-LitEval是一种基于多代理系统和大型语言模型的翻译评估方法，专注于文学翻译中的术语、叙事和风格，优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 传统翻译评估指标（如BLEU和METEOR）无法捕捉文学翻译中的文化细微差别和风格元素，需要一种更全面的评估方法。

Method: 提出MAS-LitEval，利用多代理系统和大型语言模型评估翻译质量，测试了《小王子》和《亚瑟王朝廷上的康涅狄格北方佬》的翻译。

Result: MAS-LitEval在捕捉文学细微差别方面表现优异，最高得分达0.890，优于传统指标。

Conclusion: MAS-LitEval为翻译质量评估提供了一个可扩展且细致的框架，对翻译者和研究者具有实用价值。

Abstract: Literary translation requires preserving cultural nuances and stylistic elements, which traditional metrics like BLEU and METEOR fail to assess due to their focus on lexical overlap. This oversight neglects the narrative consistency and stylistic fidelity that are crucial for literary works. To address this, we propose MAS-LitEval, a multi-agent system using Large Language Models (LLMs) to evaluate translations based on terminology, narrative, and style. We tested MAS-LitEval on translations of The Little Prince and A Connecticut Yankee in King Arthur's Court, generated by various LLMs, and compared it to traditional metrics. \textbf{MAS-LitEval} outperformed these metrics, with top models scoring up to 0.890 in capturing literary nuances. This work introduces a scalable, nuanced framework for Translation Quality Assessment (TQA), offering a practical tool for translators and researchers.

</details>


### [102] [ELI-Why: Evaluating the Pedagogical Utility of Language Model Explanations](https://arxiv.org/abs/2506.14200)
*Brihi Joshi,Keyu He,Sahana Ramnath,Sadra Sabouri,Kaitlyn Zhou,Souti Chattopadhyay,Swabha Swayamdipta,Xiang Ren*

Main category: cs.CL

TL;DR: 论文评估了语言模型在生成适合不同教育背景的解释性答案方面的能力，发现GPT-4的表现不如人工生成的内容。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型如何为不同知识背景的学习者定制回答，以提升其教育应用效果。

Method: 引入ELI-Why基准，包含13.4K个“为什么”问题，并通过两项人类研究评估语言模型生成解释的适用性。

Result: GPT-4生成解释的匹配率仅为50%，低于人工的79%；且学习者认为其解释的适用性平均低20%。

Conclusion: 当前语言模型在定制化教育回答方面仍有局限，需进一步优化。

Abstract: Language models today are widely used in education, yet their ability to tailor responses for learners with varied informational needs and knowledge backgrounds remains under-explored. To this end, we introduce ELI-Why, a benchmark of 13.4K "Why" questions to evaluate the pedagogical capabilities of language models. We then conduct two extensive human studies to assess the utility of language model-generated explanatory answers (explanations) on our benchmark, tailored to three distinct educational grades: elementary, high-school and graduate school. In our first study, human raters assume the role of an "educator" to assess model explanations' fit to different educational grades. We find that GPT-4-generated explanations match their intended educational background only 50% of the time, compared to 79% for lay human-curated explanations. In our second study, human raters assume the role of a learner to assess if an explanation fits their own informational needs. Across all educational backgrounds, users deemed GPT-4-generated explanations 20% less suited on average to their informational needs, when compared to explanations curated by lay people. Additionally, automated evaluation metrics reveal that explanations generated across different language model families for different informational needs remain indistinguishable in their grade-level, limiting their pedagogical effectiveness.

</details>


### [103] [Intended Target Identification for Anomia Patients with Gradient-based Selective Augmentation](https://arxiv.org/abs/2506.14203)
*Jongho Kim,Romain Storaï,Seung-won Hwang*

Main category: cs.CL

TL;DR: 研究探讨语言模型在帮助失语症患者命名困难（anomia）中的潜力，提出两种方法应对术语缺失和语义错误，并在真实患者数据上验证效果。


<details>
  <summary>Details</summary>
Motivation: 失语症患者在命名物品时面临术语缺失和语义错误（语义性错语）的挑战，语言模型可能提供帮助。

Method: 通过梯度选择性增强方法，分别处理语义错误和未见术语问题：梯度值控制数据质量，梯度方差引导相关术语的引入。

Result: 在Tip-of-the-Tongue数据集和AphasiaBank患者数据上表现优于基线模型。

Conclusion: 提出的方法有效解决了失语症患者的命名困难问题，验证了语言模型的潜力。

Abstract: In this study, we investigate the potential of language models (LMs) in aiding patients experiencing anomia, a difficulty identifying the names of items. Identifying the intended target item from patient's circumlocution involves the two challenges of term failure and error: (1) The terms relevant to identifying the item remain unseen. (2) What makes the challenge unique is inherent perturbed terms by semantic paraphasia, which are not exactly related to the target item, hindering the identification process. To address each, we propose robustifying the model from semantically paraphasic errors and enhancing the model with unseen terms with gradient-based selective augmentation. Specifically, the gradient value controls augmented data quality amid semantic errors, while the gradient variance guides the inclusion of unseen but relevant terms. Due to limited domain-specific datasets, we evaluate the model on the Tip-of-the-Tongue dataset as an intermediary task and then apply our findings to real patient data from AphasiaBank. Our results demonstrate strong performance against baselines, aiding anomia patients by addressing the outlined challenges.

</details>


### [104] [AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents](https://arxiv.org/abs/2506.14205)
*Jingxu Xie,Dylan Xu,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: AgentSynth是一种高效、低成本的方法，用于自动合成高质量任务和轨迹数据集，支持通用计算机使用代理的开发。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量、多样化的任务数据集，尤其是长时程任务，AgentSynth旨在填补这一空白。

Method: 利用信息不对称性，通过LLM生成简单子任务，组合为复杂任务，并由执行代理记录轨迹，最终形成可控难度的任务。

Result: 生成了6,000多个多样化任务，实验显示现有LLM代理在难度增加时性能显著下降，且成本仅为每轨迹0.60美元。

Conclusion: AgentSynth提供了一种高效、低成本的任务合成方法，显著提升了任务数据集的多样性和复杂性。

Abstract: We introduce AgentSynth, a scalable and cost-efficient pipeline for automatically synthesizing high-quality tasks and trajectory datasets for generalist computer-use agents. Leveraging information asymmetry, AgentSynth constructs subtasks that are simple during generation but significantly more challenging when composed into long-horizon tasks, enabling the creation of over 6,000 diverse and realistic tasks. Our pipeline begins with an LLM-based task proposer guided by a persona, followed by an execution agent that completes the task and logs the trajectory. This process is repeated iteratively to form a sequence of subtasks, which are then summarized by a separate agent into a composite task of controllable difficulty. A key strength of AgentSynth is its ability to precisely modulate task complexity by varying the number of subtasks. Empirical evaluations show that state-of-the-art LLM agents suffer a steep performance drop, from 18% success at difficulty level 1 to just 4% at level 6, highlighting the benchmark's difficulty and discriminative power. Moreover, our pipeline achieves a low average cost of \$0.60 per trajectory, orders of magnitude cheaper than human annotations. Our code and data are publicly available at https://github.com/sunblaze-ucb/AgentSynth

</details>


### [105] [CausalDiffTab: Mixed-Type Causal-Aware Diffusion for Tabular Data Generation](https://arxiv.org/abs/2506.14206)
*Jia-Chen Zhang,Zheng Zhou,Yu-Jie Xiong,Chun-Ming Xia,Fei Dai*

Main category: cs.CL

TL;DR: CausalDiffTab是一种基于扩散模型的生成模型，专门用于处理混合类型的表格数据，通过自适应因果正则化方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 高质量数据的获取存在隐私和复杂性挑战，尤其是混合类型的表格数据生成。

Method: 提出CausalDiffTab模型，结合扩散模型和自适应因果正则化方法，捕捉变量间复杂关系。

Result: 在七个数据集上的实验表明，CausalDiffTab在所有指标上均优于基线方法。

Conclusion: CausalDiffTab为混合表格数据生成提供了一种高效且灵活的解决方案。

Abstract: Training data has been proven to be one of the most critical components in training generative AI. However, obtaining high-quality data remains challenging, with data privacy issues presenting a significant hurdle. To address the need for high-quality data. Synthesize data has emerged as a mainstream solution, demonstrating impressive performance in areas such as images, audio, and video. Generating mixed-type data, especially high-quality tabular data, still faces significant challenges. These primarily include its inherent heterogeneous data types, complex inter-variable relationships, and intricate column-wise distributions. In this paper, we introduce CausalDiffTab, a diffusion model-based generative model specifically designed to handle mixed tabular data containing both numerical and categorical features, while being more flexible in capturing complex interactions among variables. We further propose a hybrid adaptive causal regularization method based on the principle of Hierarchical Prior Fusion. This approach adaptively controls the weight of causal regularization, enhancing the model's performance without compromising its generative capabilities. Comprehensive experiments conducted on seven datasets demonstrate that CausalDiffTab outperforms baseline methods across all metrics. Our code is publicly available at: https://github.com/Godz-z/CausalDiffTab.

</details>


### [106] [Explainable Detection of Implicit Influential Patterns in Conversations via Data Augmentation](https://arxiv.org/abs/2506.14211)
*Sina Abdidizaji,Md Kowsher,Niloofar Yousefi,Ivan Garibay*

Main category: cs.CL

TL;DR: 本文提出了一种改进的方法来检测对话中的隐性影响力模式，并能够定位这些模式的具体位置。通过增强数据集和设计新框架，检测性能提升了6%，多标签分类任务性能显著提高。


<details>
  <summary>Details</summary>
Motivation: 随着数字化时代的发展，恶意行为者开始利用隐性语言模式影响公众认知，而现有模型难以有效检测这些模式。

Method: 利用先进语言模型的推理能力增强现有数据集，并设计新框架以检测和定位隐性影响力模式。

Result: 检测隐性影响力模式的性能提升了6%，多标签分类任务中技术和受害者脆弱性的识别分别提高了33%和43%。

Conclusion: 该方法有效提升了隐性影响力模式的检测能力，为对抗数字化时代的语言操纵提供了新工具。

Abstract: In the era of digitalization, as individuals increasingly rely on digital platforms for communication and news consumption, various actors employ linguistic strategies to influence public perception. While models have become proficient at detecting explicit patterns, which typically appear in texts as single remarks referred to as utterances, such as social media posts, malicious actors have shifted toward utilizing implicit influential verbal patterns embedded within conversations. These verbal patterns aim to mentally penetrate the victim's mind in order to influence them, enabling the actor to obtain the desired information through implicit means. This paper presents an improved approach for detecting such implicit influential patterns. Furthermore, the proposed model is capable of identifying the specific locations of these influential elements within a conversation. To achieve this, the existing dataset was augmented using the reasoning capabilities of state-of-the-art language models. Our designed framework resulted in a 6% improvement in the detection of implicit influential patterns in conversations. Moreover, this approach improved the multi-label classification tasks related to both the techniques used for influence and the vulnerability of victims by 33% and 43%, respectively.

</details>


### [107] [Chaining Event Spans for Temporal Relation Grounding](https://arxiv.org/abs/2506.14213)
*Jongho Kim,Dohyeon Lee,Minsoo Kim,Seung-won Hwang*

Main category: cs.CL

TL;DR: 论文提出了一种新方法（TRN），通过预测事件时间跨度来解决现有方法因答案重叠导致的不可靠问题，并在多个任务中表现优于先前方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖答案重叠作为代理标签来区分相似问题，但答案重叠可能导致不可靠结果，因为不同问题可能偶然有相同答案。

Method: 提出Timeline Reasoning Network（TRN），采用两步归纳推理：首先生成初步答案，然后通过预测时间线来修正答案。

Result: 在TORQUE、TB-dense、TRC和TRE任务中，TRN表现优于现有方法。

Conclusion: TRN通过时间线预测有效解决了答案重叠问题，提升了任务性能。

Abstract: Accurately understanding temporal relations between events is a critical building block of diverse tasks, such as temporal reading comprehension (TRC) and relation extraction (TRE). For example in TRC, we need to understand the temporal semantic differences between the following two questions that are lexically near-identical: "What finished right before the decision?" or "What finished right after the decision?". To discern the two questions, existing solutions have relied on answer overlaps as a proxy label to contrast similar and dissimilar questions. However, we claim that answer overlap can lead to unreliable results, due to spurious overlaps of two dissimilar questions with coincidentally identical answers. To address the issue, we propose a novel approach that elicits proper reasoning behaviors through a module for predicting time spans of events. We introduce the Timeline Reasoning Network (TRN) operating in a two-step inductive reasoning process: In the first step model initially answers each question with semantic and syntactic information. The next step chains multiple questions on the same event to predict a timeline, which is then used to ground the answers. Results on the TORQUE and TB-dense, TRC and TRE tasks respectively, demonstrate that TRN outperforms previous methods by effectively resolving the spurious overlaps using the predicted timeline.

</details>


### [108] [Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team](https://arxiv.org/abs/2506.14234)
*Md Tanzib Hosain,Salman Rahman,Md Kishor Morol,Md Rizwan Parvez*

Main category: cs.CL

TL;DR: Xolver是一个免训练的多智能体推理框架，通过持久记忆和多样化经验模态提升大型语言模型的推理能力，显著优于现有专用推理模型。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在复杂推理中缺乏经验积累和整合，而专家问题解决者则依赖丰富的经验。Xolver旨在通过记忆和多样化经验模态弥补这一差距。

Method: Xolver结合外部和自我检索、工具使用、协作交互、智能体驱动评估和迭代优化，实现经验感知推理。

Result: Xolver在多个基准测试中表现优异，包括GSM8K（98.1%）、AIME'24（94.4%）等，甚至超越高级模型。

Conclusion: Xolver展示了经验学习对实现专家级推理的重要性，为通用智能体的发展提供了关键步骤。

Abstract: Despite impressive progress on complex reasoning, current large language models (LLMs) typically operate in isolation - treating each problem as an independent attempt, without accumulating or integrating experiential knowledge. In contrast, expert problem solvers - such as Olympiad or programming contest teams - leverage a rich tapestry of experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality, adapting strategies based on the expertise and experiences of peers, continuously refining their reasoning through trial and error, and learning from other related problems even during competition. We introduce Xolver, a training-free multi-agent reasoning framework that equips a black-box LLM with a persistent, evolving memory of holistic experience. Xolver integrates diverse experience modalities, including external and self-retrieval, tool use, collaborative interactions, agent-driven evaluation, and iterative refinement. By learning from relevant strategies, code fragments, and abstract reasoning patterns at inference time, Xolver avoids generating solutions from scratch - marking a transition from isolated inference toward experience-aware language agents. Built on both open-weight and proprietary models, Xolver consistently outperforms specialized reasoning agents. Even with lightweight backbones (e.g., QWQ-32B), it often surpasses advanced models including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high. With o3-mini-high, it achieves new best results on GSM8K (98.1%), AIME'24 (94.4%), AIME'25 (93.7%), Math-500 (99.8%), and LiveCodeBench-V5 (91.6%) - highlighting holistic experience learning as a key step toward generalist agents capable of expert-level reasoning. Code and data are available at https://kagnlp.github.io/xolver.github.io/.

</details>


### [109] [A Multi-Expert Structural-Semantic Hybrid Framework for Unveiling Historical Patterns in Temporal Knowledge Graphs](https://arxiv.org/abs/2506.14235)
*Yimin Deng,Yuxia Wu,Yejing Wang,Guoshuai Zhao,Li Zhu,Qidong Liu,Derong Xu,Zichuan Fu,Xian Wu,Yefeng Zheng,Xiangyu Zhao,Xueming Qian*

Main category: cs.CL

TL;DR: 提出了一种多专家结构-语义混合框架（MESH），用于整合结构和语义信息，提升时序知识图谱推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能整合结构和语义推理视角，且无法区分历史与非历史事件，限制了泛化能力。

Method: 采用三种专家模块，结合结构和语义信息，指导不同事件的推理过程。

Result: 在三个数据集上的实验验证了方法的有效性。

Conclusion: MESH框架通过整合双重视角，显著提升了时序知识图谱推理的性能。

Abstract: Temporal knowledge graph reasoning aims to predict future events with knowledge of existing facts and plays a key role in various downstream tasks. Previous methods focused on either graph structure learning or semantic reasoning, failing to integrate dual reasoning perspectives to handle different prediction scenarios. Moreover, they lack the capability to capture the inherent differences between historical and non-historical events, which limits their generalization across different temporal contexts. To this end, we propose a Multi-Expert Structural-Semantic Hybrid (MESH) framework that employs three kinds of expert modules to integrate both structural and semantic information, guiding the reasoning process for different events. Extensive experiments on three datasets demonstrate the effectiveness of our approach.

</details>


### [110] [Re-Initialization Token Learning for Tool-Augmented Large Language Models](https://arxiv.org/abs/2506.14248)
*Chenghao Li,Liu Liu,Baosheng Yu,Jiayan Qiu,Yibing Zhan*

Main category: cs.CL

TL;DR: 提出了一种新的令牌学习方法，通过将工具令牌与现有词嵌入空间对齐，提升大语言模型调用外部工具的能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂任务（如数值推理、计划生成）中表现不佳，现有方法未考虑工具令牌与词令牌的关系，限制了模型的适应性。

Method: 基于工具名称或描述构建先验令牌嵌入，用于初始化和正则化可学习的工具令牌嵌入，确保其与词令牌空间对齐。

Result: 在GSM8K-XL、FuncQA、KAMEL和VirtualHome数据集上评估，结果显示该方法在数值推理、知识问答和计划生成任务中优于基线方法。

Conclusion: 该方法通过相关令牌有效增强了大语言模型在多领域任务中调用工具的能力。

Abstract: Large language models have demonstrated exceptional performance, yet struggle with complex tasks such as numerical reasoning, plan generation. Integrating external tools, such as calculators and databases, into large language models (LLMs) is crucial for enhancing problem-solving capabilities. Current methods assign a unique token to each tool, enabling LLMs to call tools through token prediction-similar to word generation. However, this approach fails to account for the relationship between tool and word tokens, limiting adaptability within pre-trained LLMs. To address this issue, we propose a novel token learning method that aligns tool tokens with the existing word embedding space from the perspective of initialization, thereby enhancing model performance. We begin by constructing prior token embeddings for each tool based on the tool's name or description, which are used to initialize and regularize the learnable tool token embeddings. This ensures the learned embeddings are well-aligned with the word token space, improving tool call accuracy. We evaluate the method on tasks such as numerical reasoning, knowledge-based question answering, and embodied plan generation using GSM8K-XL, FuncQA, KAMEL, and VirtualHome datasets. The results demonstrate clear improvements over recent baselines, including CoT, REACT, ICL, and ToolkenGPT, indicating that our approach effectively augments LLMs with tools through relevant tokens across diverse domains.

</details>


### [111] [From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents](https://arxiv.org/abs/2506.14285)
*Seongbo Jang,Minjin Jeon,Jaehoon Lee,Seonghyeon Lee,Dongha Lee,Hwanjo Yu*

Main category: cs.CL

TL;DR: 论文提出了一项新任务“及时对话响应生成”，并引入了TimelyChat基准，用于评估语言模型预测时间间隔和生成时间条件响应的能力。通过构建大规模训练数据集和训练Timer对话代理，实验表明Timer优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有对话响应生成研究主要关注文本上下文的连贯性，而忽略了基于时间上下文的响应时机问题。

Method: 利用时间常识知识图谱构建大规模训练数据集，并训练Timer对话代理，预测时间间隔并生成时间条件响应。

Result: Timer在对话级别和轮次级别评估中均优于基于提示的大语言模型和其他微调基线。

Conclusion: 论文成功填补了对话响应生成中时间上下文的研究空白，并公开了数据、模型和代码。

Abstract: While research on dialogue response generation has primarily focused on generating coherent responses conditioning on textual context, the critical question of when to respond grounded on the temporal context remains underexplored. To bridge this gap, we propose a novel task called timely dialogue response generation and introduce the TimelyChat benchmark, which evaluates the capabilities of language models to predict appropriate time intervals and generate time-conditioned responses. Additionally, we construct a large-scale training dataset by leveraging unlabeled event knowledge from a temporal commonsense knowledge graph and employing a large language model (LLM) to synthesize 55K event-driven dialogues. We then train Timer, a dialogue agent designed to proactively predict time intervals and generate timely responses that align with those intervals. Experimental results show that Timer outperforms prompting-based LLMs and other fine-tuned baselines in both turn-level and dialogue-level evaluations. We publicly release our data, model, and code.

</details>


### [112] [Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent](https://arxiv.org/abs/2506.14302)
*Xueyang Feng,Jingsen Zhang,Jiakai Tang,Wei Li,Guohao Cai,Xu Chen,Quanyu Dai,Yue Zhu,Zhenhua Dong*

Main category: cs.CL

TL;DR: 论文提出了一种名为ECPO的多轮偏好优化方法，通过期望确认理论建模用户满意度演变，优化对话推荐系统的交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有对话推荐代理（CRAs）在多轮对话中表现不佳，偏好优化成本高且效果有限。

Method: 引入ECPO范式，结合期望确认理论，建模用户满意度演变，并利用LLM模拟用户反馈（AILO）。

Result: 实验表明，ECPO显著提升了CRAs的交互能力，效率和效果均优于现有方法。

Conclusion: ECPO为多轮偏好优化提供了高效且有效的解决方案。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly propelled the development of Conversational Recommendation Agents (CRAs). However, these agents often generate short-sighted responses that fail to sustain user guidance and meet expectations. Although preference optimization has proven effective in aligning LLMs with user expectations, it remains costly and performs poorly in multi-turn dialogue. To address this challenge, we introduce a novel multi-turn preference optimization (MTPO) paradigm ECPO, which leverages Expectation Confirmation Theory to explicitly model the evolution of user satisfaction throughout multi-turn dialogues, uncovering the underlying causes of dissatisfaction. These causes can be utilized to support targeted optimization of unsatisfactory responses, thereby achieving turn-level preference optimization. ECPO ingeniously eliminates the significant sampling overhead of existing MTPO methods while ensuring the optimization process drives meaningful improvements. To support ECPO, we introduce an LLM-based user simulator, AILO, to simulate user feedback and perform expectation confirmation during conversational recommendations. Experimental results show that ECPO significantly enhances CRA's interaction capabilities, delivering notable improvements in both efficiency and effectiveness over existing MTPO methods.

</details>


### [113] [Evaluation Should Not Ignore Variation: On the Impact of Reference Set Choice on Summarization Metrics](https://arxiv.org/abs/2506.14335)
*Silvia Casola,Yang Janet Liu,Siyao Peng,Oliver Kraus,Albert Gatt,Barbara Plank*

Main category: cs.CL

TL;DR: 论文研究了参考摘要集对基于参考的摘要评估指标的影响，发现许多流行指标（如ROUGE）对参考集选择敏感，导致模型排名不稳定。建议在评估中考虑参考集变化以提高一致性。


<details>
  <summary>Details</summary>
Motivation: 人类语言生成的多样性在摘要评估中常被忽视，而参考集的选择对评估指标的影响尚未系统研究。

Method: 分析了三个多参考摘要数据集（SummEval、GUMSum、DUC2004），检验了流行指标对参考集选择的敏感性，并收集了人类对LLM输出的评估数据。

Result: 发现许多指标（尤其是n-gram类如ROUGE）对参考集选择敏感，模型排名不稳定；人类评估与指标相关性弱或无。

Conclusion: 建议在摘要评估中纳入参考集变化，以提高评估的一致性和与人类判断的相关性，特别是在评估LLMs时。

Abstract: Human language production exhibits remarkable richness and variation, reflecting diverse communication styles and intents. However, this variation is often overlooked in summarization evaluation. While having multiple reference summaries is known to improve correlation with human judgments, the impact of using different reference sets on reference-based metrics has not been systematically investigated. This work examines the sensitivity of widely used reference-based metrics in relation to the choice of reference sets, analyzing three diverse multi-reference summarization datasets: SummEval, GUMSum, and DUC2004. We demonstrate that many popular metrics exhibit significant instability. This instability is particularly concerning for n-gram-based metrics like ROUGE, where model rankings vary depending on the reference sets, undermining the reliability of model comparisons. We also collect human judgments on LLM outputs for genre-diverse data and examine their correlation with metrics to supplement existing findings beyond newswire summaries, finding weak-to-no correlation. Taken together, we recommend incorporating reference set variation into summarization evaluation to enhance consistency alongside correlation with human judgments, especially when evaluating LLMs.

</details>


### [114] [A Vision for Geo-Temporal Deep Research Systems: Towards Comprehensive, Transparent, and Reproducible Geo-Temporal Information Synthesis](https://arxiv.org/abs/2506.14345)
*Bruno Martins,Piotr Szymański,Piotr Gramacki*

Main category: cs.CL

TL;DR: 本文探讨了如何将地理时间推理能力整合到深度研究系统中，以解决当前系统在处理地理和时间约束问题时的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）驱动的深度研究系统缺乏处理地理和时间约束的能力，而这些能力在公共健康、环境科学等领域至关重要。

Method: 提出通过增强检索和合成过程的能力，结合开放和可复现的基础设施及严格评估协议，整合地理时间推理。

Result: 提出了下一代系统的愿景，明确了技术、基础设施和评估方面的挑战。

Conclusion: 通过整合地理时间推理，未来AI驱动的信息访问系统将更加先进和实用。

Abstract: The emergence of Large Language Models (LLMs) has transformed information access, with current LLMs also powering deep research systems that can generate comprehensive report-style answers, through planned iterative search, retrieval, and reasoning. Still, current deep research systems lack the geo-temporal capabilities that are essential for answering context-rich questions involving geographic and/or temporal constraints, frequently occurring in domains like public health, environmental science, or socio-economic analysis. This paper reports our vision towards next generation systems, identifying important technical, infrastructural, and evaluative challenges in integrating geo-temporal reasoning into deep research pipelines. We argue for augmenting retrieval and synthesis processes with the ability to handle geo-temporal constraints, supported by open and reproducible infrastructures and rigorous evaluation protocols. Our vision outlines a path towards more advanced and geo-temporally aware deep research systems, of potential impact to the future of AI-driven information access.

</details>


### [115] [Digital Gatekeepers: Google's Role in Curating Hashtags and Subreddits](https://arxiv.org/abs/2506.14370)
*Amrit Poudel,Yifan Ding,Jurgen Pfeffer,Tim Weninger*

Main category: cs.CL

TL;DR: 研究发现搜索引擎（如Google）通过算法选择性推广或压制某些标签和子论坛，影响用户接触的信息，揭示其系统性偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨搜索引擎如何通过算法影响社交媒体内容的可见性，从而塑造公共话语。

Method: 通过比较搜索引擎结果与Reddit和Twitter/X的非抽样数据，分析内容可见性偏差。

Result: Google算法倾向于压制与色情内容、阴谋论、广告和加密货币相关的子论坛和标签，同时推广高参与度内容。

Conclusion: Google的门控行为通过筛选社交媒体叙事影响公共话语。

Abstract: Search engines play a crucial role as digital gatekeepers, shaping the visibility of Web and social media content through algorithmic curation. This study investigates how search engines like Google selectively promotes or suppresses certain hashtags and subreddits, impacting the information users encounter. By comparing search engine results with nonsampled data from Reddit and Twitter/X, we reveal systematic biases in content visibility. Google's algorithms tend to suppress subreddits and hashtags related to sexually explicit material, conspiracy theories, advertisements, and cryptocurrencies, while promoting content associated with higher engagement. These findings suggest that Google's gatekeeping practices influence public discourse by curating the social media narratives available to users.

</details>


### [116] [ELLIS Alicante at CQs-Gen 2025: Winning the critical thinking questions shared task: LLM-based question generation and selection](https://arxiv.org/abs/2506.14371)
*Lucile Favero,Daniel Frases,Juan Antonio Pérez-Ortiz,Tanja Käser,Nuria Oliver*

Main category: cs.CL

TL;DR: 论文探讨了利用大型语言模型（LLMs）生成批判性问题以促进深度思考，而非仅用于检索事实信息。提出的两步框架在比赛中排名第一。


<details>
  <summary>Details</summary>
Motivation: 担心基于LLMs的聊天界面可能助长浅层学习，削弱批判性思维能力的培养。

Method: 采用两步框架：一个生成候选问题的Questioner模型和一个筛选最相关问题的Judge模型。

Result: 系统在比赛中排名第一，证明了LLM方法在促进批判性思考方面的潜力。

Conclusion: LLMs可用于生成批判性问题，有效促进对论证文本的深度思考。

Abstract: The widespread adoption of chat interfaces based on Large Language Models (LLMs) raises concerns about promoting superficial learning and undermining the development of critical thinking skills. Instead of relying on LLMs purely for retrieving factual information, this work explores their potential to foster deeper reasoning by generating critical questions that challenge unsupported or vague claims in debate interventions. This study is part of a shared task of the 12th Workshop on Argument Mining, co-located with ACL 2025, focused on automatic critical question generation. We propose a two-step framework involving two small-scale open source language models: a Questioner that generates multiple candidate questions and a Judge that selects the most relevant ones. Our system ranked first in the shared task competition, demonstrating the potential of the proposed LLM-based approach to encourage critical engagement with argumentative texts.

</details>


### [117] [Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding](https://arxiv.org/abs/2506.14397)
*Yeonkyoung So,Gyuseong Lee,Sungmok Jung,Joonhak Lee,JiA Kang,Sangho Kim,Jaejin Lee*

Main category: cs.CL

TL;DR: Thunder-NUBench是一个专门评估大语言模型在句子层面否定理解能力的新基准，超越了表面线索检测，包含多样化的否定结构。


<details>
  <summary>Details</summary>
Motivation: 现有基准通常将否定视为自然语言推理等任务的次要案例，缺乏专门针对否定理解的基准。

Method: 通过对比标准否定与局部否定、矛盾、释义等多样化结构，构建手动筛选的句子-否定对和多选题数据集。

Result: Thunder-NUBench提供了对大语言模型否定理解能力的深入评估。

Conclusion: 该基准填补了专门评估否定理解的空白，为模型能力提供了更全面的测试。

Abstract: Negation is a fundamental linguistic phenomenon that poses persistent challenges for Large Language Models (LLMs), particularly in tasks requiring deep semantic understanding. Existing benchmarks often treat negation as a side case within broader tasks like natural language inference, resulting in a lack of benchmarks that exclusively target negation understanding. In this work, we introduce \textbf{Thunder-NUBench}, a novel benchmark explicitly designed to assess sentence-level negation understanding in LLMs. Thunder-NUBench goes beyond surface-level cue detection by contrasting standard negation with structurally diverse alternatives such as local negation, contradiction, and paraphrase. The benchmark consists of manually curated sentence-negation pairs and a multiple-choice dataset that enables in-depth evaluation of models' negation understanding.

</details>


### [118] [ImpliRet: Benchmarking the Implicit Fact Retrieval Challenge](https://arxiv.org/abs/2506.14407)
*Zeinab Sadat Taghavi,Ali Modarressi,Yunpu Ma,Hinrich Schütze*

Main category: cs.CL

TL;DR: ImpliRet是一个新的检索基准，将推理挑战转移到文档端处理，而非查询端。


<details>
  <summary>Details</summary>
Motivation: 现有检索系统依赖浅层信号（如关键词重叠），而新基准将复杂性转移到查询端处理。ImpliRet旨在通过简单查询但依赖文档隐含事实（如时间、算术和世界知识关系）来评估文档端推理能力。

Method: 提出ImpliRet基准，评估稀疏和密集检索器在文档端推理任务中的表现，并测试长上下文模型（如GPT-4.1）的能力。

Result: 所有检索器表现不佳，最佳nDCG@10仅为15.07%。GPT-4.1在短上下文（10篇文档）中得分仅35.06%，显示文档端推理仍具挑战性。

Conclusion: ImpliRet揭示了文档端推理的困难，为未来研究提供了新方向。

Abstract: Retrieval systems are central to many NLP pipelines, but often rely on surface-level cues such as keyword overlap and lexical semantic similarity. To evaluate retrieval beyond these shallow signals, recent benchmarks introduce reasoning-heavy queries; however, they primarily shift the burden to query-side processing techniques -- like prompting or multi-hop retrieval -- that can help resolve complexity. In contrast, we present ImpliRet, a benchmark that shifts the reasoning challenge to document-side processing: The queries are simple, but relevance depends on facts stated implicitly in documents through temporal (e.g., resolving "two days ago"), arithmetic, and world knowledge relationships. We evaluate a range of sparse and dense retrievers, all of which struggle in this setting: the best nDCG@10 is only 15.07%. We also test whether long-context models can overcome this limitation. But even with a short context of only ten documents, including the positive document, GPT-4.1 scores only 35.06%, showing that document-side reasoning remains a challenge. Our codes are available at github.com/ZeinabTaghavi/IMPLIRET.Contribution.

</details>


### [119] [LongLLaDA: Unlocking Long Context Capabilities in Diffusion LLMs](https://arxiv.org/abs/2506.14429)
*Xiaoran Liu,Zhigeng Liu,Zengfeng Huang,Qipeng Guo,Ziwei He,Xipeng Qiu*

Main category: cs.CL

TL;DR: 本文首次系统研究了扩散大语言模型（diffusion LLMs）的长上下文能力，发现其具有稳定的困惑度和局部感知现象，并提出了一种无需训练的长上下文扩展方法LongLLaDA。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型的长上下文能力尚未被系统研究，缺乏相关分析或扩展方法。

Method: 通过比较扩散LLMs与传统自回归LLMs的长上下文表现，发现扩散LLMs的稳定困惑度和局部感知现象，并基于RoPE缩放理论提出LongLLaDA方法。

Result: 扩散LLMs在长上下文任务中表现优于自回归LLMs，且提出的LongLLaDA方法有效扩展了上下文窗口。

Conclusion: 本研究为扩散LLMs的长上下文扩展提供了首个方法，并揭示了其理论特性和实际表现，为未来研究奠定了基础。

Abstract: Large Language Diffusion Models, or diffusion LLMs, have emerged as a significant focus in NLP research, with substantial effort directed toward understanding their scalability and downstream task performance. However, their long-context capabilities remain unexplored, lacking systematic analysis or methods for context extension. In this work, we present the first systematic investigation comparing the long-context performance of diffusion LLMs and traditional auto-regressive LLMs. We first identify a unique characteristic of diffusion LLMs, unlike auto-regressive LLMs, they maintain remarkably \textbf{\textit{stable perplexity}} during direct context extrapolation. Furthermore, where auto-regressive models fail outright during the Needle-In-A-Haystack task with context exceeding their pretrained length, we discover diffusion LLMs exhibit a distinct \textbf{\textit{local perception}} phenomenon, enabling successful retrieval from recent context segments. We explain both phenomena through the lens of Rotary Position Embedding (RoPE) scaling theory. Building on these observations, we propose LongLLaDA, a training-free method that integrates LLaDA with the NTK-based RoPE extrapolation. Our results validate that established extrapolation scaling laws remain effective for extending the context windows of diffusion LLMs. Furthermore, we identify long-context tasks where diffusion LLMs outperform auto-regressive LLMs and others where they fall short. Consequently, this study establishes the first context extrapolation method for diffusion LLMs while providing essential theoretical insights and empirical benchmarks critical for advancing future research on long-context diffusion LLMs.

</details>


### [120] [How Far Can LLMs Improve from Experience? Measuring Test-Time Learning Ability in LLMs with Human Comparison](https://arxiv.org/abs/2506.14448)
*Jiayin Wang,Zhiquang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CL

TL;DR: 论文主张评估大型语言模型的测试时学习能力，提出语义游戏作为评估工具，并发现模型虽具备学习能力，但稳定性与进步速度不及人类。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估静态知识，但智能还需快速从经验中学习的能力，因此需评估测试时学习能力。

Method: 提出语义游戏作为评估工具，设计包含四种经验表示的客观评估框架，并与人类参与者对比。

Result: LLMs展现出可测量的测试时学习能力，但在累积经验下改进不稳定且进步速度慢于人类。

Conclusion: LLMs具备通用学习机器的潜力，但与人类仍存在显著智力差距。

Abstract: As evaluation designs of large language models may shape our trajectory toward artificial general intelligence, comprehensive and forward-looking assessment is essential. Existing benchmarks primarily assess static knowledge, while intelligence also entails the ability to rapidly learn from experience. To this end, we advocate for the evaluation of Test-time Learning, the capacity to improve performance in experience-based, reasoning-intensive tasks during test time. In this work, we propose semantic games as effective testbeds for evaluating test-time learning, due to their resistance to saturation and inherent demand for strategic reasoning. We introduce an objective evaluation framework that compares model performance under both limited and cumulative experience settings, and contains four forms of experience representation. To provide a comparative baseline, we recruit eight human participants to complete the same task. Results show that LLMs exhibit measurable test-time learning capabilities; however, their improvements are less stable under cumulative experience and progress more slowly than those observed in humans. These findings underscore the potential of LLMs as general-purpose learning machines, while also revealing a substantial intellectual gap between models and humans, irrespective of how well LLMs perform on static benchmarks.

</details>


### [121] [LexiMark: Robust Watermarking via Lexical Substitutions to Enhance Membership Verification of an LLM's Textual Training Data](https://arxiv.org/abs/2506.14474)
*Eyal German,Sagiv Antebi,Edan Habler,Asaf Shabtai,Yuval Elovici*

Main category: cs.CL

TL;DR: LexiMark是一种新型文本水印技术，通过同义词替换高熵词嵌入水印，既保持语义完整性又难以检测，显著提升了检测未经授权数据使用的效果。


<details>
  <summary>Details</summary>
Motivation: 现有水印技术缺乏隐蔽性，容易被检测和移除，需要一种更隐蔽且有效的方法来验证LLM是否使用了未经授权的数据。

Method: LexiMark通过同义词替换高熵词嵌入水印，增强LLM对水印文本的记忆能力，同时保持语义完整性。

Result: 在多个开源模型和训练设置下，LexiMark的AUROC分数显著优于现有方法，验证了其有效性。

Conclusion: LexiMark提供了一种隐蔽且可靠的方法，用于检测LLM是否使用了未经授权的水印数据。

Abstract: Large language models (LLMs) can be trained or fine-tuned on data obtained without the owner's consent. Verifying whether a specific LLM was trained on particular data instances or an entire dataset is extremely challenging. Dataset watermarking addresses this by embedding identifiable modifications in training data to detect unauthorized use. However, existing methods often lack stealth, making them relatively easy to detect and remove. In light of these limitations, we propose LexiMark, a novel watermarking technique designed for text and documents, which embeds synonym substitutions for carefully selected high-entropy words. Our method aims to enhance an LLM's memorization capabilities on the watermarked text without altering the semantic integrity of the text. As a result, the watermark is difficult to detect, blending seamlessly into the text with no visible markers, and is resistant to removal due to its subtle, contextually appropriate substitutions that evade automated and manual detection. We evaluated our method using baseline datasets from recent studies and seven open-source models: LLaMA-1 7B, LLaMA-3 8B, Mistral 7B, Pythia 6.9B, as well as three smaller variants from the Pythia family (160M, 410M, and 1B). Our evaluation spans multiple training settings, including continued pretraining and fine-tuning scenarios. The results demonstrate significant improvements in AUROC scores compared to existing methods, underscoring our method's effectiveness in reliably verifying whether unauthorized watermarked data was used in LLM training.

</details>


### [122] [LingoLoop Attack: Trapping MLLMs via Linguistic Context and State Entrapment into Endless Loops](https://arxiv.org/abs/2506.14493)
*Jiyuan Fu,Kaixun Jiang,Lingyi Hong,Jinglun Li,Haijing Guo,Dingkang Yang,Zhaoyu Chen,Wenqiang Zhang*

Main category: cs.CL

TL;DR: LingoLoop是一种针对多模态大语言模型（MLLMs）的攻击方法，通过调整词性（POS）注意力和限制输出多样性，诱导模型生成冗长重复的序列，显著增加计算资源和能耗。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法忽视了词性和句子结构对生成输出的影响，限制了攻击效果。LingoLoop旨在通过更精细的控制提升攻击效率。

Method: 1. 提出POS-Aware Delay Mechanism，基于词性调整注意力权重以延迟EOS生成；2. 引入Generative Path Pruning Mechanism，限制隐藏状态幅度以诱导重复循环。

Result: 实验显示LingoLoop可将生成标记数量提升30倍，能耗显著增加，有效推动MLLMs达到生成极限。

Conclusion: LingoLoop揭示了MLLMs的重大漏洞，对其可靠部署提出了挑战。

Abstract: Multimodal Large Language Models (MLLMs) have shown great promise but require substantial computational resources during inference. Attackers can exploit this by inducing excessive output, leading to resource exhaustion and service degradation. Prior energy-latency attacks aim to increase generation time by broadly shifting the output token distribution away from the EOS token, but they neglect the influence of token-level Part-of-Speech (POS) characteristics on EOS and sentence-level structural patterns on output counts, limiting their efficacy. To address this, we propose LingoLoop, an attack designed to induce MLLMs to generate excessively verbose and repetitive sequences. First, we find that the POS tag of a token strongly affects the likelihood of generating an EOS token. Based on this insight, we propose a POS-Aware Delay Mechanism to postpone EOS token generation by adjusting attention weights guided by POS information. Second, we identify that constraining output diversity to induce repetitive loops is effective for sustained generation. We introduce a Generative Path Pruning Mechanism that limits the magnitude of hidden states, encouraging the model to produce persistent loops. Extensive experiments demonstrate LingoLoop can increase generated tokens by up to 30 times and energy consumption by a comparable factor on models like Qwen2.5-VL-3B, consistently driving MLLMs towards their maximum generation limits. These findings expose significant MLLMs' vulnerabilities, posing challenges for their reliable deployment. The code will be released publicly following the paper's acceptance.

</details>


### [123] [M2BeamLLM: Multimodal Sensing-empowered mmWave Beam Prediction with Large Language Models](https://arxiv.org/abs/2506.14532)
*Can Zheng,Jiguang He,Chung G. Kang,Guofa Cai,Zitong Yu,Merouane Debbah*

Main category: cs.CL

TL;DR: M2BeamLLM是一种新型神经网络框架，用于毫米波大规模MIMO系统中的波束预测，结合多模态传感器数据和LLM，显著提高了预测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决毫米波大规模MIMO通信系统中波束预测的挑战，通过多模态数据和LLM提升预测性能。

Method: 整合多模态传感器数据（图像、雷达、LiDAR、GPS），利用LLM（如GPT-2）进行推理，结合数据编码、多模态对齐与融合以及监督微调。

Result: 在标准和少样本场景下，M2BeamLLM的波束预测精度和鲁棒性显著优于传统DL模型，且性能随传感器模态多样性增加而提升。

Conclusion: M2BeamLLM为车对基础设施毫米波通信系统提供了高效智能的波束预测解决方案。

Abstract: This paper introduces a novel neural network framework called M2BeamLLM for beam prediction in millimeter-wave (mmWave) massive multi-input multi-output (mMIMO) communication systems. M2BeamLLM integrates multi-modal sensor data, including images, radar, LiDAR, and GPS, leveraging the powerful reasoning capabilities of large language models (LLMs) such as GPT-2 for beam prediction. By combining sensing data encoding, multimodal alignment and fusion, and supervised fine-tuning (SFT), M2BeamLLM achieves significantly higher beam prediction accuracy and robustness, demonstrably outperforming traditional deep learning (DL) models in both standard and few-shot scenarios. Furthermore, its prediction performance consistently improves with increased diversity in sensing modalities. Our study provides an efficient and intelligent beam prediction solution for vehicle-to-infrastructure (V2I) mmWave communication systems.

</details>


### [124] [AlphaDecay:Module-wise Weight Decay for Heavy-Tailed Balancing in LLMs](https://arxiv.org/abs/2506.14562)
*Di He,Ajay Jaiswal,Songjun Tu,Li Shen,Ganzhao Yuan,Shiwei Liu,Lu Yin*

Main category: cs.CL

TL;DR: AlphaDecay是一种自适应分配权重衰减强度的新方法，通过分析模块的频谱特性来优化LLM训练。


<details>
  <summary>Details</summary>
Motivation: 传统的均匀权重衰减忽略了LLM模块的结构多样性和频谱特性差异，AlphaDecay旨在解决这一问题。

Method: 基于HT-SR理论，通过分析权重相关矩阵的ESD来量化“重尾性”，并据此自适应分配衰减强度。

Result: 在60M到1B规模的模型上，AlphaDecay在困惑度和泛化能力上优于传统均匀衰减和其他自适应方法。

Conclusion: AlphaDecay通过模块化自适应权重衰减，显著提升了LLM的性能。

Abstract: Weight decay is a standard regularization technique for training large language models (LLMs). While it is common to assign a uniform decay rate to every layer, this approach overlooks the structural diversity of LLMs and the varying spectral properties across modules. In this paper, we introduce AlphaDecay, a simple yet effective method that adaptively assigns different weight decay strengths to each module of an LLM. Our approach is guided by Heavy-Tailed Self-Regularization (HT-SR) theory, which analyzes the empirical spectral density (ESD) of weight correlation matrices to quantify "heavy-tailedness." Modules exhibiting more pronounced heavy-tailed ESDs, reflecting stronger feature learning, are assigned weaker decay, while modules with lighter-tailed spectra receive stronger decay. Our method leverages tailored weight decay assignments to balance the module-wise differences in spectral properties, leading to improved performance. Extensive pre-training tasks with various model sizes from 60M to 1B demonstrate that AlphaDecay achieves better perplexity and generalization than conventional uniform decay and other adaptive decay baselines.

</details>


### [125] [GenerationPrograms: Fine-grained Attribution with Executable Programs](https://arxiv.org/abs/2506.14580)
*David Wan,Eran Hirsch,Elias Stengel-Eskin,Ido Dagan,Mohit Bansal*

Main category: cs.CL

TL;DR: 论文提出了一种模块化生成框架GenerationPrograms，通过分解生成过程为程序计划和执行两阶段，显著提升了文本生成中的细粒度归因质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在细粒度归因上表现不佳，且缺乏对模型如何利用源文档的解释，影响了可信度和可解释性。

Method: 采用模块化生成框架，首先生成可执行的程序计划（如改写、压缩、融合等操作），再执行这些操作生成最终响应。

Result: 在长问答和多文档摘要任务中，GenerationPrograms显著提升了文档和句子级别的归因质量，并可作为后处理归因方法优于传统技术。

Conclusion: GenerationPrograms通过模块化设计和可解释程序，实现了更高的归因质量和局部优化能力。

Abstract: Recent large language models (LLMs) achieve impressive performance in source-conditioned text generation but often fail to correctly provide fine-grained attributions for their outputs, undermining verifiability and trust. Moreover, existing attribution methods do not explain how and why models leverage the provided source documents to generate their final responses, limiting interpretability. To overcome these challenges, we introduce a modular generation framework, GenerationPrograms, inspired by recent advancements in executable "code agent" architectures. Unlike conventional generation methods that simultaneously generate outputs and attributions or rely on post-hoc attribution, GenerationPrograms decomposes the process into two distinct stages: first, creating an executable program plan composed of modular text operations (such as paraphrasing, compression, and fusion) explicitly tailored to the query, and second, executing these operations following the program's specified instructions to produce the final response. Empirical evaluations demonstrate that GenerationPrograms significantly improves attribution quality at both the document level and sentence level across two long-form question-answering tasks and a multi-document summarization task. We further demonstrate that GenerationPrograms can effectively function as a post-hoc attribution method, outperforming traditional techniques in recovering accurate attributions. In addition, the interpretable programs generated by GenerationPrograms enable localized refinement through modular-level improvements that further enhance overall attribution quality.

</details>


### [126] [Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees](https://arxiv.org/abs/2506.14606)
*Ahmed Heakl,Sarim Hashmi,Chaimaa Abi,Celine Lee,Abdulrahman Mahmoud*

Main category: cs.CL

TL;DR: GG是一种结合大型语言模型和软件测试框架的ISA转换方法，用于快速、灵活且正确地实现CISC到RISC的代码翻译，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 硬件生态系统快速发展，需要一种高效且可靠的方法实现不同指令集架构（ISA）间的代码翻译，以提升代码的可移植性和寿命。

Method: GG采用预训练大型语言模型（LLM）生成候选翻译，并通过软件测试框架验证翻译的正确性，确保高代码覆盖率和功能正确性。

Result: 在HumanEval和BringupBench数据集上分别达到99%和49%的功能正确性，性能优于Rosetta 2，运行速度更快、能效更高、内存占用更少。

Conclusion: GG为CISC到RISC的代码翻译提供了高效解决方案，开源代码和数据将推动ISA级代码翻译研究的发展。

Abstract: The hardware ecosystem is rapidly evolving, with increasing interest in translating low-level programs across different instruction set architectures (ISAs) in a quick, flexible, and correct way to enhance the portability and longevity of existing code. A particularly challenging class of this transpilation problem is translating between complex- (CISC) and reduced- (RISC) hardware architectures, due to fundamental differences in instruction complexity, memory models, and execution paradigms. In this work, we introduce GG (Guaranteed Guess), an ISA-centric transpilation pipeline that combines the translation power of pre-trained large language models (LLMs) with the rigor of established software testing constructs. Our method generates candidate translations using an LLM from one ISA to another, and embeds such translations within a software-testing framework to build quantifiable confidence in the translation. We evaluate our GG approach over two diverse datasets, enforce high code coverage (>98%) across unit tests, and achieve functional/semantic correctness of 99% on HumanEval programs and 49% on BringupBench programs, respectively. Further, we compare our approach to the state-of-the-art Rosetta 2 framework on Apple Silicon, showcasing 1.73x faster runtime performance, 1.47x better energy efficiency, and 2.41x better memory usage for our transpiled code, demonstrating the effectiveness of GG for real-world CISC-to-RISC translation tasks. We will open-source our codes, data, models, and benchmarks to establish a common foundation for ISA-level code translation research.

</details>


### [127] [When Does Meaning Backfire? Investigating the Role of AMRs in NLI](https://arxiv.org/abs/2506.14613)
*Junghyun Min,Xiulin Yang,Shira Wein*

Main category: cs.CL

TL;DR: 研究了在自然语言推理（NLI）中引入抽象意义表示（AMR）对预训练语言模型的影响。实验表明，微调时加入AMR会阻碍模型泛化，而提示时使用AMR在GPT-4o中略有提升，但改进源于表面差异的放大而非语义推理。


<details>
  <summary>Details</summary>
Motivation: 探索AMR是否能通过提供语义信息帮助预训练语言模型在NLI任务中更好地泛化。

Method: 在微调和提示两种设置下将AMR整合到NLI任务中，并进行消融研究。

Result: 微调时AMR阻碍泛化，提示时略有提升但源于表面差异放大。

Conclusion: AMR在NLI中的改进效果有限，且可能误导模型忽略核心语义。

Abstract: Natural Language Inference (NLI) relies heavily on adequately parsing the semantic content of the premise and hypothesis. In this work, we investigate whether adding semantic information in the form of an Abstract Meaning Representation (AMR) helps pretrained language models better generalize in NLI. Our experiments integrating AMR into NLI in both fine-tuning and prompting settings show that the presence of AMR in fine-tuning hinders model generalization while prompting with AMR leads to slight gains in \texttt{GPT-4o}. However, an ablation study reveals that the improvement comes from amplifying surface-level differences rather than aiding semantic reasoning. This amplification can mislead models to predict non-entailment even when the core meaning is preserved.

</details>


### [128] [Probabilistic Aggregation and Targeted Embedding Optimization for Collective Moral Reasoning in Large Language Models](https://arxiv.org/abs/2506.14625)
*Chenchen Yuan,Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 论文提出了一种框架，通过整合多个大语言模型（LLMs）的道德判断，形成集体道德判断，并对偏离共识的模型进行优化，以提高道德一致性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在面对复杂多因素道德困境时判断不一致的问题。

Method: 提出了一种聚合机制，融合连续道德接受度评分，并通过模型可靠性加权；对偏离模型进行嵌入优化，最小化与共识的JS散度。

Result: 实验表明，该方法能建立稳健共识并提升单个模型的道德判断一致性。

Conclusion: 数据驱动的多模型道德对齐有助于构建更安全、一致的AI系统。

Abstract: Large Language Models (LLMs) have shown impressive moral reasoning abilities. Yet they often diverge when confronted with complex, multi-factor moral dilemmas. To address these discrepancies, we propose a framework that synthesizes multiple LLMs' moral judgments into a collectively formulated moral judgment, realigning models that deviate significantly from this consensus. Our aggregation mechanism fuses continuous moral acceptability scores (beyond binary labels) into a collective probability, weighting contributions by model reliability. For misaligned models, a targeted embedding-optimization procedure fine-tunes token embeddings for moral philosophical theories, minimizing JS divergence to the consensus while preserving semantic integrity. Experiments on a large-scale social moral dilemma dataset show our approach builds robust consensus and improves individual model fidelity. These findings highlight the value of data-driven moral alignment across multiple models and its potential for safer, more consistent AI systems.

</details>


### [129] [AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation](https://arxiv.org/abs/2506.14634)
*Leah von der Heyde,Anna-Carolina Haensch,Bernd Weiß,Jessika Daikeler*

Main category: cs.CL

TL;DR: LLMs在开放式调查响应分类中的表现因模型和提示方法而异，仅经过微调的LLM表现较好。研究探讨了LLMs在德语调查数据中的应用及其与人工编码的比较。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在非英语、复杂主题的开放式调查响应分类中的适用性，并与传统方法比较。

Method: 使用德语调查数据，比较多种LLM和提示方法，以人工专家编码为基准评估性能。

Result: 不同LLM表现差异显著，仅微调LLM表现满意；提示方法效果因LLM而异；分类性能不均导致类别分布差异。

Conclusion: LLMs在调查研究中需权衡效率与准确性，微调是关键；研究为LLMs在开放式响应分类中的应用提供了实证支持。

Abstract: The recent development and wider accessibility of LLMs have spurred discussions about how they can be used in survey research, including classifying open-ended survey responses. Due to their linguistic capacities, it is possible that LLMs are an efficient alternative to time-consuming manual coding and the pre-training of supervised machine learning models. As most existing research on this topic has focused on English-language responses relating to non-complex topics or on single LLMs, it is unclear whether its findings generalize and how the quality of these classifications compares to established methods. In this study, we investigate to what extent different LLMs can be used to code open-ended survey responses in other contexts, using German data on reasons for survey participation as an example. We compare several state-of-the-art LLMs and several prompting approaches, and evaluate the LLMs' performance by using human expert codings. Overall performance differs greatly between LLMs, and only a fine-tuned LLM achieves satisfactory levels of predictive performance. Performance differences between prompting approaches are conditional on the LLM used. Finally, LLMs' unequal classification performance across different categories of reasons for survey participation results in different categorical distributions when not using fine-tuning. We discuss the implications of these findings, both for methodological research on coding open-ended responses and for their substantive analysis, and for practitioners processing or substantively analyzing such data. Finally, we highlight the many trade-offs researchers need to consider when choosing automated methods for open-ended response classification in the age of LLMs. In doing so, our study contributes to the growing body of research about the conditions under which LLMs can be efficiently, accurately, and reliably leveraged in survey research.

</details>


### [130] [Revisiting Chain-of-Thought Prompting: Zero-shot Can Be Stronger than Few-shot](https://arxiv.org/abs/2506.14641)
*Xiang Cheng,Chengyan Pan,Minjun Zhao,Deyang Li,Fangchao Liu,Xinyu Zhang,Xiao Zhang,Yong Liu*

Main category: cs.CL

TL;DR: 研究发现，对于近期强大的语言模型（如Qwen2.5系列），传统的CoT示例并未提升推理性能，其主要作用是格式化输出。增强版CoT示例同样无效，模型倾向于忽略示例而关注指令。


<details>
  <summary>Details</summary>
Motivation: 探讨近期强大语言模型中CoT示例是否仍能提升数学推理能力。

Method: 通过系统实验，比较传统CoT示例、增强版CoT示例与零样本CoT的效果。

Result: 传统和增强版CoT示例均未提升推理性能，模型更关注指令而非示例。

Conclusion: 当前ICL+CoT框架在数学推理中存在局限性，需重新审视ICL范式及示例定义。

Abstract: In-Context Learning (ICL) is an essential emergent ability of Large Language Models (LLMs), and recent studies introduce Chain-of-Thought (CoT) to exemplars of ICL to enhance the reasoning capability, especially in mathematics tasks. However, given the continuous advancement of model capabilities, it remains unclear whether CoT exemplars still benefit recent, stronger models in such tasks. Through systematic experiments, we find that for recent strong models such as the Qwen2.5 series, adding traditional CoT exemplars does not improve reasoning performance compared to Zero-Shot CoT. Instead, their primary function is to align the output format with human expectations. We further investigate the effectiveness of enhanced CoT exemplars, constructed using answers from advanced models such as \texttt{Qwen2.5-Max} and \texttt{DeepSeek-R1}. Experimental results indicate that these enhanced exemplars still fail to improve the model's reasoning performance. Further analysis reveals that models tend to ignore the exemplars and focus primarily on the instructions, leading to no observable gain in reasoning ability. Overall, our findings highlight the limitations of the current ICL+CoT framework in mathematical reasoning, calling for a re-examination of the ICL paradigm and the definition of exemplars.

</details>


### [131] [Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments](https://arxiv.org/abs/2506.14645)
*. Pazzaglia,V. Vendetti,L. D. Comencini,F. Deriu,V. Modugno*

Main category: cs.CL

TL;DR: 研究发现，经过微调的大型语言模型（LLMs）能够生成高度可信且具有煽动性的政治内容，加剧意识形态极化。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在生成偏见内容方面的潜在影响，及其对在线政治讨论的极化作用。

Method: 使用Reddit的政治讨论数据集微调开源LLM，并通过语言分析、情感评分和人工标注评估其输出。

Result: 微调后的LLM能生成与人类写作难以区分的极化内容，引发伦理担忧。

Conclusion: 研究呼吁加强AI治理、平台监管，并开发检测工具以应对微调风险。

Abstract: The increasing sophistication of large language models (LLMs) has sparked growing concerns regarding their potential role in exacerbating ideological polarization through the automated generation of persuasive and biased content. This study explores the extent to which fine-tuned LLMs can replicate and amplify polarizing discourse within online environments. Using a curated dataset of politically charged discussions extracted from Reddit, we fine-tune an open-source LLM to produce context-aware and ideologically aligned responses. The model's outputs are evaluated through linguistic analysis, sentiment scoring, and human annotation, with particular attention to credibility and rhetorical alignment with the original discourse. The results indicate that, when trained on partisan data, LLMs are capable of producing highly plausible and provocative comments, often indistinguishable from those written by humans. These findings raise significant ethical questions about the use of AI in political discourse, disinformation, and manipulation campaigns. The paper concludes with a discussion of the broader implications for AI governance, platform regulation, and the development of detection tools to mitigate adversarial fine-tuning risks.

</details>


### [132] [GuiLoMo: Allocating Expert Number and Rank for LoRA-MoE via Bilevel Optimization with GuidedSelection Vectors](https://arxiv.org/abs/2506.14646)
*Hengyuan Zhang,Xinrong Chen,Yingmin Qiu,Xiao Liang,Ziyue Li,Guanyu Wang,Weiping Li,Tong Mo,Wenyue Li,Hayden Kwok-Hay So,Ngai Wong*

Main category: cs.CL

TL;DR: GuiLoMo提出了一种细粒度的层间专家数量和秩分配策略，通过优化指导向量（GSVs）提升LoRA-MoE的性能，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA-MoE方法在专家数量和秩分配上存在不足，限制了模型的潜力。

Method: 使用指导向量（GSVs）通过双层优化学习任务和模型需求，动态分配专家数量和秩。

Result: 在多个基准测试中，GuiLoMo表现优于或与基线方法相当。

Conclusion: 自适应专家配置显著提升了性能，为参数高效微调提供了新思路。

Abstract: Parameter-efficient fine-tuning (PEFT) methods, particularly Low-Rank Adaptation (LoRA), offer an efficient way to adapt large language models with reduced computational costs. However, their performance is limited by the small number of trainable parameters. Recent work combines LoRA with the Mixture-of-Experts (MoE), i.e., LoRA-MoE, to enhance capacity, but two limitations remain in hindering the full exploitation of its potential: 1) the influence of downstream tasks when assigning expert numbers, and 2) the uniform rank assignment across all LoRA experts, which restricts representational diversity. To mitigate these gaps, we propose GuiLoMo, a fine-grained layer-wise expert numbers and ranks allocation strategy with GuidedSelection Vectors (GSVs). GSVs are learned via a prior bilevel optimization process to capture both model- and task-specific needs, and are then used to allocate optimal expert numbers and ranks. Experiments on three backbone models across diverse benchmarks show that GuiLoMo consistently achieves superior or comparable performance to all baselines. Further analysis offers key insights into how expert numbers and ranks vary across layers and tasks, highlighting the benefits of adaptive expert configuration. Our code is available at https://github.com/Liar406/Gui-LoMo.git.

</details>


### [133] [Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality](https://arxiv.org/abs/2506.14681)
*Yuto Harada,Yusuke Yamauchi,Yusuke Oda,Yohei Oseki,Yusuke Miyao,Yu Takagi*

Main category: cs.CL

TL;DR: 论文研究了监督微调（SFT）在大型语言模型（LLM）中的作用，通过训练1000多个模型，发现数据集特性和层间修改对性能影响显著，困惑度是预测SFT效果的关键指标。


<details>
  <summary>Details</summary>
Motivation: 尽管SFT在LLM与人类指令对齐中至关重要，但其许多方面仍未被充分理解。

Method: 在多种数据集（如代码生成、数学推理和通用任务）上训练了1000多个SFT模型，分析了数据集特性和层间修改。

Result: 发现训练任务的协同效应因模型而异，困惑度能有效预测SFT效果，中层权重变化与性能提升相关性最强。

Conclusion: 强调了模型特定策略的重要性，并计划公开1000多个SFT模型以推动进一步研究。

Abstract: Supervised fine-tuning (SFT) is a critical step in aligning large language models (LLMs) with human instructions and values, yet many aspects of SFT remain poorly understood. We trained a wide range of base models on a variety of datasets including code generation, mathematical reasoning, and general-domain tasks, resulting in 1,000+ SFT models under controlled conditions. We then identified the dataset properties that matter most and examined the layer-wise modifications introduced by SFT. Our findings reveal that some training-task synergies persist across all models while others vary substantially, emphasizing the importance of model-specific strategies. Moreover, we demonstrate that perplexity consistently predicts SFT effectiveness--often surpassing superficial similarity between trained data and benchmark--and that mid-layer weight changes correlate most strongly with performance gains. We will release these 1,000+ SFT models and benchmark results to accelerate further research.

</details>


### [134] [Treasure Hunt: Real-time Targeting of the Long Tail using Training-Time Markers](https://arxiv.org/abs/2506.14702)
*Daniel D'souza,Julia Kreutzer,Adrien Morisot,Ahmet Üstün,Sara Hooker*

Main category: cs.CL

TL;DR: 论文提出了一种优化训练协议的方法，旨在提高模型在罕见和代表性不足用例上的性能和可控性。


<details>
  <summary>Details</summary>
Motivation: 解决现代机器学习在长尾数据（罕见和代表性不足的特征）上表现不佳的问题，同时提升模型的可控性。

Method: 通过创建数据特征和任务来源的详细分类法，显式控制生成属性并隐式条件化生成，微调基础模型以自动推断这些标记。

Result: 在开放生成质量上平均提升5.7%胜率，在代表性不足领域提升9.1%，在特定任务（如CodeRepair）上相对提升14.1%，在长度指令遵循上绝对提升35.3%。

Conclusion: 该方法显著提升了模型在长尾数据和可控性方面的表现，为优化训练协议提供了新思路。

Abstract: One of the most profound challenges of modern machine learning is performing well on the long-tail of rare and underrepresented features. Large general-purpose models are trained for many tasks, but work best on high-frequency use cases. After training, it is hard to adapt a model to perform well on specific use cases underrepresented in the training corpus. Relying on prompt engineering or few-shot examples to maximize the output quality on a particular test case can be frustrating, as models can be highly sensitive to small changes, react in unpredicted ways or rely on a fixed system prompt for maintaining performance. In this work, we ask: "Can we optimize our training protocols to both improve controllability and performance on underrepresented use cases at inference time?" We revisit the divide between training and inference techniques to improve long-tail performance while providing users with a set of control levers the model is trained to be responsive to. We create a detailed taxonomy of data characteristics and task provenance to explicitly control generation attributes and implicitly condition generations at inference time. We fine-tune a base model to infer these markers automatically, which makes them optional at inference time. This principled and flexible approach yields pronounced improvements in performance, especially on examples from the long tail of the training distribution. While we observe an average lift of 5.7% win rates in open-ended generation quality with our markers, we see over 9.1% gains in underrepresented domains. We also observe relative lifts of up to 14.1% on underrepresented tasks like CodeRepair and absolute improvements of 35.3% on length instruction following evaluations.

</details>


### [135] [Capacity Matters: a Proof-of-Concept for Transformer Memorization on Real-World Data](https://arxiv.org/abs/2506.14704)
*Anton Changalidis,Aki Härmä*

Main category: cs.CL

TL;DR: 论文研究了模型架构和数据配置对生成式Transformer记忆能力的影响，发现嵌入大小是主要决定因素，而增加层数可能对简单数据集不利。


<details>
  <summary>Details</summary>
Motivation: 探索模型架构和数据配置如何影响生成式Transformer的记忆能力，以优化模型设计。

Method: 使用SNOMED知识图谱生成的合成文本数据集训练模型，分析不同配置（如嵌入大小、层数、激活函数）的影响。

Result: 嵌入大小是学习速度和容量的主要决定因素，Softmax激活函数表现更稳定，数据复杂性提升记忆能力。

Conclusion: 研究为理解Transformer记忆机制提供了框架，并指导了结构化真实数据下的模型优化。

Abstract: This paper studies how the model architecture and data configurations influence the empirical memorization capacity of generative transformers. The models are trained using synthetic text datasets derived from the Systematized Nomenclature of Medicine (SNOMED) knowledge graph: triplets, representing static connections, and sequences, simulating complex relation patterns. The results show that embedding size is the primary determinant of learning speed and capacity, while additional layers provide limited benefits and may hinder performance on simpler datasets. Activation functions play a crucial role, and Softmax demonstrates greater stability and capacity. Furthermore, increasing the complexity of the data set seems to improve the final memorization. These insights improve our understanding of transformer memory mechanisms and provide a framework for optimizing model design with structured real-world data.

</details>


### [136] [Ring-lite: Scalable Reasoning via C3PO-Stabilized Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.14731)
*Ring Team,Bin Hu,Cai Chen,Deng Zhao,Ding Liu,Dingnan Jin,Feng Zhu,Hao Dai,Hongzhi Luan,Jia Guo,Jiaming Liu,Jiewei Wu,Jun Mei,Jun Zhou,Junbo Zhao,Junwu Xiong,Kaihong Zhang,Kuan Xu,Lei Liang,Liang Jiang,Liangcheng Fu,Longfei Zheng,Qiang Gao,Qing Cui,Quan Wan,Shaomian Zheng,Shuaicheng Li,Tongkai Yang,Wang Ren,Xiaodong Yan,Xiaopei Wan,Xiaoyun Feng,Xin Zhao,Xinxing Yang,Xinyu Kong,Xuemin Yang,Yang Li,Yingting Wu,Yongkang Liu,Zhankai Xu,Zhenduo Zhang,Zhenglei Zhou,Zhenyu Huang,Zhiqiang Zhang,Zihao Wang,Zujie Wen*

Main category: cs.CL

TL;DR: Ring-lite是一个基于混合专家（MoE）的大型语言模型，通过强化学习（RL）优化，实现了高效且鲁棒的推理能力。其性能与小型推理模型相当，但仅激活了三分之一的参数。


<details>
  <summary>Details</summary>
Motivation: 旨在通过结合蒸馏与强化学习，解决MoE RL训练中的优化不稳定性和多域数据冲突问题，提升模型效率与性能。

Method: 提出联合训练流程，包括C3PO算法以增强训练稳定性，基于熵损失的蒸馏检查点选择，以及两阶段训练范式处理多域数据冲突。

Result: 模型在多个基准测试中表现优异，性能与SOTA小型模型相当，同时显著减少参数激活量。

Conclusion: Ring-lite展示了MoE RL训练的潜力，并通过算法-系统协同设计解决了关键挑战，为未来研究提供了实用工具和数据。

Abstract: We present Ring-lite, a Mixture-of-Experts (MoE)-based large language model optimized via reinforcement learning (RL) to achieve efficient and robust reasoning capabilities. Built upon the publicly available Ling-lite model, a 16.8 billion parameter model with 2.75 billion activated parameters, our approach matches the performance of state-of-the-art (SOTA) small-scale reasoning models on challenging benchmarks (e.g., AIME, LiveCodeBench, GPQA-Diamond) while activating only one-third of the parameters required by comparable models. To accomplish this, we introduce a joint training pipeline integrating distillation with RL, revealing undocumented challenges in MoE RL training. First, we identify optimization instability during RL training, and we propose Constrained Contextual Computation Policy Optimization(C3PO), a novel approach that enhances training stability and improves computational throughput via algorithm-system co-design methodology. Second, we empirically demonstrate that selecting distillation checkpoints based on entropy loss for RL training, rather than validation metrics, yields superior performance-efficiency trade-offs in subsequent RL training. Finally, we develop a two-stage training paradigm to harmonize multi-domain data integration, addressing domain conflicts that arise in training with mixed dataset. We will release the model, dataset, and code.

</details>


### [137] [Reasoning with Exploration: An Entropy Perspective](https://arxiv.org/abs/2506.14758)
*Daixuan Cheng,Shaohan Huang,Xuekai Zhu,Bo Dai,Wayne Xin Zhao,Zhenliang Zhang,Furu Wei*

Main category: cs.CL

TL;DR: 论文提出通过熵信号增强语言模型的探索性推理，仅需一行代码修改即可显著提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型方法偏向利用而非探索，导致性能瓶颈，因此研究熵与探索性推理的关系。

Method: 在标准强化学习中增加基于熵的优势函数项，促进更长更深的推理链。

Result: 实验表明，该方法在Pass@K指标上显著提升，尤其是在大K值下。

Conclusion: 通过熵增强探索性推理，突破了语言模型推理能力的边界。

Abstract: Balancing exploration and exploitation is a central goal in reinforcement learning (RL). Despite recent advances in enhancing language model (LM) reasoning, most methods lean toward exploitation, and increasingly encounter performance plateaus. In this work, we revisit entropy -- a signal of exploration in RL -- and examine its relationship to exploratory reasoning in LMs. Through empirical analysis, we uncover strong positive correlations between high-entropy regions and three types of exploratory reasoning actions: (1) pivotal tokens that determine or connect logical steps, (2) reflective actions such as self-verification and correction, and (3) rare behaviors under-explored by the base LMs. Motivated by this, we introduce a minimal modification to standard RL with only one line of code: augmenting the advantage function with an entropy-based term. Unlike traditional maximum-entropy methods which encourage exploration by promoting uncertainty, we encourage exploration by promoting longer and deeper reasoning chains. Notably, our method achieves significant gains on the Pass@K metric -- an upper-bound estimator of LM reasoning capabilities -- even when evaluated with extremely large K values, pushing the boundaries of LM reasoning.

</details>


### [138] [From Bytes to Ideas: Language Modeling with Autoregressive U-Nets](https://arxiv.org/abs/2506.14761)
*Mathurin Videau,Badr Youbi Idrissi,Alessandro Leite,Marc Schoenauer,Olivier Teytaud,David Lopez-Paz*

Main category: cs.CL

TL;DR: 论文提出了一种自回归U-Net模型，通过学习动态嵌入自己的标记，解决了传统BPE等静态分词方法的局限性，实现了多尺度的序列处理。


<details>
  <summary>Details</summary>
Motivation: 传统分词方法（如BPE）固定了输入文本的粒度，限制了语言模型的灵活性和预测能力。

Method: 采用自回归U-Net模型，从原始字节开始逐步聚合为单词、词组（最多4个单词），实现多尺度序列处理。

Result: 浅层结构与BPE基线性能相当，深层结构展现出潜力；模型能同时处理字符级任务和跨低资源语言的知识迁移。

Conclusion: 动态分词嵌入模型提供了更灵活的文本处理方式，适用于多任务和多语言场景。

Abstract: Tokenization imposes a fixed granularity on the input text, freezing how a language model operates on data and how far in the future it predicts. Byte Pair Encoding (BPE) and similar schemes split text once, build a static vocabulary, and leave the model stuck with that choice. We relax this rigidity by introducing an autoregressive U-Net that learns to embed its own tokens as it trains. The network reads raw bytes, pools them into words, then pairs of words, then up to 4 words, giving it a multi-scale view of the sequence. At deeper stages, the model must predict further into the future -- anticipating the next few words rather than the next byte -- so deeper stages focus on broader semantic patterns while earlier stages handle fine details. When carefully tuning and controlling pretraining compute, shallow hierarchies tie strong BPE baselines, and deeper hierarchies have a promising trend. Because tokenization now lives inside the model, the same system can handle character-level tasks and carry knowledge across low-resource languages.

</details>


### [139] [A Variational Framework for Improving Naturalness in Generative Spoken Language Models](https://arxiv.org/abs/2506.14767)
*Li-Wei Chen,Takuya Higuchi,Zakaria Aldeneh,Ahmed Hussen Abdelaziz,Alexander Rudnicky*

Main category: cs.CL

TL;DR: 论文提出了一种端到端的变分方法，自动学习编码连续语音属性以增强语义标记，解决了现有方法依赖手动特征提取的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过添加音高特征来增强语义标记，但音高无法完全代表副语言属性，且需要手动特征工程。

Method: 采用端到端的变分方法，自动学习编码连续语音属性，无需手动提取特征。

Result: 该方法生成的语音在人类评分中更受青睐。

Conclusion: 提出的方法有效提升了语音生成的流畅性和自然度，且无需手动特征工程。

Abstract: The success of large language models in text processing has inspired their adaptation to speech modeling. However, since speech is continuous and complex, it is often discretized for autoregressive modeling. Speech tokens derived from self-supervised models (known as semantic tokens) typically focus on the linguistic aspects of speech but neglect prosodic information. As a result, models trained on these tokens can generate speech with reduced naturalness. Existing approaches try to fix this by adding pitch features to the semantic tokens. However, pitch alone cannot fully represent the range of paralinguistic attributes, and selecting the right features requires careful hand-engineering. To overcome this, we propose an end-to-end variational approach that automatically learns to encode these continuous speech attributes to enhance the semantic tokens. Our approach eliminates the need for manual extraction and selection of paralinguistic features. Moreover, it produces preferred speech continuations according to human raters. Code, samples and models are available at https://github.com/b04901014/vae-gslm.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [140] [Knowledge Compression via Question Generation: Enhancing Multihop Document Retrieval without Fine-tuning](https://arxiv.org/abs/2506.13778)
*Anvi Alex Eponon,Moein Shahiki-Tash,Ildar Batyrshin,Christian E. Maldonado-Sifuentes,Grigori Sidorov,Alexander Gelbukh*

Main category: cs.IR

TL;DR: 提出一种基于问题编码的知识表示方法，显著提升RAG系统性能，无需微调或传统分块。


<details>
  <summary>Details</summary>
Motivation: 改进检索增强生成系统，避免微调和传统分块的限制，提升检索效率和准确性。

Method: 通过生成覆盖词法和语义空间的问题编码文本内容，结合自定义语法重排序方法。

Result: 在单跳检索中Recall@3达0.84，多跳任务F1分数0.52，优于传统方法。

Conclusion: 该方法高效、可扩展，显著降低存储需求和延迟，适合大规模应用。

Abstract: This study presents a question-based knowledge encoding approach that improves retrieval-augmented generation (RAG) systems without requiring fine-tuning or traditional chunking. We encode textual content using generated questions that span the lexical and semantic space, creating targeted retrieval cues combined with a custom syntactic reranking method.
  In single-hop retrieval over 109 scientific papers, our approach achieves a Recall@3 of 0.84, outperforming traditional chunking methods by 60 percent. We also introduce "paper-cards", concise paper summaries under 300 characters, which enhance BM25 retrieval, increasing MRR@3 from 0.56 to 0.85 on simplified technical queries.
  For multihop tasks, our reranking method reaches an F1 score of 0.52 with LLaMA2-Chat-7B on the LongBench 2WikiMultihopQA dataset, surpassing chunking and fine-tuned baselines which score 0.328 and 0.412 respectively.
  This method eliminates fine-tuning requirements, reduces retrieval latency, enables intuitive question-driven knowledge access, and decreases vector storage demands by 80%, positioning it as a scalable and efficient RAG alternative.

</details>


### [141] [AcademicBrowse: Benchmarking Academic Browse Ability of LLMs](https://arxiv.org/abs/2506.13784)
*Junting Zhou,Wang Li,Yiyan Liao,Nengyuan Zhang,Tingjia Miaoand Zhihui Qi,Yuhan Wu,Tong Yang*

Main category: cs.IR

TL;DR: AcademicBrowse是一个专门评估大语言模型（LLMs）在学术研究中复杂信息检索能力的数据集，填补了现有基准在学术搜索需求上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如OpenAI的BrowseComp）主要关注通用搜索场景，未能满足学术搜索的特定需求，如深度文献追踪、专业数据库支持、长尾学术知识导航及学术严谨性。

Method: 提出AcademicBrowse数据集，具有学术实用性、高难度、简洁评估和广泛覆盖等关键特性。

Result: 数据集涵盖至少15个学科，通过限制条件确保答案唯一性，并附带清晰来源和解决方案解释，便于审计验证。

Conclusion: AcademicBrowse有望更精确地衡量和提升LLMs在复杂学术信息检索任务中的表现。

Abstract: Large Language Models (LLMs)' search capabilities have garnered significant attention. Existing benchmarks, such as OpenAI's BrowseComp, primarily focus on general search scenarios and fail to adequately address the specific demands of academic search. These demands include deeper literature tracing and organization, professional support for academic databases, the ability to navigate long-tail academic knowledge, and ensuring academic rigor. Here, we proposed AcademicBrowse, the first dataset specifically designed to evaluate the complex information retrieval capabilities of Large Language Models (LLMs) in academic research. AcademicBrowse possesses the following key characteristics: Academic Practicality, where question content closely mirrors real academic learning and research environments, avoiding deliberately misleading models; High Difficulty, with answers that are challenging for single models (e.g., Grok DeepSearch or Gemini Deep Research) to provide directly, often requiring at least three deep searches to derive; Concise Evaluation, where limiting conditions ensure answers are as unique as possible, accompanied by clear sources and brief solution explanations, greatly facilitating subsequent audit and verification, surpassing the current lack of analyzed search datasets both domestically and internationally; and Broad Coverage, as the dataset spans at least 15 different academic disciplines. Through AcademicBrowse, we expect to more precisely measure and promote the performance improvement of LLMs in complex academic information retrieval tasks. The data is available at: https://huggingface.co/datasets/PKU-DS-LAB/AcademicBrowse

</details>


### [142] [InsertRank: LLMs can reason over BM25 scores to Improve Listwise Reranking](https://arxiv.org/abs/2506.14086)
*Rahul Seetharaman,Kaustubh D. Dhole,Aman Bansal*

Main category: cs.IR

TL;DR: InsertRank是一种基于LLM的重新排序器，通过结合BM25等词汇信号提升检索性能，在BRIGHT和R2MED基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 用户对复杂查询的需求增加，需要LLM具备推理能力，而现有方法仍有改进空间。

Method: 提出InsertRank，结合BM25分数等词汇信号进行重新排序。

Result: 在BRIGHT和R2MED基准测试中表现优于现有方法，Deepseek-R1模型分别达到37.5和51.1分。

Conclusion: InsertRank通过结合词汇信号显著提升了LLM在复杂查询中的检索效果。

Abstract: Large Language Models (LLMs) have demonstrated significant strides across various information retrieval tasks, particularly as rerankers, owing to their strong generalization and knowledge-transfer capabilities acquired from extensive pretraining. In parallel, the rise of LLM-based chat interfaces has raised user expectations, encouraging users to pose more complex queries that necessitate retrieval by ``reasoning'' over documents rather than through simple keyword matching or semantic similarity. While some recent efforts have exploited reasoning abilities of LLMs for reranking such queries, considerable potential for improvement remains. In that regards, we introduce InsertRank, an LLM-based reranker that leverages lexical signals like BM25 scores during reranking to further improve retrieval performance. InsertRank demonstrates improved retrieval effectiveness on -- BRIGHT, a reasoning benchmark spanning 12 diverse domains, and R2MED, a specialized medical reasoning retrieval benchmark spanning 8 different tasks. We conduct an exhaustive evaluation and several ablation studies and demonstrate that InsertRank consistently improves retrieval effectiveness across multiple families of LLMs, including GPT, Gemini, and Deepseek models. %In addition, we also conduct ablation studies on normalization by varying the scale of the BM25 scores, and positional bias by shuffling the order of the documents. With Deepseek-R1, InsertRank achieves a score of 37.5 on the BRIGHT benchmark. and 51.1 on the R2MED benchmark, surpassing previous methods.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [143] [Multimodal Fusion with Semi-Supervised Learning Minimizes Annotation Quantity for Modeling Videoconference Conversation Experience](https://arxiv.org/abs/2506.13971)
*Andrew Chang,Chenkai Hu,Ji Qi,Zhuojian Wei,Kexin Zhang,Viswadruth Akkaraju,David Poeppel,Dustin Freeman*

Main category: eess.AS

TL;DR: 论文提出了一种半监督学习方法，用于预测视频会议中的负面体验时刻，显著减少了标注数据的成本。


<details>
  <summary>Details</summary>
Motivation: 视频会议中的负面体验（如流畅性或愉悦感丧失）研究不足，且自然数据中这些时刻稀少，标注成本高。

Method: 采用半监督学习（SSL），结合标注和未标注的多模态（音频、面部、文本）数据，训练深度特征预测负面时刻。

Result: SSL模型的ROC-AUC为0.9，F1分数为0.6，优于监督学习模型，仅用8%标注数据即可达到96%全数据性能。

Conclusion: 该方法为视频会议体验建模提供了一种高效的标注框架。

Abstract: Group conversations over videoconferencing are a complex social behavior. However, the subjective moments of negative experience, where the conversation loses fluidity or enjoyment remain understudied. These moments are infrequent in naturalistic data, and thus training a supervised learning (SL) model requires costly manual data annotation. We applied semi-supervised learning (SSL) to leverage targeted labeled and unlabeled clips for training multimodal (audio, facial, text) deep features to predict non-fluid or unenjoyable moments in holdout videoconference sessions. The modality-fused co-training SSL achieved an ROC-AUC of 0.9 and an F1 score of 0.6, outperforming SL models by up to 4% with the same amount of labeled data. Remarkably, the best SSL model with just 8% labeled data matched 96% of the SL model's full-data performance. This shows an annotation-efficient framework for modeling videoconference experience.

</details>


### [144] [Improving Practical Aspects of End-to-End Multi-Talker Speech Recognition for Online and Offline Scenarios](https://arxiv.org/abs/2506.14204)
*Aswin Shanmugam Subramanian,Amit Das,Naoyuki Kanda,Jinyu Li,Xiaofei Wang,Yifan Gong*

Main category: eess.AS

TL;DR: 扩展了SOT框架，平衡延迟与准确性，适用于流式和离线ASR应用，提出CSS前端、双模型和segSOT改进。


<details>
  <summary>Details</summary>
Motivation: 解决流式和离线ASR应用中延迟与准确性的平衡问题，满足实时字幕和摘要需求。

Method: 1. 使用CSS单通道前端与E2E系统结合处理重叠语音；2. 采用双模型（流式Conformer Transducer和离线Seq2Seq）或两阶段编码器模型；3. 探索segSOT改进离线场景和多说话者转录。

Result: CSS提升重叠语音识别准确性，双模型和segSOT优化流式与离线性能。

Conclusion: 提出的方法在延迟与准确性间取得平衡，适用于多种ASR应用场景。

Abstract: We extend the frameworks of Serialized Output Training (SOT) to address practical needs of both streaming and offline automatic speech recognition (ASR) applications. Our approach focuses on balancing latency and accuracy, catering to real-time captioning and summarization requirements. We propose several key improvements: (1) Leveraging Continuous Speech Separation (CSS) single-channel front-end with end-to-end (E2E) systems for highly overlapping scenarios, challenging the conventional wisdom of E2E versus cascaded setups. The CSS framework improves the accuracy of the ASR system by separating overlapped speech from multiple speakers. (2) Implementing dual models -- Conformer Transducer for streaming and Sequence-to-Sequence for offline -- or alternatively, a two-pass model based on cascaded encoders. (3) Exploring segment-based SOT (segSOT) which is better suited for offline scenarios while also enhancing readability of multi-talker transcriptions.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [145] [BraTS orchestrator : Democratizing and Disseminating state-of-the-art brain tumor image analysis](https://arxiv.org/abs/2506.13807)
*Florian Kofler,Marcel Rosier,Mehdi Astaraki,Ujjwal Baid,Hendrik Möller,Josef A. Buchner,Felix Steinbauer,Eva Oswald,Ezequiel de la Rosa,Ivan Ezhov,Constantin von See,Jan Kirschke,Anton Schmick,Sarthak Pati,Akis Linardos,Carla Pitarch,Sanyukta Adap,Jeffrey Rudie,Maria Correia de Verdier,Rachit Saluja,Evan Calabrese,Dominic LaBella,Mariam Aboian,Ahmed W. Moawad,Nazanin Maleki,Udunna Anazodo,Maruf Adewole,Marius George Linguraru,Anahita Fathi Kazerooni,Zhifan Jiang,Gian Marco Conte,Hongwei Li,Juan Eugenio Iglesias,Spyridon Bakas,Benedikt Wiestler,Marie Piraud,Bjoern Menze*

Main category: eess.IV

TL;DR: BraTS orchestrator是一个开源Python工具包，旨在简化BraTS挑战赛中先进算法的使用，促进其在科研和临床中的普及。


<details>
  <summary>Details</summary>
Motivation: 尽管BraTS挑战赛在脑肿瘤图像分析方面取得了显著进展，但其算法在科学和临床领域的应用仍有限。

Method: 通过开发开源Python工具包BraTS orchestrator，提供直观教程，简化深度学习复杂性。

Result: 该工具包使研究人员和临床医生能够轻松部署BraTS的先进算法。

Conclusion: BraTS orchestrator有助于将BraTS社区的成果推广到更广泛的神经放射学和神经肿瘤学领域。

Abstract: The Brain Tumor Segmentation (BraTS) cluster of challenges has significantly advanced brain tumor image analysis by providing large, curated datasets and addressing clinically relevant tasks. However, despite its success and popularity, algorithms and models developed through BraTS have seen limited adoption in both scientific and clinical communities. To accelerate their dissemination, we introduce BraTS orchestrator, an open-source Python package that provides seamless access to state-of-the-art segmentation and synthesis algorithms for diverse brain tumors from the BraTS challenge ecosystem. Available on GitHub (https://github.com/BrainLesion/BraTS), the package features intuitive tutorials designed for users with minimal programming experience, enabling both researchers and clinicians to easily deploy winning BraTS algorithms for inference. By abstracting the complexities of modern deep learning, BraTS orchestrator democratizes access to the specialized knowledge developed within the BraTS community, making these advances readily available to broader neuro-radiology and neuro-oncology audiences.

</details>


### [146] [Reliable Noninvasive Glucose Sensing via CNN-Based Spectroscopy](https://arxiv.org/abs/2506.13819)
*El Arbi Belfarsi,Henry Flores,Maria Valero*

Main category: eess.IV

TL;DR: 提出了一种基于短波红外光谱的双模态AI框架，结合CNN和光电二极管传感器，用于非侵入性血糖监测，具有高精度和可穿戴性。


<details>
  <summary>Details</summary>
Motivation: 开发一种平衡临床准确性、成本效益和可穿戴性的非侵入性血糖监测解决方案。

Method: 使用多波长SWIR成像系统与CNN捕捉空间特征，以及光电二极管电压传感器与机器学习回归器分析光学信号。

Result: CNN的MAPE为4.82%，光电二极管系统在Clarke误差网格中达到86.4% Zone A准确率。

Conclusion: 该框架为可靠的非侵入性血糖监测提供了先进解决方案。

Abstract: In this study, we present a dual-modal AI framework based on short-wave infrared (SWIR) spectroscopy. The first modality employs a multi-wavelength SWIR imaging system coupled with convolutional neural networks (CNNs) to capture spatial features linked to glucose absorption. The second modality uses a compact photodiode voltage sensor and machine learning regressors (e.g., random forest) on normalized optical signals. Both approaches were evaluated on synthetic blood phantoms and skin-mimicking materials across physiological glucose levels (70 to 200 mg/dL). The CNN achieved a mean absolute percentage error (MAPE) of 4.82% at 650 nm with 100% Zone A coverage in the Clarke Error Grid, while the photodiode system reached 86.4% Zone A accuracy. This framework constitutes a state-of-the-art solution that balances clinical accuracy, cost efficiency, and wearable integration, paving the way for reliable continuous non-invasive glucose monitoring.

</details>


### [147] [Latent Anomaly Detection: Masked VQ-GAN for Unsupervised Segmentation in Medical CBCT](https://arxiv.org/abs/2506.14209)
*Pengwei Wang*

Main category: eess.IV

TL;DR: 本文提出了一种无监督训练方法，用于自动识别ONJ影像中的异常，通过两阶段训练流程实现，并在模拟和真实患者数据上成功分割。


<details>
  <summary>Details</summary>
Motivation: 由于ONJ影像中标记数据的稀缺性，监督训练不切实际，因此需要开发无监督训练方法。

Method: 提出两阶段训练流程：第一阶段训练VQ-GAN重建正常样本；第二阶段通过随机立方体掩码和ONJ特定掩码训练新编码器。

Result: 方法在模拟和真实患者数据上实现了成功分割。

Conclusion: 该方法减轻了手动标记负担，并有望直接用于3D打印。

Abstract: Advances in treatment technology now allow for the use of customizable 3D-printed hydrogel wound dressings for patients with osteoradionecrosis (ORN) of the jaw (ONJ). Meanwhile, deep learning has enabled precise segmentation of 3D medical images using tools like nnUNet.
  However, the scarcity of labeled data in ONJ imaging makes supervised training impractical. This study aims to develop an unsupervised training approach for automatically identifying anomalies in imaging scans.
  We propose a novel two-stage training pipeline. In the first stage, a VQ-GAN is trained to accurately reconstruct normal subjects. In the second stage, random cube masking and ONJ-specific masking are applied to train a new encoder capable of recovering the data.
  The proposed method achieves successful segmentation on both simulated and real patient data.
  This approach provides a fast initial segmentation solution, reducing the burden of manual labeling. Additionally, it has the potential to be directly used for 3D printing when combined with hand-tuned post-processing.

</details>


### [148] [orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation of Surgical Images and Ground Truth Labels](https://arxiv.org/abs/2506.14303)
*Niran Nataraj,Maina Sogabe,Kenji Kawashima*

Main category: eess.IV

TL;DR: orGAN是一个基于GAN的系统，用于生成高保真、带注释的手术出血图像，解决了医学影像中数据多样性不足、伦理问题和标注成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 医学影像中深度学习的应用面临数据多样性有限、伦理问题、高采集成本和精确标注需求等挑战，尤其是手术中出血检测和定位缺乏高质量数据集。

Method: orGAN基于StyleGAN和关系位置学习生成逼真的出血图像，并通过LaMa修复模块恢复干净的术前图像，实现像素级标注。

Result: 评估显示，orGAN生成的图像与真实数据结合后，在手术场景中达到90%的检测准确率和99%的帧级准确率。

Conclusion: orGAN显著提升了伦理、高效且低成本生成真实标注出血数据集的能力，推动了AI在手术实践中的广泛应用。

Abstract: Deep learning in medical imaging faces obstacles: limited data diversity, ethical issues, high acquisition costs, and the need for precise annotations. Bleeding detection and localization during surgery is especially challenging due to the scarcity of high-quality datasets that reflect real surgical scenarios. We propose orGAN, a GAN-based system for generating high-fidelity, annotated surgical images of bleeding. By leveraging small "mimicking organ" datasets, synthetic models that replicate tissue properties and bleeding, our approach reduces ethical concerns and data-collection costs. orGAN builds on StyleGAN with Relational Positional Learning to simulate bleeding events realistically and mark bleeding coordinates. A LaMa-based inpainting module then restores clean, pre-bleed visuals, enabling precise pixel-level annotations. In evaluations, a balanced dataset of orGAN and mimicking-organ images achieved 90% detection accuracy in surgical settings and up to 99% frame-level accuracy. While our development data lack diverse organ morphologies and contain intraoperative artifacts, orGAN markedly advances ethical, efficient, and cost-effective creation of realistic annotated bleeding datasets, supporting broader integration of AI in surgical practice.

</details>


### [149] [BRISC: Annotated Dataset for Brain Tumor Segmentation and Classification with Swin-HAFNet](https://arxiv.org/abs/2506.14318)
*Amirreza Fateh,Yasin Rezvani,Sara Moayedi,Sadjad Rezvani,Fatemeh Fateh,Mansoor Fateh*

Main category: eess.IV

TL;DR: 本文介绍了一个新的MRI数据集，专门用于脑肿瘤分割和分类任务，包含6,000个标注样本，并提出了一种基于Transformer的分割模型，取得了82.3%的加权平均IoU。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤的准确分割和分类在医学图像分析中仍具挑战性，主要由于缺乏高质量、平衡且多样化的数据集。

Method: 提出了一种新的Transformer分割模型，并在新数据集上进行了基准测试。

Result: 模型在所有肿瘤类别中均表现优异，加权平均IoU达到82.3%。

Conclusion: 该数据集为神经肿瘤学中的机器学习应用提供了宝贵资源，可用于学术研究和临床决策支持。

Abstract: Accurate segmentation and classification of brain tumors from Magnetic Resonance Imaging (MRI) remain key challenges in medical image analysis, largely due to the lack of high-quality, balanced, and diverse datasets. In this work, we present a new curated MRI dataset designed specifically for brain tumor segmentation and classification tasks. The dataset comprises 6,000 contrast-enhanced T1-weighted MRI scans annotated by certified radiologists and physicians, spanning three major tumor types-glioma, meningioma, and pituitary-as well as non-tumorous cases. Each sample includes high-resolution labels and is categorized across axial, sagittal, and coronal imaging planes to facilitate robust model development and cross-view generalization. To demonstrate the utility of the dataset, we propose a transformer-based segmentation model and benchmark it against established baselines. Our method achieves the highest weighted mean Intersection-over-Union (IoU) of 82.3%, with improvements observed across all tumor categories. Importantly, this study serves primarily as an introduction to the dataset, establishing foundational benchmarks for future research. We envision this dataset as a valuable resource for advancing machine learning applications in neuro-oncology, supporting both academic research and clinical decision-support development. datasetlink: https://www.kaggle.com/datasets/briscdataset/brisc2025/

</details>


### [150] [Compressed Video Super-Resolution based on Hierarchical Encoding](https://arxiv.org/abs/2506.14381)
*Yuxuan Jiang,Siyue Teng,Qiang Zhu,Chen Feng,Chengxi Zeng,Fan Zhang,Shuyuan Zhu,Bing Zeng,David Bull*

Main category: eess.IV

TL;DR: VSR-HE是一种通用视频超分辨率方法，专注于提升压缩内容的感知质量，通过分层编码变换块消除压缩伪影。


<details>
  <summary>Details</summary>
Motivation: 针对高压缩场景，提升低分辨率视频质量，消除H.265/HEVC编码引入的伪影。

Method: 采用分层编码变换块，优化处理多种量化参数下的压缩伪影，训练和评估多样化压缩设置。

Result: 有效恢复细节并保持视觉保真度，已提交至ICME 2025挑战赛。

Conclusion: VSR-HE在压缩视频超分辨率任务中表现出色，具备鲁棒性和泛化能力。

Abstract: This paper presents a general-purpose video super-resolution (VSR) method, dubbed VSR-HE, specifically designed to enhance the perceptual quality of compressed content. Targeting scenarios characterized by heavy compression, the method upscales low-resolution videos by a ratio of four, from 180p to 720p or from 270p to 1080p. VSR-HE adopts hierarchical encoding transformer blocks and has been sophisticatedly optimized to eliminate a wide range of compression artifacts commonly introduced by H.265/HEVC encoding across various quantization parameter (QP) levels. To ensure robustness and generalization, the model is trained and evaluated under diverse compression settings, allowing it to effectively restore fine-grained details and preserve visual fidelity. The proposed VSR-HE has been officially submitted to the ICME 2025 Grand Challenge on VSR for Video Conferencing (Team BVI-VSR), under both the Track 1 (General-Purpose Real-World Video Content) and Track 2 (Talking Head Videos).

</details>


### [151] [A large-scale heterogeneous 3D magnetic resonance brain imaging dataset for self-supervised learning](https://arxiv.org/abs/2506.14432)
*Asbjørn Munk,Stefano Cerri,Jakob Ambsdorf,Julia Machnio,Sebastian Nørgaard Llambias,Vardan Nersesjan,Christian Hedeager Krag,Peirong Liu,Pablo Rocamora García,Mostafa Mehdipour Ghazi,Mikael Boesen,Michael Eriksen Benros,Juan Eugenio Iglesias,Mads Nielsen*

Main category: eess.IV

TL;DR: FOMO60K是一个包含60,529个脑部MRI扫描的大规模异构数据集，旨在支持医学影像中自监督学习方法的开发和基准测试。


<details>
  <summary>Details</summary>
Motivation: 提供大规模、多样化的脑部MRI数据集，以降低新用户的入门门槛，并促进医学影像中自监督学习的研究。

Method: 数据集整合了16个公开来源的临床和研究级图像，仅进行最小预处理以保留原始图像特征，并提供自监督预训练和微调的代码。

Result: FOMO60K包含13,900个会话和11,187名受试者的数据，涵盖多种MRI序列和广泛的解剖及病理变异性。

Conclusion: FOMO60K为医学影像中的自监督学习提供了丰富的资源，支持大规模方法的开发和评估。

Abstract: We present FOMO60K, a large-scale, heterogeneous dataset of 60,529 brain Magnetic Resonance Imaging (MRI) scans from 13,900 sessions and 11,187 subjects, aggregated from 16 publicly available sources. The dataset includes both clinical- and research-grade images, multiple MRI sequences, and a wide range of anatomical and pathological variability, including scans with large brain anomalies. Minimal preprocessing was applied to preserve the original image characteristics while reducing barriers to entry for new users. Accompanying code for self-supervised pretraining and finetuning is provided. FOMO60K is intended to support the development and benchmarking of self-supervised learning methods in medical imaging at scale.

</details>


### [152] [Towards Reliable WMH Segmentation under Domain Shift: An Application Study using Maximum Entropy Regularization to Improve Uncertainty Estimation](https://arxiv.org/abs/2506.14497)
*Franco Matzkin,Agostina Larrazabal,Diego H Milone,Jose Dolz,Enzo Ferrante*

Main category: eess.IV

TL;DR: 该研究提出最大熵正则化技术，用于改善白质高信号（WMH）分割模型的校准和不确定性估计，以应对领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 领域偏移（如MRI机器类型或采集参数的变化）对WMH分割模型的校准和不确定性估计带来挑战，影响临床决策。

Method: 使用U-Net架构，结合最大熵正则化技术，在两个公开数据集上评估模型性能，指标包括Dice系数、预期校准误差和基于熵的不确定性估计。

Result: 基于熵的不确定性估计能预测分割错误，最大熵正则化增强了不确定性与分割性能的关联，并改善了领域偏移下的模型校准。

Conclusion: 最大熵正则化技术能有效提升WMH分割模型在领域偏移下的鲁棒性和不确定性估计能力。

Abstract: Accurate segmentation of white matter hyperintensities (WMH) is crucial for clinical decision-making, particularly in the context of multiple sclerosis. However, domain shifts, such as variations in MRI machine types or acquisition parameters, pose significant challenges to model calibration and uncertainty estimation. This study investigates the impact of domain shift on WMH segmentation by proposing maximum-entropy regularization techniques to enhance model calibration and uncertainty estimation, with the purpose of identifying errors post-deployment using predictive uncertainty as a proxy measure that does not require ground-truth labels. To do this, we conducted experiments using a U-Net architecture to evaluate these regularization schemes on two publicly available datasets, assessing performance with the Dice coefficient, expected calibration error, and entropy-based uncertainty estimates. Our results show that entropy-based uncertainty estimates can anticipate segmentation errors, and that maximum-entropy regularization further strengthens the correlation between uncertainty and segmentation performance while also improving model calibration under domain shift.

</details>


### [153] [Integrating Radiomics with Deep Learning Enhances Multiple Sclerosis Lesion Delineation](https://arxiv.org/abs/2506.14524)
*Nadezhda Alsahanova,Pavel Bartenev,Maksim Sharaev,Milos Ljubisavljevic,Taleb Al. Mansoori,Yauhen Statsenko*

Main category: eess.IV

TL;DR: 该研究通过结合放射组学特征和原始影像数据，改进了多发性硬化（MS）病灶分割的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在多发性硬化病灶分割中存在鲁棒性问题，研究旨在通过数据融合提升性能。

Method: 提出新的放射组学特征（浓度率和Rényi熵），并与原始影像数据融合，采用ResNeXt-UNet和注意力增强U-Net架构进行实验。

Result: 放射组学增强的ResNeXt-UNet显著提升了分割精度和敏感性（Dice得分0.774±0.05），注意力增强U-Net模型稳定性更高。

Conclusion: 融合放射组学与原始影像数据能显著提升分割性能和模型稳定性。

Abstract: Background: Accurate lesion segmentation is critical for multiple sclerosis (MS) diagnosis, yet current deep learning approaches face robustness challenges.
  Aim: This study improves MS lesion segmentation by combining data fusion and deep learning techniques.
  Materials and Methods: We suggested novel radiomic features (concentration rate and Rényi entropy) to characterize different MS lesion types and fused these with raw imaging data. The study integrated radiomic features with imaging data through a ResNeXt-UNet architecture and attention-augmented U-Net architecture. Our approach was evaluated on scans from 46 patients (1102 slices), comparing performance before and after data fusion.
  Results: The radiomics-enhanced ResNeXt-UNet demonstrated high segmentation accuracy, achieving significant improvements in precision and sensitivity over the MRI-only baseline and a Dice score of 0.774$\pm$0.05; p<0.001 according to Bonferroni-adjusted Wilcoxon signed-rank tests. The radiomics-enhanced attention-augmented U-Net model showed a greater model stability evidenced by reduced performance variability (SDD = 0.18 $\pm$ 0.09 vs. 0.21 $\pm$ 0.06; p=0.03) and smoother validation curves with radiomics integration.
  Conclusion: These results validate our hypothesis that fusing radiomics with raw imaging data boosts segmentation performance and stability in state-of-the-art models.

</details>


### [154] [Plug-and-Play with 2.5D Artifact Reduction Prior for Fast and Accurate Industrial Computed Tomography Reconstruction](https://arxiv.org/abs/2506.14719)
*Haley Duba-Sullivan,Aniket Pramanik,Venkatakrishnan Singanallur,Amirkoushyar Ziabari*

Main category: eess.IV

TL;DR: 提出了一种基于2.5D CNN的PnP重建方法，用于稀疏视图XCT扫描，显著提升了重建质量并减少伪影。


<details>
  <summary>Details</summary>
Motivation: 传统2D CNN在XCT重建中仅能捕获切片独立信息，限制了性能。2.5D CNN能利用相邻切片信息，提升重建效果。

Method: 采用2.5D CNN作为先验的PnP重建框架，结合模拟和实验数据训练，直接抑制XCT常见伪影。

Result: 实验表明，2.5D方法在保留结构细节（如孔隙形状）和伪影抑制方面优于2D方法，且具有跨域泛化能力。

Conclusion: 2.5D CNN先验显著提升了XCT重建质量，无需额外预处理，适用于实际应用。

Abstract: Cone-beam X-ray computed tomography (XCT) is an essential imaging technique for generating 3D reconstructions of internal structures, with applications ranging from medical to industrial imaging. Producing high-quality reconstructions typically requires many X-ray measurements; this process can be slow and expensive, especially for dense materials. Recent work incorporating artifact reduction priors within a plug-and-play (PnP) reconstruction framework has shown promising results in improving image quality from sparse-view XCT scans while enhancing the generalizability of deep learning-based solutions. However, this method uses a 2D convolutional neural network (CNN) for artifact reduction, which captures only slice-independent information from the 3D reconstruction, limiting performance. In this paper, we propose a PnP reconstruction method that uses a 2.5D artifact reduction CNN as the prior. This approach leverages inter-slice information from adjacent slices, capturing richer spatial context while remaining computationally efficient. We show that this 2.5D prior not only improves the quality of reconstructions but also enables the model to directly suppress commonly occurring XCT artifacts (such as beam hardening), eliminating the need for artifact correction pre-processing. Experiments on both experimental and synthetic cone-beam XCT data demonstrate that the proposed method better preserves fine structural details, such as pore size and shape, leading to more accurate defect detection compared to 2D priors. In particular, we demonstrate strong performance on experimental XCT data using a 2.5D artifact reduction prior trained entirely on simulated scans, highlighting the proposed method's ability to generalize across domains.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [155] [Déjà Vu: Efficient Video-Language Query Engine with Learning-based Inter-Frame Computation Reuse](https://arxiv.org/abs/2506.14107)
*Jinwoo Hwang,Daeun Kim,Sangyeop Lee,Yoonsung Kim,Guseul Heo,Hojoon Kim,Yunseok Jeong,Tadiwos Meaza,Eunhyeok Park,Jeongseob Ahn,Jongse Park*

Main category: cs.DC

TL;DR: Déjà Vu是一种视频语言查询引擎，通过重用连续帧的计算加速ViT-based VideoLMs，显著提升大规模视频分析的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有VideoLMs在处理大规模视频时，因ViT逐帧计算导致高计算成本，难以实际部署，亟需高效解决方案。

Method: 提出ReuseViT模型，检测帧间重用机会以减少计算量，并结合内存-计算联合压缩技术将计算节省转化为实际性能提升。

Result: 在三个VideoLM任务中，Déjà Vu将嵌入生成速度提升至2.64倍，误差控制在2%以内。

Conclusion: Déjà Vu通过计算重用和优化技术，显著提升了VideoLMs在大规模视频分析中的实用性。

Abstract: Recently, Video-Language Models (VideoLMs) have demonstrated remarkable capabilities, offering significant potential for flexible and powerful video query systems. These models typically rely on Vision Transformers (ViTs), which process video frames individually to extract visual embeddings. However, generating embeddings for large-scale videos requires ViT inferencing across numerous frames, posing a major hurdle to real-world deployment and necessitating solutions for integration into scalable video data management systems. This paper introduces Déjà Vu, a video-language query engine that accelerates ViT-based VideoLMs by reusing computations across consecutive frames. At its core is ReuseViT, a modified ViT model specifically designed for VideoLM tasks, which learns to detect inter-frame reuse opportunities, striking an effective balance between accuracy and reuse. Although ReuseViT significantly reduces computation, these savings do not directly translate into performance gains on GPUs. To overcome this, Déjà Vu integrates memory-compute joint compaction techniques that convert the FLOP savings into tangible performance gains. Evaluations on three VideoLM tasks show that Déjà Vu accelerates embedding generation by up to a 2.64x within a 2% error bound, dramatically enhancing the practicality of VideoLMs for large-scale video analytics.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [156] [Computational Studies in Influencer Marketing: A Systematic Literature Review](https://arxiv.org/abs/2506.14602)
*Haoyang Gui,Thales Bertaglia,Catalina Goanta,Gerasimos Spanakis*

Main category: cs.CY

TL;DR: 本文通过系统文献综述（SLR）分析了69项研究，总结了计算性影响者营销的四大主题和方法，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 计算性影响者营销领域缺乏系统性综述，导致科学测量不足，影响了平台外利益相关者（如监管者和跨领域研究者）的需求。

Method: 基于PRISMA模型进行系统文献综述，分析69项研究，识别主题和方法。

Result: 识别四大主题：影响者识别与特征、广告策略与参与、赞助内容分析、公平性；方法分为机器学习与非机器学习技术。发现商业优化为主，伦理与合规研究不足。

Conclusion: 提出多学科研究议程，强调需结合上下文因素、提升模型可解释性、标准化数据集，并加强与监管技术的联系。

Abstract: Influencer marketing has become a crucial feature of digital marketing strategies. Despite its rapid growth and algorithmic relevance, the field of computational studies in influencer marketing remains fragmented, especially with limited systematic reviews covering the computational methodologies employed. This makes overarching scientific measurements in the influencer economy very scarce, to the detriment of interested stakeholders outside of platforms themselves, such as regulators, but also researchers from other fields. This paper aims to provide an overview of the state of the art of computational studies in influencer marketing by conducting a systematic literature review (SLR) based on the PRISMA model. The paper analyses 69 studies to identify key research themes, methodologies, and future directions in this research field. The review identifies four major research themes: Influencer identification and characterisation, Advertising strategies and engagement, Sponsored content analysis and discovery, and Fairness. Methodologically, the studies are categorised into machine learning-based techniques (e.g., classification, clustering) and non-machine-learning-based techniques (e.g., statistical analysis, network analysis). Key findings reveal a strong focus on optimising commercial outcomes, with limited attention to regulatory compliance and ethical considerations. The review highlights the need for more nuanced computational research that incorporates contextual factors such as language, platform, and industry type, as well as improved model explainability and dataset reproducibility. The paper concludes by proposing a multidisciplinary research agenda that emphasises the need for further links to regulation and compliance technology, finer granularity in analysis, and the development of standardised datasets.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [157] [Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study](https://arxiv.org/abs/2506.13811)
*Sompote Youwai,David Phim,Vianne Gayl Murcia,Rianne Clair Onas*

Main category: cs.MA

TL;DR: 研究探讨了基于路由器的多智能体系统在基础设计计算自动化中的应用，通过智能任务分类和专家选择，评估了三种方法，结果显示路由器配置性能最佳。


<details>
  <summary>Details</summary>
Motivation: 自动化基础设计计算以提高效率和准确性，同时满足土木工程的安全关键需求。

Method: 评估了单智能体处理、多智能体设计-检查架构和基于路由器的专家选择三种方法，使用多种基线模型进行性能测试。

Result: 基于路由器的配置在浅基础和桩基设计中分别达到95.00%和90.63%的性能，优于其他方法。

Conclusion: 基于路由器的多智能体系统是基础设计自动化的最优选择，但仍需人类监督，作为高级计算辅助工具而非完全自主设计替代。

Abstract: This study investigates router-based multi-agent systems for automating foundation design calculations through intelligent task classification and expert selection. Three approaches were evaluated: single-agent processing, multi-agent designer-checker architecture, and router-based expert selection. Performance assessment utilized baseline models including DeepSeek R1, ChatGPT 4 Turbo, Grok 3, and Gemini 2.5 Pro across shallow foundation and pile design scenarios. The router-based configuration achieved performance scores of 95.00% for shallow foundations and 90.63% for pile design, representing improvements of 8.75 and 3.13 percentage points over standalone Grok 3 performance respectively. The system outperformed conventional agentic workflows by 10.0 to 43.75 percentage points. Grok 3 demonstrated superior standalone performance without external computational tools, indicating advances in direct LLM mathematical reasoning for engineering applications. The dual-tier classification framework successfully distinguished foundation types, enabling appropriate analytical approaches. Results establish router-based multi-agent systems as optimal for foundation design automation while maintaining professional documentation standards. Given safety-critical requirements in civil engineering, continued human oversight remains essential, positioning these systems as advanced computational assistance tools rather than autonomous design replacements in professional practice.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [158] [CRITICTOOL: Evaluating Self-Critique Capabilities of Large Language Models in Tool-Calling Error Scenarios](https://arxiv.org/abs/2506.13977)
*Shiting Huang,Zhen Fang,Zehui Chen,Siyu Yuan,Junjie Ye,Yu Zeng,Lin Chen,Qi Mao,Feng Zhao*

Main category: cs.SE

TL;DR: 论文研究了大型语言模型（LLM）在复杂任务中使用外部工具时的错误处理问题，提出了CRITICTOOL基准测试，用于评估工具学习中的错误识别、诊断和恢复能力。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂性和长期性增加，LLM使用工具时可能触发多种错误，如何有效处理这些错误成为关键研究方向。

Method: 通过分析多个工具评估基准中的错误类型，构建了CRITICTOOL基准测试，采用进化策略生成多样化错误数据集。

Result: 实验验证了CRITICTOOL的泛化性和有效性，并深入分析了不同LLM的工具反思能力。

Conclusion: CRITICTOOL为工具学习领域提供了新的评估视角，推动了LLM在复杂任务中的应用。

Abstract: The ability of large language models (LLMs) to utilize external tools has enabled them to tackle an increasingly diverse range of tasks. However, as the tasks become more complex and long-horizon, the intricate tool utilization process may trigger various unexpected errors. Therefore, how to effectively handle such errors, including identifying, diagnosing, and recovering from them, has emerged as a key research direction for advancing tool learning. In this work, we first extensively analyze the types of errors encountered during the function-calling process on several competitive tool evaluation benchmarks. Based on it, we introduce CRITICTOOL, a comprehensive critique evaluation benchmark specialized for tool learning. Building upon a novel evolutionary strategy for dataset construction, CRITICTOOL holds diverse tool-use errors with varying complexities, which better reflects real-world scenarios. We conduct extensive experiments on CRITICTOOL, and validate the generalization and effectiveness of our constructed benchmark strategy. We also provide an in-depth analysis of the tool reflection ability on various LLMs, offering a new perspective on the field of tool learning in LLMs. The code is available at \href{https://github.com/Shellorley0513/CriticTool}{https://github.com/Shellorley0513/CriticTool}.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [159] [ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs, \& a ML Ensemble on Longitudinal Identity Resolution](https://arxiv.org/abs/2506.13792)
*Gonçalo Hora de Carvalho,Lazar S. Popov,Sander Kaatee,Kristinn R. Thórisson,Tangrui Li,Pétur Húni Björnsson,Jilles S. Dibangoye*

Main category: cs.AI

TL;DR: ICE-ID是一个用于历史身份解析的新基准数据集，涵盖220年（1703-1920）的冰岛人口普查记录，支持多代纵向数据研究。


<details>
  <summary>Details</summary>
Motivation: 填补长期人物实体匹配研究中的空白，提供首个大规模开放表格数据集，促进跨学科研究。

Method: 定义了身份解析任务，评估了多种方法，包括规则匹配器、机器学习集成、LLMs和新型NARS框架。

Result: NARS方法表现出色，达到SOTA水平。

Conclusion: 通过发布ICE-ID和代码，支持可重复的基准测试，推动数据链接和历史分析的研究。

Abstract: We introduce ICE-ID, a novel benchmark dataset for historical identity resolution, comprising 220 years (1703-1920) of Icelandic census records. ICE-ID spans multiple generations of longitudinal data, capturing name variations, demographic changes, and rich genealogical links. To the best of our knowledge, this is the first large-scale, open tabular dataset specifically designed to study long-term person-entity matching in a real-world population. We define identity resolution tasks (within and across census waves) with clearly documented metrics and splits. We evaluate a range of methods: handcrafted rule-based matchers, a ML ensemble as well as LLMs for structured data (e.g. transformer-based tabular networks) against a novel approach to tabular data called NARS (Non-Axiomatic Reasoning System) - a general-purpose AI framework designed to reason with limited knowledge and resources. Its core is Non-Axiomatic Logic (NAL), a term-based logic. Our experiments show that NARS is suprisingly simple and competitive with other standard approaches, achieving SOTA at our task. By releasing ICE-ID and our code, we enable reproducible benchmarking of identity resolution approaches in longitudinal settings and hope that ICE-ID opens new avenues for cross-disciplinary research in data linkage and historical analytics.

</details>


### [160] [Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs](https://arxiv.org/abs/2506.14245)
*Xumeng Wen,Zihan Liu,Shun Zheng,Zhijian Xu,Shengyu Ye,Zhirong Wu,Xiao Liang,Yang Wang,Junjie Li,Ziming Miao,Jiang Bian,Mao Yang*

Main category: cs.AI

TL;DR: 论文提出RLVR（可验证奖励的强化学习）在提升大语言模型推理能力时存在矛盾：RLVR调优的模型在$Pass@K$指标上表现不佳。作者发现$Pass@K$指标本身有缺陷，因为它忽略了推理链的正确性。为此，他们提出新指标$CoT$-$Pass@K$，要求推理链和最终答案均正确，并证明RLVR能有效提升推理完整性。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR调优模型在$Pass@K$指标上表现不佳的矛盾，揭示$Pass@K$指标的缺陷，并提出更可靠的评估方法。

Method: 引入新指标$CoT$-$Pass@K$，要求推理链和答案均正确；理论分析RLVR如何激励逻辑完整性；通过实验验证新指标的有效性。

Result: 使用$CoT$-$Pass@K$指标后，RLVR能显著提升推理完整性，且这种能力在训练早期即出现并平滑泛化。

Conclusion: RLVR通过新指标$CoT$-$Pass@K$被证明能真正提升机器推理能力，为RLVR的作用提供了清晰视角和可靠评估方法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). However, a critical paradox clouds its efficacy: RLVR-tuned models often underperform their base models on the $Pass@K$ metric for solution-finding, leading to the hypothesis that RLVR merely re-weights existing reasoning paths at the cost of reasoning diversity. In this work, we resolve this contradiction by identifying the source of the problem: the $Pass@K$ metric itself is a flawed measure of reasoning, as it credits correct final answers that probably arise from inaccurate or incomplete chains of thought (CoTs). To address this, we introduce a more precise evaluation metric, $CoT$-$Pass@K$, which mandates that both the reasoning path and the final answer be correct. We provide a new theoretical foundation that formalizes how RLVR, unlike traditional RL, is uniquely structured to incentivize logical integrity. Our empirical results are supportive: using $CoT$-$Pass@K$, we observe that RLVR can incentivize the generalization of correct reasoning for all values of $K$. Furthermore, by analyzing the training dynamics, we find that this enhanced reasoning capability emerges early in the training process and smoothly generalizes. Our work provides a clear perspective on the role of RLVR, offers a more reliable method for its evaluation, and confirms its potential to genuinely advance machine reasoning.

</details>


### [161] [Optimizing Length Compression in Large Reasoning Models](https://arxiv.org/abs/2506.14755)
*Zhengxiang Cheng,Dongping Chen,Mingyang Fu,Tianyi Zhou*

Main category: cs.AI

TL;DR: 论文提出LC-R1方法，通过Brevity和Sufficiency原则优化大型推理模型（LRMs），减少冗余推理链，实现高压缩（序列长度减少50%）且精度仅下降2%。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）常因产生冗余推理链（无效思考）而效率低下，需针对性优化。

Method: 提出LC-R1方法，基于GRPO框架，结合长度奖励（Length Reward）和压缩奖励（Compress Reward）消除无效推理。

Result: 实验显示LC-R1显著减少序列长度（50%），精度仅降2%，达到帕累托最优。

Conclusion: LC-R1为高效LRMs开发提供了新思路，代码已开源。

Abstract: Large Reasoning Models (LRMs) have achieved remarkable success, yet they often suffer from producing unnecessary and verbose reasoning chains. We identify a core aspect of this issue as "invalid thinking" -- models tend to repeatedly double-check their work after having derived the correct answer. To address this specific inefficiency, we move beyond the general principles of Efficacy and Efficiency to propose two new, fine-grained principles: Brevity, which advocates for eliminating redundancy, and Sufficiency, which ensures critical reasoning steps are preserved. Guided by these principles, we introduce LC-R1, a post-training method based on Group Relative Policy Optimization (GRPO). LC-R1 employs a novel combination of a Length Reward for overall conciseness and a Compress Reward that is specifically designed to remove the invalid portion of the thinking process. Extensive experiments on multiple reasoning benchmarks demonstrate that LC-R1 achieves a significant reduction in sequence length (~50%) with only a marginal (~2%) drop in accuracy, achieving a favorable trade-off point on the Pareto frontier that prioritizes high compression. Our analysis further validates the robustness of LC-R1 and provides valuable insights for developing more powerful yet computationally efficient LRMs. Our code is released at https://github.com/zxiangx/LC-R1.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [162] [Busting the Paper Ballot: Voting Meets Adversarial Machine Learning](https://arxiv.org/abs/2506.14582)
*Kaleel Mahmood,Caleb Manicke,Ethan Rathbun,Aayushi Verma,Sohaib Ahmad,Nicholas Stamatakis,Laurent Michel,Benjamin Fuller*

Main category: cs.CR

TL;DR: 论文探讨了在美国选举计票器中使用机器学习分类器的安全风险，通过新数据集和多种模型展示了对抗攻击的潜在影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示机器学习模型在选举计票中的潜在漏洞，尤其是对抗攻击可能对选举结果产生的重大影响。

Method: 方法包括引入四个新数据集、训练多种模型（如SVM、CNN、ViT）、分析梯度掩蔽问题，并提出改进的对抗攻击方法。

Result: 结果显示，传统白盒攻击因梯度掩蔽而无效，但改进方法能在物理世界中实现低成功率但高影响的攻击。

Conclusion: 结论指出，即使低成功率的对抗攻击也可能改变选举结果，强调了选举安全中对抗攻击的现实威胁。

Abstract: We show the security risk associated with using machine learning classifiers in United States election tabulators. The central classification task in election tabulation is deciding whether a mark does or does not appear on a bubble associated to an alternative in a contest on the ballot. Barretto et al. (E-Vote-ID 2021) reported that convolutional neural networks are a viable option in this field, as they outperform simple feature-based classifiers.
  Our contributions to election security can be divided into four parts. To demonstrate and analyze the hypothetical vulnerability of machine learning models on election tabulators, we first introduce four new ballot datasets. Second, we train and test a variety of different models on our new datasets. These models include support vector machines, convolutional neural networks (a basic CNN, VGG and ResNet), and vision transformers (Twins and CaiT). Third, using our new datasets and trained models, we demonstrate that traditional white box attacks are ineffective in the voting domain due to gradient masking. Our analyses further reveal that gradient masking is a product of numerical instability. We use a modified difference of logits ratio loss to overcome this issue (Croce and Hein, ICML 2020). Fourth, in the physical world, we conduct attacks with the adversarial examples generated using our new methods. In traditional adversarial machine learning, a high (50% or greater) attack success rate is ideal. However, for certain elections, even a 5% attack success rate can flip the outcome of a race. We show such an impact is possible in the physical domain. We thoroughly discuss attack realism, and the challenges and practicality associated with printing and scanning ballot adversarial examples.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [163] [LittleBit: Ultra Low-Bit Quantization via Latent Factorization](https://arxiv.org/abs/2506.13771)
*Banseok Lee,Dongkyu Kim,Youngcheon You,Youngmin Kim*

Main category: cs.LG

TL;DR: LittleBit是一种新颖的极端LLM压缩方法，通过低秩矩阵分解和二值化实现0.1 BPW的压缩，显著减少内存和计算成本。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）部署面临高内存和计算成本问题，而现有量化方法在低于1位精度时性能下降严重。

Method: 采用低秩矩阵分解表示权重并二值化，结合多尺度补偿机制（行、列和潜在维度）减少信息损失。关键贡献包括Dual-SVID和残差补偿。

Result: 实验显示LittleBit在0.1 BPW下性能优于现有方法（如Llama2-7B），内存减少31倍，速度提升5倍。

Conclusion: LittleBit为资源受限环境部署高性能LLM提供了有效解决方案。

Abstract: Deploying large language models (LLMs) often faces challenges from substantial memory and computational costs. Quantization offers a solution, yet performance degradation in the sub-1-bit regime remains particularly difficult. This paper introduces LittleBit, a novel method for extreme LLM compression. It targets levels like 0.1 bits per weight (BPW), achieving nearly 31$\times$ memory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents weights in a low-rank form using latent matrix factorization, subsequently binarizing these factors. To counteract information loss from this extreme precision, it integrates a multi-scale compensation mechanism. This includes row, column, and an additional latent dimension that learns per-rank importance. Two key contributions enable effective training: Dual Sign-Value-Independent Decomposition (Dual-SVID) for stable quantization-aware training (QAT) initialization, and integrated Residual Compensation to mitigate errors. Extensive experiments confirm LittleBit's superiority in sub-1-bit quantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading method's 0.7 BPW. This establishes a superior size-performance trade-off, with kernel-level benchmarks indicating potential for a 5$\times$ speedup compared to FP16. LittleBit paves the way for deploying powerful LLMs in resource-constrained environments.

</details>


### [164] [Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models](https://arxiv.org/abs/2506.13923)
*Vaskar Nath,Elaine Lau,Anisha Gunjal,Manasi Sharma,Nikhil Baharte,Sean Hendryx*

Main category: cs.LG

TL;DR: RLVR训练通过压缩pass@k到pass@1和能力提升（解决新问题）提升性能，主要依赖自蒸馏。提出Guide算法，通过自适应提示和调整采样比优化策略，在7B和32B模型上提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究RLVR训练如何通过压缩和能力提升解决新问题，并探索如何通过自然语言提示进一步提升性能。

Method: 使用RLVR训练模型，提出Guide算法，结合自适应提示和重要性采样调整，优化策略。

Result: Guide算法在7B和32B模型上显著提升泛化能力，数学基准上最高提升4%。

Conclusion: RLVR训练和Guide算法能有效提升模型解决新问题的能力，并通过自适应提示进一步优化性能。

Abstract: We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance through two main means: (1) by compressing pass@$k$ into pass@1 and (2) via "capability gain" in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B on >500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $\text{Guide}$ - a new class of online training algorithms. $\text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the "off-policy" trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $\text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$\%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $\text{Guide}$'s components and theoretically analyze Guide's learning efficiency.

</details>


### [165] [AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science](https://arxiv.org/abs/2506.13992)
*An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding*

Main category: cs.LG

TL;DR: 论文评估了大型语言模型（LLMs）在数据科学任务中处理领域知识的能力，发现其存在盲目采纳信息、对抗性内容影响显著等问题。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否能像人类数据科学家一样批判性地利用外部领域知识。

Method: 引入AssistedDS基准，结合合成数据集和真实Kaggle竞赛，评估LLMs在表格预测任务中处理领域知识的表现。

Result: LLMs常盲目采纳信息，对抗性内容显著降低预测性能；在时间序列和分类变量处理上表现不佳。

Conclusion: 当前模型在批判性评估和利用专家知识方面存在显著不足，需开发更鲁棒的知识感知系统。

Abstract: Large language models (LLMs) have advanced the automation of data science workflows. Yet it remains unclear whether they can critically leverage external domain knowledge as human data scientists do in practice. To answer this question, we introduce AssistedDS (Assisted Data Science), a benchmark designed to systematically evaluate how LLMs handle domain knowledge in tabular prediction tasks. AssistedDS features both synthetic datasets with explicitly known generative mechanisms and real-world Kaggle competitions, each accompanied by curated bundles of helpful and adversarial documents. These documents provide domain-specific insights into data cleaning, feature engineering, and model selection. We assess state-of-the-art LLMs on their ability to discern and apply beneficial versus harmful domain knowledge, evaluating submission validity, information recall, and predictive performance. Our results demonstrate three key findings: (1) LLMs frequently exhibit an uncritical adoption of provided information, significantly impairing their predictive performance when adversarial content is introduced, (2) helpful guidance is often insufficient to counteract the negative influence of adversarial information, and (3) in Kaggle datasets, LLMs often make errors in handling time-series data, applying consistent feature engineering across different folds, and interpreting categorical variables correctly. These findings highlight a substantial gap in current models' ability to critically evaluate and leverage expert knowledge, underscoring an essential research direction for developing more robust, knowledge-aware automated data science systems.

</details>


### [166] [Improving LoRA with Variational Learning](https://arxiv.org/abs/2506.14280)
*Bai Cong,Nico Daheim,Yuesong Shen,Rio Yokota,Mohammad Emtiyaz Khan,Thomas Möllenhoff*

Main category: cs.LG

TL;DR: IVON算法显著改善了LoRA微调，提升了准确性和校准性，同时计算成本与AdamW相当。


<details>
  <summary>Details</summary>
Motivation: 解决贝叶斯方法在LoRA微调中计算开销大且效果有限的问题。

Method: 使用IVON变分算法，结合后验剪枝技术。

Result: 在Llama-3.2-3B模型上，准确率提升1.3%，ECE降低5.4%。

Conclusion: IVON能有效改进LoRA微调，优于AdamW及其他贝叶斯方法。

Abstract: Bayesian methods have recently been used to improve LoRA finetuning and, although they improve calibration, their effect on other metrics (such as accuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian methods also increase computational overheads and require additional tricks for them to work well. Here, we fix these issues by using a recently proposed variational algorithm called IVON. We show that IVON is easy to implement and has similar costs to AdamW, and yet it can also drastically improve many metrics by using a simple posterior pruning technique. We present extensive results on billion-scale LLMs (Llama and Qwen series) going way beyond the scale of existing applications of IVON. For example, we finetune a Llama-3.2-3B model on a set of commonsense reasoning tasks and improve accuracy over AdamW by 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian methods like Laplace-LoRA and BLoB. Overall, our results show that variational learning with IVON can effectively improve LoRA finetuning.

</details>


### [167] [TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization](https://arxiv.org/abs/2506.14574)
*Mingkang Zhu,Xi Chen,Zhongdao Wang,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.LG

TL;DR: 论文提出了一种方法，将序列级的PPO分解为一系列令牌级的PPO问题，并利用令牌级奖励指导DPO，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管令牌级奖励模型能提升PPO性能，但难以直接用于DPO，因为DPO是序列级问题。

Method: 将序列级PPO分解为令牌级问题，推导出令牌级最优策略和奖励，并基于此设计DPO的损失函数。

Result: 在多个基准测试中，性能显著提升（MT-Bench提升7.5分，AlpacaEval 2提升6.2分，Arena-Hard提升4.3分）。

Conclusion: 该方法成功将令牌级奖励引入DPO，显著提升了模型对齐效果。

Abstract: Recent advancements in reinforcement learning from human feedback have shown that utilizing fine-grained token-level reward models can substantially enhance the performance of Proximal Policy Optimization (PPO) in aligning large language models. However, it is challenging to leverage such token-level reward as guidance for Direct Preference Optimization (DPO), since DPO is formulated as a sequence-level bandit problem. To address this challenge, this work decomposes the sequence-level PPO into a sequence of token-level proximal policy optimization problems and then frames the problem of token-level PPO with token-level reward guidance, from which closed-form optimal token-level policy and the corresponding token-level reward can be derived. Using the obtained reward and Bradley-Terry model, this work establishes a framework of computable loss functions with token-level reward guidance for DPO, and proposes a practical reward guidance based on the induced DPO reward. This formulation enables different tokens to exhibit varying degrees of deviation from reference policy based on their respective rewards. Experiment results demonstrate that our method achieves substantial performance improvements over DPO, with win rate gains of up to 7.5 points on MT-Bench, 6.2 points on AlpacaEval 2, and 4.3 points on Arena-Hard. Code is available at https://github.com/dvlab-research/TGDPO.

</details>


### [168] [Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection](https://arxiv.org/abs/2506.14390)
*Conrad Orglmeister,Erik Bochinski,Volker Eiselein,Elvira Fleig*

Main category: cs.LG

TL;DR: 论文提出了一种结合自解释原型变分模型和自编码器的OOD检测方法，通过变分自编码器学习潜在空间，用于分类、OOD检测和重建，并在真实铁路数据上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 提高深度机器学习模型在安全相关应用中的决策可信度和可靠性。

Method: 使用变分自编码器学习潜在空间，定义高斯混合分布作为ID区域，引入限制损失以保持ID区域的紧凑性。

Result: 在常见OOD检测基准和真实铁路数据集上表现优于现有方法。

Conclusion: 该方法通过自解释性和紧凑的ID区域设计，有效提升了OOD检测性能。

Abstract: Understanding the decision-making and trusting the reliability of Deep Machine Learning Models is crucial for adopting such methods to safety-relevant applications. We extend self-explainable Prototypical Variational models with autoencoder-based out-of-distribution (OOD) detection: A Variational Autoencoder is applied to learn a meaningful latent space which can be used for distance-based classification, likelihood estimation for OOD detection, and reconstruction. The In-Distribution (ID) region is defined by a Gaussian mixture distribution with learned prototypes representing the center of each mode. Furthermore, a novel restriction loss is introduced that promotes a compact ID region in the latent space without collapsing it into single points. The reconstructive capabilities of the Autoencoder ensure the explainability of the prototypes and the ID region of the classifier, further aiding the discrimination of OOD samples. Extensive evaluations on common OOD detection benchmarks as well as a large-scale dataset from a real-world railway application demonstrate the usefulness of the approach, outperforming previous methods.

</details>


### [169] [Train Once, Forget Precisely: Anchored Optimization for Efficient Post-Hoc Unlearning](https://arxiv.org/abs/2506.14515)
*Prabhav Sanga,Jaskaran Singh,Arun K. Dubey*

Main category: cs.LG

TL;DR: FAMR是一种高效的后处理遗忘框架，用于深度图像分类器，通过约束优化问题实现选择性遗忘，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统依赖受隐私法规约束的数据，选择性遗忘特定信息变得至关重要。

Method: FAMR通过最小化遗忘集的均匀预测损失，并结合ℓ2惩罚锚定原始模型参数，实现遗忘。

Result: 在CIFAR-10和ImageNet-100上的实验表明，FAMR能有效保留性能且计算开销低。

Conclusion: FAMR为视觉模型提供了一种可扩展且可验证的高效遗忘方法。

Abstract: As machine learning systems increasingly rely on data subject to privacy regulation, selectively unlearning specific information from trained models has become essential. In image classification, this involves removing the influence of particular training samples, semantic classes, or visual styles without full retraining. We introduce \textbf{Forget-Aligned Model Reconstruction (FAMR)}, a theoretically grounded and computationally efficient framework for post-hoc unlearning in deep image classifiers. FAMR frames forgetting as a constrained optimization problem that minimizes a uniform-prediction loss on the forget set while anchoring model parameters to their original values via an $\ell_2$ penalty. A theoretical analysis links FAMR's solution to influence-function-based retraining approximations, with bounds on parameter and output deviation. Empirical results on class forgetting tasks using CIFAR-10 and ImageNet-100 demonstrate FAMR's effectiveness, with strong performance retention and minimal computational overhead. The framework generalizes naturally to concept and style erasure, offering a scalable and certifiable route to efficient post-hoc forgetting in vision models.

</details>


### [170] [Towards Desiderata-Driven Design of Visual Counterfactual Explainers](https://arxiv.org/abs/2506.14698)
*Sidney Bender,Jan Herrmann,Klaus-Robert Müller,Grégoire Montavon*

Main category: cs.LG

TL;DR: 本文提出了一种新的视觉反事实解释方法（SCE），旨在弥补现有方法在解释全面性上的不足，如保真度、可理解性和充分性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉反事实解释器（VCEs）过于关注样本质量或变化最小化，忽略了更全面的解释需求。

Method: 提出了一种新的反事实生成机制，并将其整合为‘平滑反事实探索器’（SCE）算法。

Result: 通过合成数据和真实数据的系统评估，证明了SCE算法的有效性。

Conclusion: SCE算法能够更好地满足解释的全面需求，提升图像分类器的透明度。

Abstract: Visual counterfactual explainers (VCEs) are a straightforward and promising approach to enhancing the transparency of image classifiers. VCEs complement other types of explanations, such as feature attribution, by revealing the specific data transformations to which a machine learning model responds most strongly. In this paper, we argue that existing VCEs focus too narrowly on optimizing sample quality or change minimality; they fail to consider the more holistic desiderata for an explanation, such as fidelity, understandability, and sufficiency. To address this shortcoming, we explore new mechanisms for counterfactual generation and investigate how they can help fulfill these desiderata. We combine these mechanisms into a novel 'smooth counterfactual explorer' (SCE) algorithm and demonstrate its effectiveness through systematic evaluations on synthetic and real data.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [171] [MobileHolo: A Lightweight Complex-Valued Deformable CNN for High-Quality Computer-Generated Hologram](https://arxiv.org/abs/2506.14542)
*Xie Shuyang,Zhou Jie,Xu Bo,Wang Jun,Xu Renjing*

Main category: physics.optics

TL;DR: 论文提出了一种基于深度学习的全息显示方法，通过设计复数可变形卷积网络，动态调整卷积核形状以提升特征提取能力，实现了在模拟和光学实验中的最优性能。


<details>
  <summary>Details</summary>
Motivation: 全息显示在虚拟和增强现实中潜力巨大，但现有方法因有效感受野不足而难以准确建模衍射过程。

Method: 设计复数可变形卷积网络，动态调整卷积核形状以增强特征提取能力。

Result: 在1920×1072分辨率下，峰值信噪比分别比CCNN-CGH、HoloNet和Holo-encoder高2.04 dB、5.31 dB和9.71 dB，且参数量仅为CCNN-CGH的八分之一。

Conclusion: 该方法通过动态调整卷积核形状，显著提升了全息显示的性能，同时减少了模型参数量。

Abstract: Holographic displays have significant potential in virtual reality and augmented reality owing to their ability to provide all the depth cues. Deep learning-based methods play an important role in computer-generated holograms (CGH). During the diffraction process, each pixel exerts an influence on the reconstructed image. However, previous works face challenges in capturing sufficient information to accurately model this process, primarily due to the inadequacy of their effective receptive field (ERF). Here, we designed complex-valued deformable convolution for integration into network, enabling dynamic adjustment of the convolution kernel's shape to increase flexibility of ERF for better feature extraction. This approach allows us to utilize a single model while achieving state-of-the-art performance in both simulated and optical experiment reconstructions, surpassing existing open-source models. Specifically, our method has a peak signal-to-noise ratio that is 2.04 dB, 5.31 dB, and 9.71 dB higher than that of CCNN-CGH, HoloNet, and Holo-encoder, respectively, when the resolution is 1920$\times$1072. The number of parameters of our model is only about one-eighth of that of CCNN-CGH.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [172] [GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation](https://arxiv.org/abs/2506.14135)
*Ying Chai,Litao Deng,Ruizhi Shao,Jiajun Zhang,Liangjun Xing,Hongwen Zhang,Yebin Liu*

Main category: cs.RO

TL;DR: 论文提出了一种V-4D-A框架，通过高斯动作场（GAF）直接从运动感知的4D表示中进行动作推理，显著提升了机器人操作的准确性和场景重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法（V-A或V-3D-A）在复杂动态场景中动作推理不准确，因此需要一种能同时建模动态场景和操作动作的新方法。

Method: 提出GAF，扩展3D高斯泼溅（3DGS）以包含可学习运动属性，支持场景重建、未来帧预测和初始动作估计，并通过GAF引导的扩散模型优化动作。

Result: GAF在重建质量上显著提升（PSNR +11.5385 dB，LPIPS -0.5574），机器人操作任务成功率提高10.33%。

Conclusion: V-4D-A框架和GAF在动态场景建模和动作推理中表现出色，为机器人操作提供了更高效的解决方案。

Abstract: Accurate action inference is critical for vision-based robotic manipulation. Existing approaches typically follow either a Vision-to-Action (V-A) paradigm, predicting actions directly from visual inputs, or a Vision-to-3D-to-Action (V-3D-A) paradigm, leveraging intermediate 3D representations. However, these methods often struggle with action inaccuracies due to the complexity and dynamic nature of manipulation scenes. In this paper, we propose a V-4D-A framework that enables direct action reasoning from motion-aware 4D representations via a Gaussian Action Field (GAF). GAF extends 3D Gaussian Splatting (3DGS) by incorporating learnable motion attributes, allowing simultaneous modeling of dynamic scenes and manipulation actions. To learn time-varying scene geometry and action-aware robot motion, GAF supports three key query types: reconstruction of the current scene, prediction of future frames, and estimation of initial action via robot motion. Furthermore, the high-quality current and future frames generated by GAF facilitate manipulation action refinement through a GAF-guided diffusion model. Extensive experiments demonstrate significant improvements, with GAF achieving +11.5385 dB PSNR and -0.5574 LPIPS improvements in reconstruction quality, while boosting the average success rate in robotic manipulation tasks by 10.33% over state-of-the-art methods. Project page: http://chaiying1.github.io/GAF.github.io/project_page/

</details>


### [173] [AMPLIFY: Actionless Motion Priors for Robot Learning from Videos](https://arxiv.org/abs/2506.14198)
*Jeremy A. Collins,Loránd Cheng,Kunal Aneja,Albert Wilcox,Benjamin Joffe,Animesh Garg*

Main category: cs.RO

TL;DR: AMPLIFY框架利用大规模无动作视频数据，通过关键点轨迹生成紧凑的运动标记，分离视觉运动预测与动作推断，显著提升动态模型准确性和策略学习效果。


<details>
  <summary>Details</summary>
Motivation: 机器人动作标记数据稀缺且昂贵，限制了学习策略的泛化能力，而无动作视频数据丰富但难以转化为有效策略。

Method: 通过关键点轨迹编码视觉动态为离散运动标记，分别训练前向动态模型（无动作视频）和逆向动态模型（少量标记数据）。

Result: 动态模型准确性显著提升（MSE提高3.7倍，像素预测精度提高2.5倍），策略学习在低数据量下提升1.2-2.2倍，首次实现零分布动作数据的LIBERO任务泛化。

Conclusion: AMPLIFY提出了一种利用异构数据构建高效、可泛化世界模型的新范式，适用于机器人控制及其他领域。

Abstract: Action-labeled data for robotics is scarce and expensive, limiting the generalization of learned policies. In contrast, vast amounts of action-free video data are readily available, but translating these observations into effective policies remains a challenge. We introduce AMPLIFY, a novel framework that leverages large-scale video data by encoding visual dynamics into compact, discrete motion tokens derived from keypoint trajectories. Our modular approach separates visual motion prediction from action inference, decoupling the challenges of learning what motion defines a task from how robots can perform it. We train a forward dynamics model on abundant action-free videos and an inverse dynamics model on a limited set of action-labeled examples, allowing for independent scaling. Extensive evaluations demonstrate that the learned dynamics are both accurate, achieving up to 3.7x better MSE and over 2.5x better pixel prediction accuracy compared to prior approaches, and broadly useful. In downstream policy learning, our dynamics predictions enable a 1.2-2.2x improvement in low-data regimes, a 1.4x average improvement by learning from action-free human videos, and the first generalization to LIBERO tasks from zero in-distribution action data. Beyond robotic control, we find the dynamics learned by AMPLIFY to be a versatile latent world model, enhancing video prediction quality. Our results present a novel paradigm leveraging heterogeneous data sources to build efficient, generalizable world models. More information can be found at https://amplify-robotics.github.io/.

</details>


### [174] [GAMORA: A Gesture Articulated Meta Operative Robotic Arm for Hazardous Material Handling in Containment-Level Environments](https://arxiv.org/abs/2506.14513)
*Farha Abdul Wasay,Mohammed Abdul Rahman,Hania Ghouse*

Main category: cs.RO

TL;DR: GAMORA是一种基于VR的机器人系统，用于远程执行高风险实验室任务，通过手势控制实现高精度操作。


<details>
  <summary>Details</summary>
Motivation: 随着生物危害复杂性增加，减少人类直接接触并保持操作精度成为关键需求。

Method: 系统结合Oculus Quest 2、NVIDIA Jetson Nano和ROS，提供实时沉浸式控制、数字孪生模拟和逆运动学操作。

Result: GAMORA实现了2.2 mm的位置误差、0.2 mL的移液精度和1.2 mm的重复性，并降低50%能耗。

Conclusion: GAMORA为高风险实验室任务提供了一种可扩展、沉浸式的自动化解决方案。

Abstract: The convergence of robotics and virtual reality (VR) has enabled safer and more efficient workflows in high-risk laboratory settings, particularly virology labs. As biohazard complexity increases, minimizing direct human exposure while maintaining precision becomes essential. We propose GAMORA (Gesture Articulated Meta Operative Robotic Arm), a novel VR-guided robotic system that enables remote execution of hazardous tasks using natural hand gestures. Unlike existing scripted automation or traditional teleoperation, GAMORA integrates the Oculus Quest 2, NVIDIA Jetson Nano, and Robot Operating System (ROS) to provide real-time immersive control, digital twin simulation, and inverse kinematics-based articulation. The system supports VR-based training and simulation while executing precision tasks in physical environments via a 3D-printed robotic arm. Inverse kinematics ensure accurate manipulation for delicate operations such as specimen handling and pipetting. The pipeline includes Unity-based 3D environment construction, real-time motion planning, and hardware-in-the-loop testing. GAMORA achieved a mean positional discrepancy of 2.2 mm (improved from 4 mm), pipetting accuracy within 0.2 mL, and repeatability of 1.2 mm across 50 trials. Integrated object detection via YOLOv8 enhances spatial awareness, while energy-efficient operation (50% reduced power output) ensures sustainable deployment. The system's digital-physical feedback loop enables safe, precise, and repeatable automation of high-risk lab tasks. GAMORA offers a scalable, immersive solution for robotic control and biosafety in biomedical research environments.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [175] [Acoustic scattering AI for non-invasive object classifications: A case study on hair assessment](https://arxiv.org/abs/2506.14148)
*Long-Vu Hoang,Tuan Nguyen,Tran Huy Dat*

Main category: cs.SD

TL;DR: 本文提出了一种基于声学散射的非侵入式物体分类方法，并通过头发评估案例展示了其有效性。通过发射声学刺激并捕捉头发样本的散射信号，利用AI驱动的深度学习进行头发类型和湿度的分类，最佳方法实现了近90%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 探索一种隐私保护、非接触式的替代视觉分类的方法，利用声学散射技术实现物体分类。

Method: 通过发射声学刺激并捕捉散射信号，结合四种深度学习策略（全监督、嵌入分类、监督基础模型微调、自监督模型微调）进行分类。

Result: 最佳策略（自监督模型微调）实现了近90%的分类准确率。

Conclusion: 声学散射技术在非侵入式分类中具有巨大潜力，适用于多种行业应用。

Abstract: This paper presents a novel non-invasive object classification approach using acoustic scattering, demonstrated through a case study on hair assessment. When an incident wave interacts with an object, it generates a scattered acoustic field encoding structural and material properties. By emitting acoustic stimuli and capturing the scattered signals from head-with-hair-sample objects, we classify hair type and moisture using AI-driven, deep-learning-based sound classification. We benchmark comprehensive methods, including (i) fully supervised deep learning, (ii) embedding-based classification, (iii) supervised foundation model fine-tuning, and (iv) self-supervised model fine-tuning. Our best strategy achieves nearly 90% classification accuracy by fine-tuning all parameters of a self-supervised model. These results highlight acoustic scattering as a privacy-preserving, non-contact alternative to visual classification, opening huge potential for applications in various industries.

</details>


### [176] [Pushing the Performance of Synthetic Speech Detection with Kolmogorov-Arnold Networks and Self-Supervised Learning Models](https://arxiv.org/abs/2506.14153)
*Tuan Dat Phuong,Long-Vu Hoang,Huy Dat Tran*

Main category: cs.SD

TL;DR: 论文提出了一种将Kolmogorov-Arnold Network（KAN）引入XLSR-Conformer模型的方法，显著提升了合成语音检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于自监督学习的模型在合成语音检测中表现优异，但仍需改进架构以应对日益复杂的欺骗攻击。

Method: 用Kolmogorov-Arnold Network（KAN）替代XLSR-Conformer模型中的传统多层感知机。

Result: 在ASVspoof2021数据集上，性能相对提升60.55%，在21LA集上EER达到0.70%。

Conclusion: 将KAN整合到自监督学习模型中，是提升合成语音检测性能的有效方向。

Abstract: Recent advancements in speech synthesis technologies have led to increasingly advanced spoofing attacks, posing significant challenges for automatic speaker verification systems. While systems based on self-supervised learning (SSL) models, particularly the XLSR-Conformer model, have demonstrated remarkable performance in synthetic speech detection, there remains room for architectural improvements. In this paper, we propose a novel approach that replaces the traditional Multi-Layer Perceptron in the XLSR-Conformer model with a Kolmogorov-Arnold Network (KAN), a novel architecture based on the Kolmogorov-Arnold representation theorem. Our results on ASVspoof2021 demonstrate that integrating KAN into the SSL-based models can improve the performance by 60.55% relatively on LA and DF sets, further achieving 0.70% EER on the 21LA set. These findings suggest that incorporating KAN into SSL-based models is a promising direction for advances in synthetic speech detection.

</details>


### [177] [Fretting-Transformer: Encoder-Decoder Model for MIDI to Tablature Transcription](https://arxiv.org/abs/2506.14223)
*Anna Hamberger,Sebastian Murgul,Jochen Schmidt,Michael Heizmann*

Main category: cs.SD

TL;DR: Fretting-Transformer是一种基于T5架构的编码器-解码器模型，用于将MIDI序列自动转录为吉他指法谱，解决了弦-品模糊性和可演奏性问题，性能优于基线方法和商业应用。


<details>
  <summary>Details</summary>
Motivation: 音乐转录在MIR中至关重要，尤其是吉他等弦乐器，MIDI符号缺乏可演奏性信息。

Method: 采用T5变换器架构，将任务视为符号翻译问题，结合新颖的数据预处理和标记化策略，使用DadaGP等数据集。

Result: 实验表明，Fretting-Transformer在指法谱准确性和可演奏性上优于A*和Guitar Pro等基线方法。

Conclusion: 该模型为吉他自动转录的未来发展奠定了坚实基础，结合上下文敏感处理和调音/变调夹条件进一步提升了性能。

Abstract: Music transcription plays a pivotal role in Music Information Retrieval (MIR), particularly for stringed instruments like the guitar, where symbolic music notations such as MIDI lack crucial playability information. This contribution introduces the Fretting-Transformer, an encoderdecoder model that utilizes a T5 transformer architecture to automate the transcription of MIDI sequences into guitar tablature. By framing the task as a symbolic translation problem, the model addresses key challenges, including string-fret ambiguity and physical playability. The proposed system leverages diverse datasets, including DadaGP, GuitarToday, and Leduc, with novel data pre-processing and tokenization strategies. We have developed metrics for tablature accuracy and playability to quantitatively evaluate the performance. The experimental results demonstrate that the Fretting-Transformer surpasses baseline methods like A* and commercial applications like Guitar Pro. The integration of context-sensitive processing and tuning/capo conditioning further enhances the model's performance, laying a robust foundation for future developments in automated guitar transcription.

</details>
